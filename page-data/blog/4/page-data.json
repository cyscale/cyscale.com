{"componentChunkName":"component---src-template-blog-all-posts-template-js","path":"/blog/4/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News","Compliance"],"title":"AWS SOC 2 Compliance Checklist: A Detailed Guide","seoTitle":"AWS SOC 2 Compliance Checklist: A Detailed Guide","description":"SOC 2 is a compliance standard that regulates the way data security is handled within B2B (business-to-business) organizations. SOC (Service and Organization Controls) 2 is an international standard developed by AICPA (The American Institute of Certified Public Accountants). \n\nIn this article, we will understand what requirements your company needs to fulfill to obtain the SOC 2 certifications and how to implement them correctly in your AWS environment. ","seoDescription":"AWS SOC 2 Compliance","date":"2022-10-19T10:11:42.781Z","featuredpost":true,"permalink":"AWS-SOC-2-Compliance-Checklist-A-Detailed-Guide","featuredimage":{"publicURL":"/static/db7c98536037b7995ebf25758763897c/26-cyscale-blog-min.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/db7c98536037b7995ebf25758763897c/888e2/26-cyscale-blog-min.webp","srcSet":"/static/db7c98536037b7995ebf25758763897c/913d0/26-cyscale-blog-min.webp 205w,\n/static/db7c98536037b7995ebf25758763897c/91660/26-cyscale-blog-min.webp 410w,\n/static/db7c98536037b7995ebf25758763897c/888e2/26-cyscale-blog-min.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nSOC 2 is a compliance standard that regulates the way data security is handled within B2B (business-to-business) organizations. SOC (Service and Organization Controls) 2 is an international standard developed by AICPA (The American Institute of Certified Public Accountants). In the context of **[cloud compliance](https://cyscale.com/blog/cloud-compliance-101-basics-best-practices/)**, understanding SOC 2 requirements in your AWS environment is crucial for data security.\n\nIn this article, we will understand what requirements your company needs to fulfill to obtain the [SOC 2 certifications](https://cyscale.com/blog/soc-2-compliance-in-cloud/) and how to implement them correctly in your AWS environment. \n\n### The requirements \n\nFirstly, the rules within SOC 2 are grouped by 5 TSC (Trust Service Criteria): \n\n1. Security \n2. Availability \n3. Processing Integrity \n4. Confidentiality \n5. Privacy \n\nSOC 2 has 64 mandatory trust service criteria, based on these which the company creates controls to achieve compliance. In this article, we will look at a few of the criteria required, how to implement them in your AWS environment and how to check if your implementation is complete. \n\n##### A checklist \n\n### Requires Additional Authentication or Credentials \n\nMFA (Multi-Factor Authentication) is a mechanism that adds additional steps to the authentication flow and requests supplementary credentials. These credentials can be: \n\n* What you know (for example: a password) \n* What you have (for example: a smart card) \n* What you are (for example: a fingerprint) \n\nTo fulfill this criteria, introduced under the “Security” section, you need to enable MFA when accessing the AWS Management Console. As a result, users will be prompted to enter their username and password (which is the first step, or the first factor of the authentication), and then an authentication code that is sent to their device. A biometrics-enabled device can be used instead as well. \n\nYou can configure MFA for IAM users or the AWS account root user. \n\nSteps to enable MFA in your AWS environment, according to the [documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable.html). \n\n6. Install an authenticator app on your MFA device, use a FIDO2 device or specialized hardware devices such as TOTP tokens. \n7. Enable the MFA device from the AWS Management Console (if using an authenticator app, you can also use AWS CLI or AWS API). \n\nIf your company is using an external identity provider, you have to ensure that MFA is configured for access to the AWS console. \n\n### Restricts Access \n\nThis criteria, in the “Security” TSC refers to restricting traffic to and from any cloud services and assets hosted in the cloud. This includes: \n\n* Closing unnecessarily open ports, \n* Requiring authenticated access to services such as FTP, SMB, and others. \n\nTo close an open port, follow these steps: \n\n1. Log in to the AWS Management Console. \n2. From the EC2 dashboard, on the left pane, click Security Groups. \n3. For each security group, click the Inbound Rules tab, and remove the rules that allow access to the ports you want to close. Repeat the same for the Outbound Rules. \n4. Remember to click save. \n\n### Implements Boundary Protection Systems \n\nThe third requirement we will analyze under the \"Security\" section of SOC refers to the usage of firewalls, DMZs (Demilitarized Zones), IDS, IPS, and others.  \n\nIt is recommended that you secure your cloud infrastructure by using these utilities in order to limit traffic as much as possible and only allow access to resources when necessary. \n\nTo quickly deploy a firewall: \n\n* Log in to the AWS Management Console, \n* Open the Amazon VPC console, create a firewall subnet, and update your VPC Route Tables. \n* Configure the firewall policy by accessing the Amazon VPC console navigation pane under Network Firewall. Choose Firewall policies and add any desired configurations. \n\n### Creates and Maintains Records of System Storage Activities \n\nThis criteria, located under the “Processing Integrity” criteria, checks if logging is implemented in your cloud environment.  \n\nBy logging all user activities, you can: \n\n* Observe [misconfigurations](https://cyscale.com/blog/common-cloud-misconfigurations-how-to-avoid-them/), \n* Identify any suspicious behavior, \n* Detect malicious attacks. \n\nTo enable logging in your AWS infrastructure, you can use Amazon CloudTrail. This solution tracks all actions performed in your cloud environment.  \n\nAmazon CloudTrail can be used together with Amazon CloudWatch to extend monitoring to applications and cloud assets and to analyze their health. \n\n**Amazon CloudTrail is enabled by default in your AWS account.** \n\n### Protects Encryption Keys \n\n[Encryption](https://cyscale.com/blog/types-of-encryption/) is essential to ensure confidentiality of data. In the “Confidentiality” section of SOC 2, we have criteria for both encryption and key management.  \n\nIf key management is neglected, then encryption becomes useless. Keys must be generated, stored, used and destroyed safely to protect your data. \n\nAmazon offers a complete solution for proper key management. AWS KMS (AWS Key Management System) helps you properly deal with all of the processes in a cryptographic key’s lifecycle. \n\nAccording to AWS, this service can be used:  \n\n* Through the AWS Management Console,  \n* Using the AWS KMS APIs. \n\n### Finally, check your implementations \n\nBesides the criteria presented in this article, there are many more. \n\nAlthough so many requirements can quickly become overwhelming, Cyscale can help you easily keep track of what you’ve correctly implemented and what requires your attention on our [SOC 2](https://cyscale.com/blog/soc-2-vs-ISO-27001-SaaS/) compliance page. \n\nMany technical controls in Cyscale can be mapped to SOC 2 criteria to provide visibility in your cloud environment and prove compliance. \n\nA few examples of controls that apply to the presented requirements (and more) are: \n\n* Ensure all users have MFA configured. \n* Ensure CloudTrail is enabled in all regions. \n* Ensure no security groups allow ingress from 0.0.0.0/0 to port 22 (SSH). \n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Cloud Queues Security Best Practices","seoTitle":"Cloud Queues Security Best Practices","description":"A queue is a data structure that allows you to store and retrieve data in efficiently. A message queue, in the context of the cloud, is a service used to temporarily store data before it is processed. Solutions offered by cloud vendors are: Amazon SQS, Azure Queue Storage and Cloud Tasks in Google Cloud. Best Practices for queues security are: encrypt the data that arrives, log every action, restrict access to queue management and ensure access control, configure a dead-letter queue, use private endpoints for your queues and configure a long retention period.","seoDescription":"A queue is a data structure that allows you to store and retrieve data in efficiently. A message queue, in the context of the cloud, is a service used to temporarily store data before it is processed. Solutions offered by cloud vendors are: Amazon SQS, Azure Queue Storage and Cloud Tasks in Google Cloud. Best Practices for queues security are: encrypt the data that arrives, log every action, restrict access to queue management and ensure access control, configure a dead-letter queue, use private endpoints for your queues and configure a long retention period.","date":"2022-10-07T06:51:22.269Z","featuredpost":true,"permalink":"cloud-queues-security-best-practices","featuredimage":{"publicURL":"/static/3e43f46e5da4cc8c0e95be4faaff9949/25_blog-queue-security-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/3e43f46e5da4cc8c0e95be4faaff9949/888e2/25_blog-queue-security-cover-photo.webp","srcSet":"/static/3e43f46e5da4cc8c0e95be4faaff9949/913d0/25_blog-queue-security-cover-photo.webp 205w,\n/static/3e43f46e5da4cc8c0e95be4faaff9949/91660/25_blog-queue-security-cover-photo.webp 410w,\n/static/3e43f46e5da4cc8c0e95be4faaff9949/888e2/25_blog-queue-security-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## What is a queue? \n\nA queue is a data structure that allows you to store and retrieve data in an efficient manner. A message queue, in the context of the cloud, is a service used to temporarily store data before it is processed.  \n\nA message queue's role is to act like a buffer; if a service is too busy processing data and would otherwise drop traffic, then that traffic is added to a queue for temporary storage. \n\nA message queue usually works based on the FIFO mechanism. FIFO (First In, First Out) allows easy retrieval of messages based on their order of arrival to ensure a smooth process. That means the messages are extracted from the queue in the order they arrive. \n\n## Cloud vendors and queues \n\nLet’s look at solutions offered by cloud vendors and understand how to secure queues used in the cloud infrastructure. \n\n### 1. Amazon Simple Queue Service (Amazon SQS) \n\nThis solution helps you manage distributed systems and asynchronous tasks by storing messages in a buffer and waiting until the system is ready to process them. A few of the benefits offered by Amazon through this service are: \n\n* Security, \n* Durability, \n* Availability,  \n* Scalability, and others. \n\n### 2. Azure Queue Storage \n\nAzure Queue Storage helps you store large volumes of messages that can be accessed using authenticated HTTP or HTTPS requests. This type of storage offered by Microsoft Azure is useful in managing asynchronous tasks and ensuring no data loss occurs. \n\n### 3. Cloud Tasks in Google Cloud \n\nCloud Tasks is a slightly different service than we've discussed so far; Google Cloud allows users to store asynchronous tasks in queues and easily manage them.  \n\nThis type of queue can be used as a task scheduling system since you can set a time when a task should be executed. \n\nHowever, even though the queues in Cloud Tasks are designed for tasks, message passing is a use case of the queues.  \n\nAnother solution, very similar to Cloud Tasks, is Pub/Sub. Pub/Sub is a message queueing system that functions on a predefined set of rules, where there is a set of Subscribers, who all receive the queued messages from the Publisher when an event occurs. \n\n## Queues in the Cloud - Best Practices \n\nWhen thinking about [data security in the cloud](https://cyscale.com/blog/cloud-data-security-guide/), we think of secure storage and assets protection. For this reason, it is very easy to overlook where your sensitive data might end up; and queues are one place. \n\n**Don’t leave queues out of your data security program**; secure every state of data and ensure that you don’t have any vulnerabilities in your cloud infrastructure.  \n\nLet’s look at best practices for securing queues in the cloud. \n\n### 1. Encrypt the data that arrives in queues. \n\n[Encryption](https://cyscale.com/blog/types-of-encryption/) is critical in data security; it ensures that your traffic is confidential. \n\nWhether you implement client-side encryption (which means encrypting the data before sending it) or server-side encryption (where the cloud vendor deals with the encryption process), you need to ensure you don't have information in plain text. \n\nBesides these options, you can also make sure that, after leaving the queue, your data is stored encrypted. For example, AWS S3 assets allow users to set default encryption for data that arrives, so new objects are always stored encrypted.  \n\n### 2. Log actions that affect queues. \n\nKeep details of requests made to the queue; whether they are successful or failed, ensure you keep track of what happens to queues. Important signals that can help you identify any irregularities in your queues' configuration are:  \n\n* Authentication attempts,  \n* Latency, \n* Queue depth (the number of messages waiting to be processed), \n* Request and response sizes, and others. \n\nWhy are these parameters important? For example, if your cloud infrastructure is under a DDoS attack, you can quickly identify that by looking at requests and their size; such attacks usually send either very large volumes of data often or big requests that are meant to slow down your system. \n\n### 3. Restrict access to queue management and ensure access control \n\nImplement [the Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/) and only allow a small group of users to change queue configurations. Following [recommendations offered by Google](https://cloud.google.com/tasks/docs/secure-queue-configuration), deploy specific roles like Queue Administrator and assign them only to users who require those roles. \n\nBesides management, you should also have in place good access control rules. For example, IAM (Identity and Access Management) policies that restrict unnecessary access should be implemented and applied to queues. \n\n### 4. Configure a dead-letter queue \n\nA dead-letter queue (DLQ) is a type of queue designed for messages that, for various reasons, cannot be stored in the queue and processed correctly. Some of the reasons why messages may end up in DLQs are: \n\n* The application in which the queue is used has logical errors, \n* The message length limit was exceeded, \n* The queue is full, and others. \n\nDead-letter queues are useful for debugging what went wrong with the messages’ processing. For example, using a DLQ, you can look at rejected messages and then redirect them to your main queues. \n\n### 5. Use private endpoints for your queues \n\nAlthough most cloud providers enable you to have storage assets (and queues) open to the internet, it is the safest to use private endpoints. \n\nThis can be done using a Private Link, which creates a private connection between the services in the cloud and the queue.  \n\nThis way, traffic does not unnecessarily reach the public internet, and a layer of security is added. \n\n### 6. Configure a good retention period \n\nThe retention period refers to how long messages are stored in the queue before they are deleted. **A longer retention period** is recommended to provide flexibility in your environment and allow some time between the moment a message is received and when it is processed. \n\nFor example, Amazon SQS lets you configure a retention period between 1 minute and 14 days. \n\n## Protect your data using Cyscale \n\nAfter understanding best practices regarding queue security, it’s time to ensure you’re implementing them.  \n\nYou can easily do this using Cyscale! We help you check if you have vulnerabilities in your cloud environment and quickly solve any findings to solidify [your cloud security posture](https://cyscale.com/blog/improve-cloud-security-posture/).  \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Cloud Data Security For AWS: An In-Depth Guide","seoTitle":"Cloud Data Security For AWS: An In-Depth Guide ","description":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","seoDescription":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","date":"2022-09-29T06:25:58.261Z","featuredpost":true,"permalink":"cloud-security-for-aws","featuredimage":{"publicURL":"/static/8439e84f30635c75021e87142b3bea7b/24_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp","srcSet":"/static/8439e84f30635c75021e87142b3bea7b/913d0/24_blog-cover-photo.webp 205w,\n/static/8439e84f30635c75021e87142b3bea7b/91660/24_blog-cover-photo.webp 410w,\n/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->  \n\nUnderstanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. \n\nIn this article, you will find a comprehensive guide that will help you understand possible misconfigurations in your AWS cloud infrastructure and how to remediate them.  \n\n## Steps to secure your cloud environment \n\n### 1. Data classification \n\n[Classifying your cloud data](https://cyscale.com/blog/data-classification/) can help you easily sort, retrieve, and prioritize it. This is done using a tag (sometimes called a label), which is applied to cloud storage assets. In this way, that data is placed into one or more categories and can be identified more easily. \n\nBenefits of data classification include: \n\n* Risk management, \n* Compliance,  \n* Security. \n\nIn AWS, tags are key-value pairs that add metadata to your data. \n\nThe AWS documentation recommends using a three-tiered approach, with the following tags: \n\n* Unclassified, \n* Official,  \n* Secret. \n\nHowever, users can tailor data classification to their needs and use their own tags. In addition, **tag policies** can be used to standardize their creation and ensure consistency across all assets. \n\nTo accomplish classification using tags in your AWS environment, you have the following options: \n\n* Using the Amazon console, at resource level, where tags can be added either at creation or after, \n* Programmatically, using the Amazon API, AWS CLI, or AWS SDK. \n\nAccording to the AWS documentation, restrictions regarding tags include: \n\n* There cannot be more than 50 tags per resource, \n* Each tag key must be unique for each resource, \n* The maximum key length is 128 Unicode characters in UTF-8, \n* The maximum value length is 256 Unicode characters in UTF-8. \n\n### 2. Encryption \n\nEncryption is the process of altering data in order to hide its content and ensure confidentiality because entities that do not have the decryption key cannot decrypt the data and, therefore, cannot read its content. \n\nThe two types of encryption mechanisms are: \n\n* **Symmetric encryption**, where the encryption and the decryption key are the same, and \n* **Asymmetric encryption**, where the two keys are different; one is called public key and the other private key. \n\nEncryption can be done in all three states of data: \n\n* [At rest,](https://cyscale.com/blog/protecting-data-at-rest/) \n* In transit, \n* In use. \n\nIn this article, we will discuss data encryption in the first two states, but [a more detailed article](https://cyscale.com/blog/types-of-encryption/) regarding encryption also describes encryption in the last state of data. \n\nFor data in transit, AWS provides the following solution: \n\n1. Encrypt the data using SSL/TLS. TLS (Transport Layer Security) and SSL (Secure Sockets Layer) are transport layer protocols that protect the data in transit. TLS is a newer and improved version of SSL. \n2. Perform client-side encryption. This solution requires the user to encrypt the data before uploading it to the cloud, but it is more difficult since the client has to deal with the encryption process, key management, and other services. \n\nFor data at rest, AWS provides encryption for the following services:  \n\n* Amazon EBS,  \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift,  \n* AWS Lambda, and many others. \n\nAWS uses the 256-bit Advanced Encryption Standard (AES-256) encryption algorithm, an industry-recommended standard and one of the strongest algorithms for symmetric encryption. \n\nKey management is also a very important element of data encryption. If your keys are not stored safely, then no matter how strong the encryption algorithm is, a malicious party may be able to read your data. \n\nA few best practices regarding encryption keys are: \n\n* Do not store your keys in the same place as your data or in the source code, \n* Rotate and retire keys regularly to minimize the impact of a breach, \n* Manage key deletion, \n* Use Cryptographically Secure Random Number Generators (CSRNGs) to generate your keys. \n\nAWS KMS (AWS Key Management System) is a comprehensive solution that helps users deal with all the trouble that comes with cryptographic keys. \n\nAWS KMS helps you: \n\n* Create cryptographic keys, \n* Define policies and control how the keys are used, \n* Audit the keys usage to ensure they are used legitimately. \n\nAccording to AWS, this service can be used: \n\n1. Through the AWS Management Console, \n2. Using the AWS KMS APIs. \n\n### 3. Access control \n\nRegulating access control is an essential step to your [cloud data security](https://cyscale.com/blog/cloud-data-security-guide/) program.  \n\nTo manage access control in AWS, you can use policies, which can be assigned at the following levels: \n\n* Users, \n* Groups of users, \n* Roles, \n* Resources. \n\nPolicies define permissions. To correctly implement them, use the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/) to only allow access rights to the necessary users for the minimum amount of time possible.  \n\nLet’s look at an example where a policy is applied to a resource.  \n\nAn AWS S3 bucket is a type of asset used to store object-like data such as files, databases, and other unstructured data. \n\nA bucket policy contains rules based on which access is allowed or denied and is written in JSON.  \n\n```jsonld\n{\n    \"Version\": \"2012-10-17\",\n    \"Id\": \"S3PolicyId1\",\n    \"Statement\": [\n        {\n            \"Sid\": \"IPAllow\",\n            \"Effect\": \"Deny\",\n            \"Principal\": \"*\",\n            \"Action\": \"s3:*\",\n            \"Resource\": [\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET\",\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET/*\"\n            ],\n            \"Condition\": {\n                \"NotIpAddress\": {\n                    \"aws:SourceIp\": \"54.240.143.0/24\"\n                }\n            }\n        }\n    ]\n}\n```\n\n*Policy source – docs.aws.amazon.com* \n\nAnalyzing the image above, we understand that the policy is applied to a bucket resource, the rule for the permission is “Deny”, and the result of the bucket policy is denying access to the objects stored in the specified bucket unless the requests are made with source IPs in the subnet 54.240.143.0/24. \n\n### 4. Data loss prevention \n\nData loss prevention (DLP) is a protection mechanism for sensitive data that ensures that no unintentional or malicious disclosures occur. DLP prevents data breaches by ensuring no confidential data is accidentally leaked, lost, or stolen. \n\n**Amazon Macie** is a data security and privacy service that protects users’ sensitive data using machine learning technologies and pattern matching. \n\nThis tool identifies sensitive data using **sensitive data discovery jobs**, which analyze S3 buckets. Sensitive data discovery jobs use pre-defined or user-defined lists (or a combination of both) to single out confidential data by matching patterns to the lists. \n\nA passport number is an example of sensitive data that Amazon Macie could match. This is because it has a set number of digits, some corresponding to the owner's region or country. \n\nAfter identifying sensitive data, Amazon Macie can: \n\n* use IAM policies to filter traffic to it,  \n* encrypt and decrypt data,  \n* perform logging and monitoring through AWS CloudTrail integration, and others.  \n\n### 5. Availability \n\nAvailability means that users should be able to access their data without disruptions at any point. \n\nA solution for availability in the cloud is **availability zones**. \n\nAn availability zone is a geographical area where groups of data centers are located. These data centers contain replicated data and provide redundancy regarding electrical power, networking, and connectivity. \n\nAn AWS region contains multiple AWS availability zones, all within 100km of each other, which are independent and provide redundancy. \n\nSome AWS regions around the globe are: \n\n* North America,  \n* South America, \n* Europe,  \n* China,  \n* South Africa, and others. \n\nThese regions provide high availability. \n\nAnother solution for availability is DDoS Protection. DDoS (Distributed Denial of Service) attacks are attempts to bring down a service or a resource by sending a large amount of traffic to them using controlled machines. \n\nAWS Shield is the AWS DDoS Protection service that protects applications hosted in the cloud. \n\nAWS Shield has two tiers: \n\n* Standard, \n* Advanced. \n\nBesides the features that come with the Standard plan, which are at network and transport layer, the Advanced tier of AWS Shield provides: \n\n* integration with AWS WAF (Web Application Firewall), \n* real-time visibility into attacks,  \n* additional detection and mitigation of sophisticated DDOS attacks, and others. \n\n## Secure your cloud environment \n\nAfter understanding the security demands required for the cloud, implementing them seems like a daunting task. However, using Cyscale, you can easily check if you’re lacking any of the mentioned implementations and remediate any findings. \n\nCyscale has over 400 controls that cover a large variety of misconfigurations and vulnerabilities and offer support not only for AWS, but for Azure, Google Cloud, Alibaba Cloud as well. \n\n\n\nEnhance your AWS cloud data security with our [Cloud Security Platform](https://cyscale.com/) to automate the contextual analysis of misconfigurations, vulnerabilities, access, and data for an accurate risk assessment. With over 400 controls, we ensure optimal [AWS security compliance](https://cyscale.com/use-cases/aws-cloud-security/).\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Understanding S3 Bucket Security – A Contextual Approach","seoTitle":"Understanding S3 Bucket Security – A Contextual Approach","description":"An Amazon S3 bucket is a storage cloud asset that acts as a container for data stored in the public cloud. Buckets are object storage services and are similar to folders; this type of storage is flexible and scalable and is ideal for large files and unstructured data. To secure a bucket, restrict public access to it, perform at rest and in transit encryption, log user actions, and perform regular backups.","seoDescription":"An Amazon S3 bucket is a storage cloud asset that acts as a container for data stored in the public cloud. Buckets are object storage services and are similar to folders; this type of storage is flexible and scalable and is ideal for large files and unstructured data. To secure a bucket, restrict public access to it, perform at rest and in transit encryption, log user actions, and perform regular backups.","date":"2022-09-16T08:07:20.546Z","featuredpost":true,"permalink":"s3-bucket-security","featuredimage":{"publicURL":"/static/de7396bc58775c924174c3c9f2467bbe/23_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/de7396bc58775c924174c3c9f2467bbe/888e2/23_blog-cover-photo.webp","srcSet":"/static/de7396bc58775c924174c3c9f2467bbe/913d0/23_blog-cover-photo.webp 205w,\n/static/de7396bc58775c924174c3c9f2467bbe/91660/23_blog-cover-photo.webp 410w,\n/static/de7396bc58775c924174c3c9f2467bbe/888e2/23_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->  \n\nIn 2017, 4 million records with customer information, login credentials, and source code were made publicly available due to 2 unsecured AWS S3 storage buckets owned by Time Warner Cable. \n\nThe consequences of this attack were disastrous, and this event showed the entire cloud industry how important security is. \n\n\n\nIn this article, we will learn more about Amazon S3 buckets, misconfigurations and vulnerabilities, and how to secure them.\n\n## What is an Amazon S3 bucket?  \n\nAn Amazon S3 bucket is a storage cloud asset that acts as a container for data stored in the public cloud. Buckets are object storage services and are similar to folders; this type of storage is flexible and scalable and is ideal for large files and unstructured data. \n\n## Common S3 Bucket Misconfigurations \n\n### 1. Public access to a bucket is allowed. \n\nSometimes, Amazon S3 buckets are required to be publicly accessible. For example, this use case occurs when the owner intends to make data accessible to the internet.  \n\nHowever, breaches occur when a bucket that has sensitive information such [as PII (Personal Identifiable Information)](https://cyscale.com/blog/protecting-pii-in-the-cloud/) allows: \n\n* Public “READ” access, \n* Public “WRITE” access.  \n\nYou can grant and deny access to a bucket using **access lists** and **bucket policies**.  \n\nAn access control list (ACL) is a set of rules that limit access to buckets through permissions. It defines an account's access level over a bucket (for example, READ or WRITE).  \n\nA bucket policy also contains rules based on which access is allowed or denied, but it is a more modern solution because it can enable more complex filtering. It is a JSON-based access policy language. \n\nAmazon recommends that you no longer use ACLs beside special cases, in which you need to filter access to objects individually.  \n\n### 2. No at rest encryption is performed. \n\n[Data at rest](https://cyscale.com/blog/protecting-data-at-rest/) should always be encrypted to ensure confidentiality and improve your cloud data security.  \n\nPerforming encryption on the objects inside a bucket ensures that, even if a malicious entity gains access to your data, they cannot read it.  \n\nAWS provides multiple encryption options to protect data at rest. For example, you can enable default encryption and set it, so it automatically encrypts any new objects added to the bucket.  \n\nEncryption should be done using industry-recommended algorithms and strong cryptographic keys. A strong encryption algorithm is AES-256 (Advanced Encryption Standard with a key of 256 bits). \n\n### 3. In transit encryption is not enabled. \n\nBesides the data that is already stored, you should also encrypt the data that travels to and from the S3 bucket.  \n\nThis step prevents eavesdropping attacks. It is not enough to store your data encrypted. Your efforts are wasted if it travels in plain text and attackers can read it. \n\nData in motion can be encrypted using SSL/TLS. TLS (Transport Layer Security) and SSL (Secure Sockets Layer) are transport layer protocols that protect the data in transit. TLS is a newer and improved version of SSL. \n\nAnother solution for in motion encryption is preparing the data that is to be transported by encrypting it on the client-side. \n\n### 4. Logging is disabled. \n\nLogging an S3 bucket is an essential step in securing your data. With logging, you can record actions taken by users, keep log files for compliance purposes and understand what roles have permission to access data inside a bucket. \n\nThere are two solutions for AWS bucket logging: \n\n* Server access logging, and \n* AWS CloudTrail. \n\nWith server access logging, you obtain detailed records regarding requests that are made to a bucket. \n\nAWS CloudTrail is a comprehensive service that tracks user activity and API calls. It can be used to keep a record of who sends requests to a bucket.  \n\nIt is important to keep in mind that AWS CloudTrail does not log failed authentication attempts through incorrect credentials. However, it does track requests made by anonymous or unauthorized users. \n\n### 5. No regular backups are performed \n\nAttackers may not only try to steal your sensitive data, but they can also delete it. Therefore, ensuring regular and consistent backups is essential to configuring your buckets and providing availability. \n\nUsing AWS Backup, you can perform S3 bucket backups. Amazon supports the following types of backups: \n\n* **Continuous backups**, which allow data restoration from any moment in the last 35 days, \n* **Periodic backups**, which can be performed every 1 hour, 12 hours, or less often. \n\nAn important feature of AWS Backup is that [tags](https://cyscale.com/blog/data-classification/), access control lists, and other metadata are also saved along with your data. \n\nAn additional layer of security can be added by using the MFA delete feature in AWS. This option requires a successful MFA before allowing a user to delete an object or bucket. \n\nMoreover, you can keep multiple versions of an object inside a bucket. This process is called versioning and can be used to recover objects from accidental deletion. \n\n## Do you have a complete cloud security program? \n\nIn this article, we’ve discussed many possible misconfigurations, along with best practices. However, in order to fully understand your public cloud infrastructure and find vulnerabilities, you need to have good visibility over your cloud environment.  \n\nUsing a new feature in Cyscale, the bucket graph, you can put in context all of your knowledge and grasp a better understanding of your infrastructure. \n\nBelow, you can see an example of a bucket graph. \n\n![Bucket Graph in Cyscale](/img/23_blog-graph-bucket.webp#shadow \"Bucket Graph in Cyscale\")\n\nAlthough the bucket (shown on the right) has only two IAM policies attached, we can see that these have a significant impact on the infrastructure: the AmazonS3FullAccess policy gives full access rights to a specific user and to a VM that can assume an associated IAMRole.  \n\nIn addition, there's a lambda function that has a role which gives it permissions to perform actions on the bucket \n\nWithout context, we would not be able to understand a policy's impact and the associated risk. \n\nMoreover, the icon on the right shows us that the bucket violates three policies. Cyscale users can click on the icon and obtain more details regarding this alert. \n\nThis feature helps you quickly understand and fix any misconfigurations and vulnerabilities introduced in the cloud environment due to the bucket’s settings. \n\n  \n\nBesides the graph, you can also use controls to check your cloud configurations easily. Find any gaps in your buckets' configurations using Cyscale controls! Here are a few examples that can help you instantly check the most common misconfigurations regarding S3 buckets: \n\n* *Ensure S3 bucket ACL grants permissions only to specific AWS accounts* \n* *Ensure all S3 buckets employ encryption-at-rest* \n* *Ensure a log metric filter and alarm exist for S3 bucket policy changes* \n* *Ensure that there are no publicly accessible objects in storage buckets* \n\n \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"HIPAA Compliance in the Cloud ","seoTitle":"HIPAA Compliance in the Cloud ","description":"The Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a United States federal law that defines rules regarding medical records and individuals’ personal health information (PHI). There are three rules that define how PHI should be stored, accessed, and managed: the privacy rule, the security rule, and the breach notification rule. Use Cyscale to achieve compliance with HIPAA and other international standards. \n","seoDescription":"The Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a United States federal law that defines rules regarding medical records and individuals’ personal health information (PHI). There are three rules that define how PHI should be stored, accessed, and managed: the privacy rule, the security rule, and the breach notification rule. Use Cyscale to achieve compliance with HIPAA and other international standards. ","date":"2022-09-12T06:38:29.851Z","featuredpost":true,"permalink":"hipaa-compliance-in-cloud","featuredimage":{"publicURL":"/static/a5a74cb3a5c0bbe6245522ebcb01ed03/22_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/a5a74cb3a5c0bbe6245522ebcb01ed03/888e2/22_blog-cover-photo.webp","srcSet":"/static/a5a74cb3a5c0bbe6245522ebcb01ed03/913d0/22_blog-cover-photo.webp 205w,\n/static/a5a74cb3a5c0bbe6245522ebcb01ed03/91660/22_blog-cover-photo.webp 410w,\n/static/a5a74cb3a5c0bbe6245522ebcb01ed03/888e2/22_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nThe Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a United States federal law that defines rules regarding medical records and individuals’ personal health information (PHI). \n\nSome examples of PHI are: \n\n* Some of the [PII](https://cyscale.com/blog/protecting-pii-in-the-cloud/), such as name, address, date of birth, \n* Physical and mental health information of an individual,  \n* The medical care an individual has received, \n* Payment information of a patient. \n\nWhen referring to the HIPAA compliance section, we can find three rules that define how PHI should be stored, accessed, and managed. According to the [Medicare Learning Network](https://www.cms.gov/Outreach-and-Education/Medicare-Learning-Network-MLN/MLNProducts/Downloads/HIPAAPrivacyandSecurity.pdf), the three rules are: \n\n* The Privacy Rule, \n* The Security Rule, \n* The Breach Notification Rule. \n\nWe will look at each in detail to understand how compliance with HIPAA can be achieved in the cloud. \n\n## The Privacy Rule \n\nThe Privacy Rule contains standards that regulate the usage and disclosure of PHI. This section of HIPAA includes a wide range of rules that protect an individual's rights to: \n\n* Access and obtain digital copies of their medical records, \n* Request corrections regarding their medical records, \n* Restrict access to some of their information. \n\nThe Privacy Rule also contains instructions for the medical provider. A medical professional must: \n\n1. Keep PHI secure and disable access to it unless the person requesting access is authorized to access it, \n2. Inform patients about their privacy rights and others. \n\n## The Security Rule \n\nThis rule refers to electronic PHI (ePHI). It requires that ePHI data is stored, accessed, and transferred under the three cybersecurity principles: \n\n1. Confidentiality,  \n2. Availability, \n3. Integrity. \n\nLet’s understand what these three principles require: \n\n* **Confidentiality**: Make sure no unauthorized individual can access or read the ePHI. \n* **Availability**: Authorized persons should be able at all times to access the ePHI, as needed. \n* **Integrity**: ePHI should not be altered or deleted by unauthorized entities. \n\n## The Breach Notification Rule \n\nThe third rule in HIPAA refers to how a medical professional should respond to a PHI breach.  \n\nThe parties that should always be notified of a breach are: \n\n* The affected individual or individuals, and \n* The United States Department of Health and Human Services (HHS). \n\n## Consequences of HIPAA violations \n\nSince HIPAA is a federal law, there are two types of penalties that can be applied: \n\n* Financial penalties, \n* Criminal penalties. \n\nThese repercussions depend on the gravity of the violation. According to [HIPAA Answers](https://www.hipaanswers.com/hipaa-violation-penalties/), there are four violation categories: \n\n1. A violation that was not known and could not have been realistically avoided. \n2. A violation that the responsible parties should have been aware of but could not have been avoided. \n3. A violation due to negligence, where correction attempts were made to correct it. \n4. A violation due to negligence, with no attempts made to correct it. \n\nThe **financial penalties** are also split into four categories: \n\n1. Minimum fine of $128 per violation up to $63,973, \n2. Minimum fine of $1,280 per violation up to $63,973, \n3. Minimum fine of $12,794 per violation up to $63,973, \n4. Minimum fine of $63,973 per violation up to $1,919,173. \n\n**Criminal penalties** are divided into three categories: \n\n* For reasonable cause or no knowledge of the violation: up to one year in jail, \n* For obtaining PHI under false pretenses: up to five years in jail, \n* For obtaining PHI for personal gain or malicious attempt: up to ten years in jail. \n\n## HIPAA Compliance in the Cloud: A Checklist \n\nAfter we've understood the importance of compliance with HIPAA, let's see the requirements that need to be fulfilled. They are grouped into three categories: \n\n* Technical Safeguards, \n* Administrative Safeguards, \n* Physical Safeguards.  \n\nLet’s look at them more in detail and understand how Cyscale can help you become compliant with HIPAA. \n\n### 1. Technical Safeguards \n\nTechnical Safeguards are split into four categories. We will also show you examples of controls in Cyscale to help you understand how easy it is to implement them and streamline the process of becoming compliant. \n\n* Access control – only authorized entities should access ePHI. \n* Audit control – access to ePHI should be recorded and examined. \n* Integrity – ePHI should not be altered or destroyed by unauthorized individuals. \n* Transmission security – ePHI should be safely transmitted over the network. \n\nExamples of controls for some of these safeguards are: \n\n* **Access control:** *Ensure network access rule for storage bucket is not set to publicly accessible* for Alibaba Cloud. \n* **Audit control:** *Ensure that Object-level logging for write events is enabled for S3 bucket* for AWS. \n* **Transmission security:** *Ensure 'Enforce SSL connection' is set to 'ENABLED' for MySQL Database Server* for Azure. \n\n### 2. Administrative Safeguards \n\n* **Security Management Process** – analyze potential risks and take protective measures, \n* **Security Personnel** – a security officer should be responsible for security policies and procedures, \n* **Information Access Management** – limit access to PHI to [the minimum necessary](https://cyscale.com/blog/check-for-least-privilege/), \n* **Workforce Training and Management** – employees should receive training in PHI management and be supervised, \n* **Evaluation** – a periodic assessment of security policies should be performed. \n\nTwo examples of controls for the “Information Access Management” Safeguard are: \n\n* *Ensure IAM policies that allow full \"\\*:\\*\" administrative privileges are not created* for AWS \n* *Eliminate use of the \"root\" user for administrative and daily tasks* for AWS \n\n### 3. Physical Safeguards \n\n* **Facility Access and Control** – access to a covered entity's facilities should be limited to authorized personnel, \n* **Workstation and Device Security** – policies and procedures should be implemented to regulate the usage and access to workstations and devices.  \n\nUse Cyscale to achieve compliance with HIPAA and other international standards. \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"A Guide to Cloud Security Best Practices","seoTitle":"A Guide to Cloud Security Best Practices","description":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","seoDescription":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","date":"2022-09-01T10:59:21.743Z","featuredpost":true,"permalink":"cloud-data-security-guide","featuredimage":{"publicURL":"/static/ede7e98a6093188a6e7edee54d1956fd/21-cover-01-min.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp","srcSet":"/static/ede7e98a6093188a6e7edee54d1956fd/913d0/21-cover-01-min.webp 205w,\n/static/ede7e98a6093188a6e7edee54d1956fd/91660/21-cover-01-min.webp 410w,\n/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"Data security is one of the biggest concerns of cloud-based organizations. When you think about protecting data, you need to make sure you’re providing the following features:\n\n* Confidentiality,\n* Integrity,\n* Availability.\n\nMoreover, these three security principles need to be implemented for all three states of data, which are:\n\n* In motion,\n* In use,\n* At rest.\n\nThis mission may seem daunting. Let’s break it down and understand every step of the process of securing data. In this article, you will find out:\n\n* The type of attacks that threaten your data,\n* Cloud security best practices,\n* Security solutions on the market from cloud service providers,\n* How to identify any gaps in your security policies.\n\n## **How do you ensure confidentiality?**\n\nConfidentiality is a security principle that states that only authorized users should be able to access the data. It should not be visible to unauthorized entities.\n\n### **Encryption**\n\n[Encryption](https://cyscale.com/blog/types-of-encryption/) is the process of scrambling data to obtain unreadable ciphertext. The algorithm uses a key to encrypt it, and if you are not in possession of the decryption key, you cannot reverse it back to its original state.\n\nEncryption solutions for the three states of data are: \n\n* For in motion data: SSL/TLS. They are transport protocols that encrypt data in transit. \n* For in use data: memory encryption, called Secure Encrypted Virtualization (SEV). It requires specialized hardware, and it encrypts RAM memory. \n* [For at rest data:](https://cyscale.com/blog/protecting-data-at-rest/) industry-recommended symmetric algorithms such as AES-256 are used to perform full disk, database, file system, and cloud assets encryption and to safely store data. \n\nUsing these best practices, you can improve your cloud security posture and prevent data breaches or other security incidents.\n\n### **Access control** \n\nA layered approach should be used when securing data in the cloud. This is where a robust **[cloud infrastructure security](https://cyscale.com/blog/cloud-infrastructure-security/)** becomes crucial. This means that encryption of data at rest should only be considered as the last measure of protection if access control rules are bypassed. \n\nYou must secure access to databases, buckets, and other storage assets by restricting it as much as possible. In doing this, you become compliant with the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/). \n\nA few access control best practices for [database protection](https://cyscale.com/blog/best-practices-for-securing-databases/) are:\n\n* Filter inbound and outbound traffic,\n* Secure your database connection,\n* Keep your connection details secret.\n\nFor [buckets that contain sensitive information](https://cyscale.com/blog/common-cloud-misconfigurations-how-to-avoid-them/#storage-access), do not allow public read/write access and use access control lists to define granular rules.\n\nBesides access control, to ensure robust data protection, strong authentication mechanisms should be put in place. Multi-factor authentication (MFA) is a must-have security measure for cloud computing environments.\n\nBy implementing these IAM (Identity and Access Management) best practices, attack surface is reduced and your cloud infrastructure is secured.\n\n### **Data classification**\n\nClassifying data does not protect it on its own. However, this process can help you understand which is the most sensitive data in order to better focus your efforts to secure it.\n\nAWS (Amazon Web Services), Azure, and Google Cloud provide labels or tags for users to implement [data classification](https://cyscale.com/blog/data-classification/). Labels/tags can be predefined by the public cloud vendor or can be user-defined according to the user’s specific needs.\n\n## **How do you ensure integrity?**\n\nEnsuring integrity means that data must not be altered in transit or at rest. Integrity is usually accomplished using hashes and checksums.\n\nThey are computed before the data is used or transferred and then again after. If the two values of hashes/checksums match, then the data was not altered in transit or at rest. Otherwise, that data was tampered with.\n\nLet’s look at public cloud vendors and how they provide data integrity services:\n\n* AWS S3 uses CRC32, CRC32C, SHA-1, and SHA-256 to check the data integrity after uploading/downloading,\n* Google Cloud also uses CRC32C checksums to verify data integrity.\n\n## **How do you ensure availability?**\n\nData availability means that any user should be able at any point to access their data without disruptions.\n\nFor data in the public cloud, vendors provide solutions to replicate and backup it in different data centers and regions.\n\nWe need to look at **availability zones** to understand availability in the cloud.\n\nAvailability zones are groups of data centers in the same region containing replicated data. If a data center fails, the other data center in the availability zone takes the responsibility, providing fault tolerance and increased availability and preventing data loss.\n\nMoreover, public cloud vendors support region pairs. A region is paired with another region at a great distance (for example, at least 300km away for Azure). If a natural disaster, civil unrest, or any other unforeseen events occur, the secondary region becomes the main source of cloud service.\n\nAnother service available in the public cloud that helps ensure availability is **DDOS protection**.\n\nDDOS (Distributed Denial of Service) is an attack designed to crash an application or a service by sending substantial amounts of traffic to it.\n\nA few examples of available DDOS services to secure cloud infrastructure are:\n\n* AWS Shield,\n* Azure DDOS Protection,\n* Google Cloud Armor.\n\n**Implementing our recommendations**\n\nEnsuring [multi-cloud data security](https://cyscale.com/use-cases/cloud-data-security/) is not an easy task. There are many aspects to be considered, and a small mistake can leave a vulnerability in your cloud environment.\n\nCyscale provides powerful dashboards to ensure visibility of your assets, the identities in your cloud, and an overview of your data security.\n\nMoreover, 400+ security controls ensure that your security teams have implemented the cybersecurity principles and [best practices](https://cyscale.com/blog/5-cspm-best-practices-and-strategies/). Here are some examples of controls that can be used to ensure data security:\n\n* **In motion data encryption**: *Ensure web app is using the latest version of TLS encryption* for Microsoft Azure\n* **At rest data encryption**: *Ensure VM disks for critical VMs are encrypted with Customer*-Supplied Encryption Keys (CSEK) for Google Cloud\n* **Access control**: *Ensure S3 bucket policy does not grant Allow permission to everyone* for AWS\n* **Data classification**: *Ensure Kubernetes Clusters are configured with Labels* for Google Cloud\n* **DDOS Protection**: *Ensure Anti-DDoS access and security log service is enabled* for Alibaba Cloud"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Best Practices for Securing Databases in the Cloud ","seoTitle":"Best Practices for Securing Databases in the Cloud ","description":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","seoDescription":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","date":"2022-08-26T07:19:11.434Z","featuredpost":true,"permalink":"best-practices-for-securing-databases","featuredimage":{"publicURL":"/static/79c9688bfcbf26210f6ca16250401cb0/20_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp","srcSet":"/static/79c9688bfcbf26210f6ca16250401cb0/913d0/20_blog-cover-photo.webp 205w,\n/static/79c9688bfcbf26210f6ca16250401cb0/91660/20_blog-cover-photo.webp 410w,\n/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nA database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  \n\nWhen we’re discussing databases in the cloud, there are two options for users. They can: \n\n* manage their own database in the cloud, or \n* use a service provided by their cloud vendor. \n\nThe latter is usually the easier choice since the cloud vendor takes care of security features.  \n\nHowever, your database may be vulnerable in both cases if you don’t configure your environment correctly. \n\nIn this article, we will look at best practices for securing databases in the cloud and how to identify any misconfigurations and vulnerabilities that may exist or appear in the future. \n\n## Best practices \n\n### 1. Filter inbound and outbound traffic. \n\nManaging traffic to and from the database is the first layer of database protection. Place databases behind firewalls and restrict the traffic allowed to reach them as much as possible. \n\nYou can implement more granular rules by only allowing a list of known IPs to connect to a database (for example, the range of addresses specific to a known data center), or by filtering traffic based on other criteria. \n\nMoreover, you can apply conditional access for users when administering the database. You can ask for additional security checks like Multi-Factor Authentication to ensure the entities managing the database are legitimate. \n\n### 2. Ensure availability through redundancy \n\nWhen deploying a database in the public cloud, you have the option to ensure availability through redundancy. You can replicate a database in different data centers and even different geographical regions. \n\nIf one data center or region fails, you can rely on a replication of the database located in a different data center to work. \n\n### 3. Encrypt your database \n\nDatabase [encryption](https://cyscale.com/blog/protecting-data-at-rest/) is important for protecting your data at rest.  \n\nEnsure that only authorized entities can see the data you’re storing in the database by [encrypting it ](https://cyscale.com/blog/protecting-data-at-rest/)with a strong, recommended algorithm such as AES-256. Keep your encryption keys safe by storing them separately from the data, use strong generation algorithms and rotate them every 90 days or less. \n\n### 4. Secure your database connection \n\nNot only data at rest is vulnerable. When you're transferring data to and from the database, it is essential to encrypt your traffic.  \n\nThis is called encryption for data in transit and is implemented with the TLS/SSL protocols. \n\n### 5. Keep your connection details secret \n\nDo not disclose database connection strings, keys, certificates, and other secrets that may be used to breach your database. You can use cloud solutions to keep your cryptographic secrets safe: \n\n* [Azure](https://cyscale.com/use-cases/azure-cloud-security/) Key Vault, \n* [AWS ](https://cyscale.com/use-cases/aws-cloud-security/)Key Management Service (AWS KMS), \n* [Google Cloud ](https://cyscale.com/use-cases/gcp-cloud-security/)Secret Manager, \n* dedicated hardware devices such as Hardware Security Modules (HSM), and others. \n\n### 6. Log connection attempts \n\nKeep track of who is trying to connect to your database by logging any authentication attempts. In this way, you can see if: \n\n* someone unauthorized is trying to or is connecting to the database, \n* there is a brute-force attack taking place.  \n\n### 7. Perform regular database backups \n\nDatabases should be backed up regularly, to prevent loss of data, in the case of: \n\n* Data corruption, and \n* Ransomware attacks. \n\nAlthough ransomware attacks are less common in cloud environments at the moment, attackers could in time develop the proper tactics. \n\n![RPO and RTO](/img/20_blog-rpo-and-rto.webp#shadow \"RPO and RTO\")\n\nThe time between the backups is known as RPO (Recovery Point Objective). It is measured as the time that passed between the last backup and the current one. If a disaster appears, the data written in that time is lost. \n\nRTO (Recovery Time Objective) is the time it takes for an application to go back online after a disaster and to restore its data.   \n\nRTO and RPO should be kept in acceptable limits. \n\n \n\nIt is difficult to ensure you’re implementing all the best practices we mentioned in this article. [Cyscale ](https://cyscale.com/)has over 400 controls that can help you secure your entire cloud environment. \n\nHere are some examples of controls that check for any misconfigurations and vulnerabilities regarding your database setup in the public cloud: \n\n* *Ensure encrypted storage is used for VMs that might host a database* for AWS \n* *Ensure no SQL Databases allow ingress 0.0.0.0/0 (ANY IP)* for Microsoft Azure \n* *Ensure that Cloud SQL database instances are configured with automated backups* for Google Cloud \n* *Ensure that Cloud SQL database instances require all incoming connections to use SSL* for Google Cloud \n* *Ensure parameter 'log_connections' is set to 'ON' for PostgreSQL Database* for Alibaba Cloud \n\nAlong with these controls that alert you on any findings, you receive remediation steps to quickly eliminate any vulnerabilities and secure your database in the cloud. \n\n \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Protecting Data at Rest Using Encryption  ","seoTitle":"Protecting Data at Rest Using Encryption  ","description":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.\n\n","seoDescription":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.","date":"2022-08-20T07:06:54.032Z","featuredpost":true,"permalink":"protecting-data-at-rest","featuredimage":{"publicURL":"/static/4c004ae5409e8873ac3b77d3e3668417/19_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp","srcSet":"/static/4c004ae5409e8873ac3b77d3e3668417/913d0/19_blog-cover-photo.webp 205w,\n/static/4c004ae5409e8873ac3b77d3e3668417/91660/19_blog-cover-photo.webp 410w,\n/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nData at rest is data that is not currently used or transmitted between computer systems.  \n\nThis state of data is usually the most sought-for by attackers. Data at rest can be stored in: \n\n* Storage cloud assets such as buckets, \n* Databases, \n* Files, and others. \n\nThe most common method of protecting data at rest is through [encryption](https://cyscale.com/blog/types-of-encryption/). In this article, we will look at ways to perform encryption and understand its importance. \n\n## Why is it important to encrypt data at rest? \n\nThere are three main risks regarding data at rest: \n\n* loss,  \n* leakage,  \n* theft. \n\nIn all three cases, your data at rest will probably end up in somebody’s hands. You can forget your USB drive in a coffee shop, you can accidentally disclose your data to someone else or the public or it can be stolen by a malicious attacker. \n\nFor these reasons, a safeguarding mechanism is encrypting your data. \n\nWith this method, even if someone else gets ahold of your data, they will not be able to read it. \n\n## Client-side and server-side encryption \n\nClient-side encryption is done on a local device with the user's key. \n\nServer-side encryption is implemented in the cloud, and the cloud vendor usually takes care of the key. This method of encryption is easier to use, since the cloud provider takes care of the algorithm, the key management system, and other troubles you may have. \n\nIn this article, we will look at best practices for client-side encryption, as well as solutions offered for server-side encryption.  \n\n## How do you encrypt data at rest? \n\nThere are a few best practices that need to be considered when undergoing the encryption process: \n\n### 1. Use an industry-recommended standard with an appropriate key length. \n\nFor data at rest, symmetric encryption algorithms are usually used. An industry-recommended standard is AES-256 (Advanced Encryption Standard with a key of 256 bits). \n\n### 2. Classify data and decide what to encrypt. \n\nMake sure you don’t leave any sensitive data unencrypted. Use [data classification](https://cyscale.com/blog/data-classification/) to decide what data should be encrypted.  \n\nAlternatively, perform full disk encryption to protect all data, especially in case you lose the hardware. \n\n## Key management \n\nNow that we’ve established how to encrypt data at rest, let’s talk keys.  \n\nIf your key management is poor, no matter how strong and well-done an encryption is, it can become totally useless. \n\nFollow the best practices we’re recommending to ensure textbook key management.  \n\n### 1. Use a random key generation algorithm for your keys.  \n\nMost random number generator algorithms are not truly random; they are called Pseudo-Random Number Generators (PRNGs).  \n\nIf you’re using programmatic functions such as random() or rand() from C++, Java, and other languages, you’re not generating random keys; they use a seed (which always gives the same result), can be predicted, and are not for cryptographic usage. \n\nFor this reason, you need to use tools that utilize Cryptographically Secure Random Number Generators (CSRNGs). \n\nTo generate a random, secure key, you can use: \n\n* [GenerateRandom](https://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateRandom.html), a tool provided by AWS, \n* the [GenerateRandomBytes](https://cloud.google.com/kms/docs/generate-random) API from Google Cloud, \n* [SecureRandom](https://docs.oracle.com/javase/8/docs/api/java/security/SecureRandom.html), a class from Java, and others. \n\n### 2. Store your keys separately from your ciphertext. \n\nDo not store your keys in the same place as encrypted data, and do not hardcode them in the source code. You can use: \n\n* dedicated hardware devices such as Hardware security modules (HSM), \n* key management systems such as Azure Key Vault and AWS KMS, \n* open source KMS such as HashiCorp Vault. \n\n### 3. Rotate the keys. \n\nChange the keys regularly (every 90 days or less). This process involves retiring an encryption key and generating a new one. \n\nMoreover, if a key is compromised, immediately replace it and assess which data is at risk. \n\n### 4. Implement access control for keys \n\nEnsure that access to keys is heavily restricted in the following ways: \n\n* [Implement the Least Privilege Principle.](https://cyscale.com/blog/check-for-least-privilege/) Only the individuals that need the keys should be able to access them. You can also implement time windows when keys can be accessed. \n* Only authorized personnel should be able to access keys. Ensure that, after you’ve granted access rights to people, only they can see and use the keys. \n\n###  5. Manage key deletion \n\nIf a key is permanently deleted, all data encrypted with that key is lost. The key should be appropriately destroyed after all the encrypted data is decrypted and re-encrypted with a new key. \n\nSolutions from cloud vendors for safe key deletion are: \n\n* Soft delete in Azure Key Vault, \n* Key deletion scheduling in AWS. \n\n## Server-side encryption - cloud solutions \n\nAWS, Azure, and Google Cloud provide data at rest encryption and key management solutions. Let's look at the available options and how to make sure you're using them correctly. \n\n### Encryption in AWS \n\nThe following services in AWS support data at rest encryption capabilities: \n\n* Amazon EBS, \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift, \n* AWS Lambda, and many others. \n\nKey management is done using the AWS Key Management Service, which allows users to utilize their own keys or let AWS deal with them. \n\n### Encryption in Azure \n\nIn Microsoft Azure, users have the following options: \n\n* Azure Disk Encryption, for Virtual Machines, \n* Azure Storage and Azure SQL Database, which encrypt all data at rest. \n\nFor key management, Azure provides the following services: \n\n* Azure Key Vault, \n* Vault Managed Hardware Security Model (HSM). \n\n### Encryption in Google Cloud \n\nFor key management, Google Cloud provides the Google Key Management Service. As an additional layer of security, the encryption key, named DEK (Data Encryption Key), is also encrypted using a KEK (Key-encryption key).  \n\n## How do you check for encryption misconfigurations? \n\nAs we’ve seen, there are many best practices to be considered, and therefore there is room for mistakes. \n\nYou can quickly [check for misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/) regarding data at rest encryption in the cloud using Cyscale’s controls. Here are a few examples of controls that check if you’re implementing the best practices described in this article: \n\n* *Ensure all S3 buckets employ encryption-at rest* for AWS \n* *Ensure storage for critical data are encrypted with Customer Managed Key* for Microsoft Azure, \n* *Ensure EBS encryption by default is enabled* for AWS, \n* *Ensure CloudTrail logs are encrypted at rest* for AWS. \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM","Product"],"title":"How to Check for Least Privilege with Cyscale’s New Identity Dashboard ","seoTitle":"How to Check for Least Privilege with Cyscale’s New Identity Dashboard ","description":"The Least Privilege Principle states that no user should be given more permissions and for more time than they require for their day-to-day tasks. Compliance with the Principle of Least Privilege (PoLP) is a security best practice in cloud security that should be implemented in all cloud environments. In order to implement PoLP, you must use timed privileges, set up minimum permissions to add more on the go and remove or disable identities that haven’t been active in the last 30 days or more. ","seoDescription":"The Least Privilege Principle states that no user should be given more permissions and for more time than they require for their day-to-day tasks. Compliance with the Principle of Least Privilege (PoLP) is a security best practice in cloud security that should be implemented in all cloud environments. In order to implement PoLP, you must use timed privileges, set up minimum permissions to add more on the go and remove or disable identities that haven’t been active in the last 30 days or more. ","date":"2022-08-15T05:45:35.102Z","featuredpost":true,"permalink":"check-for-least-privilege","featuredimage":{"publicURL":"/static/fbc039617d686e9adb5447d24c4ef5e3/blog_18-cover.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/fbc039617d686e9adb5447d24c4ef5e3/888e2/blog_18-cover.webp","srcSet":"/static/fbc039617d686e9adb5447d24c4ef5e3/913d0/blog_18-cover.webp 205w,\n/static/fbc039617d686e9adb5447d24c4ef5e3/91660/blog_18-cover.webp 410w,\n/static/fbc039617d686e9adb5447d24c4ef5e3/888e2/blog_18-cover.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nThe Least Privilege Principle states that no user should be given more permissions and for more time than they require for their day-to-day tasks. \n\nCompliance with the Principle of Least Privilege (PoLP) is a security best practice in cloud security that should be implemented in all cloud environments. \n\n## How do you implement Least Privilege? \n\n* Use timed privileges; only assign privileges in the moments they are needed and revoke them after. \n* Set up minimum permissions and add more on the go, if necessary. \n* Remove or disable identities that haven’t been active in the last 30 days or more. \n\n## Cyscale can help you implement the Principle of Least Privilege \n\nWith a new, powerful identity dashboard, Cyscale helps you improve the visibility of your cloud identities and pinpoint vulnerabilities or misconfigurations. \n\nUsing this page, you can see your organization's identities and their level of access. \n\nEntities that do not have permissions in the cloud but have an account are marked with the “No Access” tag on the right. \n\n![No access permissions in dashboard](/img/blog_18-1.webp#shadow \"No access permissions in dashboard\")\n\nMoreover, people who have left the organization are also visible on this dashboard. It is essential to know which entities have left to ensure you have a complete offboarding process and that they no longer have permissions. \n\nIf we expand a card of an identity that no longer exists in the company, we see that their account is disabled because it is greyed out. \n\n![Disabled identity](/img/blog_18-2-disabled-identity.webp#shadow \"Disabled identity\")\n\nTo understand an identity's impact on the entire organization's environment, you must have comprehensive visibility.  \n\nThe following image shows that the analyzed user has accounts in Alibaba, AWS, Azure, Google Cloud, and Okta. Furthermore, we can see that they are part of the \"**Admins**\" group, as well as others, and as a result, are \"**Highly Privileged**”. \n\n![Highly privileged identity](/img/blog_18-3-andrei-stefanie.webp#shadow \"Highly privileged identity\")\n\nIf we expand each account’s card, we can see the environment they have access to. Besides tracking permissions, it is crucial to also track the actual environments each user has access to. In the cloud, this tends to quickly become hard to track because applications often span multiple accounts. \n\n<br/>\n\nBeing highly privileged is not necessarily an issue, however, combining it with the lack of MFA does become a problem. Cyscale highlights this situation. This can be seen immediately after expanding a person’s card, so the vulnerability is not missed. \n\nIn this example, the user’s Okta account does not have MFA. [Okta is an identity and access management (IAM) service](https://cyscale.com/blog/provide-visibility-in-cloud-okta-integration/) where you can onboard your accounts, which helps you manage your organization’s access to other applications through SSO. \n\nIn the image below, you can see the accounts assigned using Okta. Therefore, if there is a vulnerability in your Okta account, all those accounts may be compromised. \n\n![Okta identity](/img/blog_18-4-okta.webp#shadow \"Okta identity\")\n\nAnother useful feature of the Identity Dashboard is the “Alerts” section. If an account has security alerts, the user can click on them and be redirected to the Alerts page. There, you can see failed controls along with: \n\n* Severity, \n* The asset involved, \n* The status, and others. \n\nYou can immediately pinpoint any misconfigurations and vulnerabilities using these alerts and quickly solve them with the remediation steps provided. \n\nBesides visibility, Cyscale provides controls that automatically check for misconfigurations. \n\nThere are over 400 controls currently available in Cyscale. A few examples of controls that verify you’re implementing the Least Privilege Principle correctly are: \n\n* *Eliminate use of the \"root\" user for administrative and daily tasks* for AWS \n* *Ensure that ServiceAccount has no Admin privileges* for Google Cloud Platform \n* *Ensure IAM policies that allow full \"\\*:\\*\" administrative privileges are not created* for AWS \n* *Ensure IAM Users that are inactive for 30 days or more are deactivated* for AWS \n\n<!--EndFragment-->\n"}}]}},"pageContext":{"limit":9,"skip":27,"numPages":8,"currentPage":4,"category":"All","seoTitle":"Blog Page 4 - Cyscale","seoDescription":"Cloud and Data Security Blog","categoriesList":["CSPM","News","Product","Compliance","CNAPP","Engineering"]}},"staticQueryHashes":["3765828210","4109069157","632500807","981947644"],"slicesMap":{}}