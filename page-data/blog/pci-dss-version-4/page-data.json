{"componentChunkName":"component---src-template-blog-template-js","path":"/blog/pci-dss-version-4/","result":{"pageContext":{"alldata":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"Compliance Countdown: Navigating the Transition to PCI DSS Version 4","seoTitle":"Compliance Countdown: Navigating the Transition to PCI DSS Version 4","description":"The new PCI DSS version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.\n","seoDescription":"The new PCI DSS version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.","date":"2023-07-20T09:21:54.388Z","featuredpost":true,"permalink":"pci-dss-version-4","featuredimage":{"publicURL":"/static/176523e56bb9c620ee9eca495d6e187c/45_blog-pci-v4.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/176523e56bb9c620ee9eca495d6e187c/888e2/45_blog-pci-v4.webp","srcSet":"/static/176523e56bb9c620ee9eca495d6e187c/913d0/45_blog-pci-v4.webp 205w,\n/static/176523e56bb9c620ee9eca495d6e187c/91660/45_blog-pci-v4.webp 410w,\n/static/176523e56bb9c620ee9eca495d6e187c/888e2/45_blog-pci-v4.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}},"tableOfContents":true},"rawMarkdownBody":"The new [PCI DSS](https://cyscale.com/blog/pci-dss-compliance-in-cloud/) version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.\n\n## Timeline and deadlines\n\nPCI DSS version 4 appeared at the end of March 2022 and its requirements will become mandatory in two phases: the first one is March of 2024, and the final one is March of 2025.\n\nThe new version brings considerable changes, but most of the new requirements will not be mandatory until 2025. However, companies that manage to fulfill them before 2025 can audit them.\n\nThe old version, PCI DSS 3.2.0., will remain active until the 31st of March, 2024, to allow companies enough time to recertify with the new version.\n\n## Changes in PCI DSS version 4, explained\n\nNew requirements have been added to all of the categories to better reflect the current cybersecurity landscape. Some examples of areas covered by the new requirements include the authentication process, logging and monitoring, vulnerability scanning, and others.\n\nMost of the sections have been revised or contain new requirements.\n\nPCI DSS is structured into twelve requirements, and each contains its own sections. The requirements are:\n\n### 1. Install and maintain network security controls\n\nThis requirement now specifies “network security controls” instead of “firewalls”, to cover more network security technologies. All of the sections in this category have been changed to the following:\n\n* 1.1 Processes and mechanisms for installing and maintaining network security controls are defined and understood.\n* 1.2 Network security controls (NSCs) are configured and maintained.\n* 1.3 Network access to and from the cardholder data environment is restricted.\n* 1.4 Network connections between trusted and untrusted networks are controlled.\n* 1.5 Risks to the CDE from computing devices that are able to connect to both untrusted networks and the CDE are mitigated.\n\n### 2. Apply Secure Configurations to All System Components\n\nThis requirement was initially named “Do not use vendor-supplied defaults for system passwords and other security parameters.”. Now, it refers to all of the company’s configurations, and not only to using vendor-supplied defaults. The sections in this category are the following:\n\n* 2.1 Processes and mechanisms for applying secure configurations to all system components are defined and understood.\n* 2.2 System components are configured and managed securely.\n* 2.3 Wireless environments are configured and managed securely.\n\n### 3. Protect Stored Account Data\n\nWith the third requirement, the focus is switched to account data, compared to the old version, where “cardholder data\" was mentioned instead. New sections are added in relation to PAN (Primary Account Number) and SAD (Sensitive Authentication Data) which cover the storage, encryption and hashing of this data.\n\n* 3.1 Processes and mechanisms for protecting stored account data are defined and understood.\n* 3.2 Storage of account data is kept to a minimum.\n* 3.3 Sensitive authentication data (SAD) is not stored after authorization.\n* 3.4 Access to displays of full PAN and ability to copy cardholder data are restricted.\n* 3.5 Primary account number (PAN) is secured wherever it is stored.\n* 3.6 Cryptographic keys used to protect stored account data are secured.\n* 3.7 Where cryptography is used to protect stored account data, key management processes and procedures covering all aspects of the key lifecycle are defined and implemented.\n\n### 4. Protect Cardholder Data with Strong Cryptography During Transmission Over Open, Public Networks\n\n“Strong cryptography” is now part of the 4th requirement name, to highlight the importance of using appropriate algorithms. The new sections introduce rules regarding the storage and usage of keys and certificates. \n\n* 4.1 Processes and mechanisms for protecting cardholder data with strong cryptography during transmission over open, public networks are defined and documented.  \n* 4.2 PAN is protected with strong cryptography during transmission. \n\n### 5. Protect All Systems and Networks from Malicious Software \n\nThis requirement has been renamed, replacing “anti-virus” with “malicious” software to cover a broader range of technologies. Moreover, sections in this category now regulate the frequency of scans and checks, as well as other aspects.\n\n* 5.1 Processes and mechanisms for protecting all systems and networks from malicious software are defined and understood.\n* 5.2 Malicious software (malware) is prevented, or detected and addressed.\n* 5.3 Anti-malware mechanisms and processes are active, maintained, and monitored.\n* 5.4 Anti-phishing mechanisms protect users against phishing attacks.\n\n### 6. Develop and Maintain Secure Systems and Software\n\nIn this requirement, one of the new sections added (6.4) refers to automating the detection and prevention of attacks over public-facing web apps. Sections 6.1 and 6.3 also contain new requirements.\n\n* 6.1 Processes and mechanisms for developing and maintaining secure systems and software are defined and understood.\n* 6.2 Bespoke and custom software are developed securely.\n* 6.3 Security vulnerabilities are identified and addressed.\n* 6.4 Public-facing web applications are protected against attacks.\n* 6.5 Changes to all system components are managed securely.\n\n### 7. Restrict Access to System Components and Cardholder Data by Business Need to Know\n\nThis requirement includes new rules regarding the review of user accounts and their privileges, as well as the management and privileges of applications and system accounts.\n\n* 7.1 Processes and mechanisms for restricting access to system components and cardholder data by business need to know are defined and understood.\n* 7.2 Access to system components and data is appropriately defined and assigned.\n* 7.3 Access to system components and data is managed via an access control system(s).\n\n### 8. Identify Users and Authenticate Access to System Components \n\nMany new sections regarding MFA, credentials and the entire authentication process have been added in this requirement. Two examples of changes that companies compliant with PCI DSS have to implement now are: the minimum length of a user account password has increased from 7 to 12 characters, and companies are not allowed to store passwords/passphrases in scripts or files.\n\n* 8.1 Processes and mechanisms for identifying users and authenticating access to system components are defined and understood.\n* 8.2 User identification and related accounts for users and administrators are strictly managed throughout an account’s lifecycle.\n* 8.3 Strong authentication for users and administrators is established and managed.\n* 8.4 Multi-factor authentication (MFA) is implemented to secure access into the CDE.\n* 8.5 Multi-factor authentication (MFA) systems are configured to prevent misuse.\n* 8.6 Use of application and system accounts and associated authentication factors is strictly managed.\n\n### 9. Restrict Physical Access to Cardholder Data \n\nThis requirement does not have many changes. Some sections that refer to roles and responsibilities, as well as the frequency of device inspections have been added.\n\n* 9.1 Processes and mechanisms for restricting physical access to cardholder data are defined and understood.\n* 9.2 Physical access controls manage entry into facilities and systems containing cardholder data.\n* 9.3 Physical access for personnel and visitors is authorized and managed.\n* 9.4 Media with cardholder data is securely stored, accessed, distributed, and destroyed.\n* 9.5 Point of interaction (POI) devices are protected from tampering and unauthorized substitution.\n\n### 10. Log and Monitor All Access to System Components and Cardholder Data \n\nNew sections in this requirement regulate the automation of logging, prompt response to failed security controls, as well as how often logs should be reviewed:\n\n* 10.1 Processes and mechanisms for logging and monitoring all access to system components and cardholder data are defined and documented.\n* 10.2 Audit logs are implemented to support the detection of anomalies and suspicious activity, and the forensic analysis of events.\n* 10.3 Audit logs are protected from destruction and unauthorized modifications.\n* 10.4 Audit logs are reviewed to identify anomalies or suspicious activity.\n* 10.5 Audit log history is retained and available for analysis.\n* 10.6 Time-synchronization mechanisms support consistent time settings across all systems.\n* 10.7 Failures of critical security control systems are detected, reported, and responded to promptly.\n\n### 11. Test Security of Systems and Networks Regularly\n\nThis category includes the following:\n\n* a new requirement to manage all applicable vulnerabilities,\n* a new requirement to perform internal vulnerability scans via authenticated scanning,\n* a new requirement to deploy a change-and-tamper-detection mechanism to alert for unauthorized modifications to the HTTP headers and contents of payment pages as received by the consumer browser, [according to PCI SSC](https://listings.pcisecuritystandards.org/documents/PCI-DSS-v3-2-1-to-v4-0-Summary-of-Changes-r1.pdf).\n\nThe full list of the sections included in this requirement is:\n\n* 11.1 Processes and mechanisms for regularly testing security of systems and networks are defined and understood.\n* 11.2 Wireless access points are identified and monitored, and unauthorized wireless access points are addressed.\n* 11.3 External and internal vulnerabilities are regularly identified, prioritized, and addressed.\n* 11.4 External and internal penetration testing is regularly performed, and exploitable vulnerabilities and security weaknesses are corrected.\n* 11.5 Network intrusions and unexpected file changes are detected and responded to.\n* 11.6 Unauthorized changes on payment pages are detected and responded to.\n\n### 12. Support Information Security with Organizational Policies and Programs\n\nThe title modification reflects that the focus is on organizational policies and programs. In PCI DSS version 4, requirements specify that the audited company should, at least every 12 months:\n\n* document and review cryptographic cipher suites and protocols,\n* review hardware and software components,\n* document the PCI DSS scope,\n* review and update the security awareness program, among other requirements, which are presented below.\n\n \n\n* 12.1 A comprehensive information security policy that governs and provides direction for protection of the entity’s information assets is known and current.\n* 12.2 Acceptable use policies for end-user technologies are defined and implemented.\n* 12.3 Risks to the cardholder data environment are formally identified, evaluated, and managed.\n* 12.4 PCI DSS compliance is managed.\n* 12.5 PCI DSS scope is documented and validated.\n* 12.6 Security awareness education is an ongoing activity.\n* 12.7 Personnel are screened to reduce risks from insider threats.\n* 12.8 Risk to information assets associated with third-party service provider (TPSP) relationships is managed.\n* 12.9 Third-party service providers (TPSPs) support their customers’ PCI DSS compliance.\n* 12.10 Suspected and confirmed security incidents that could impact the CDE are responded to immediately.\n\n## What do you have to do now? \n\nYou have to become PCI-DSS version 4 certified until the 31st of March 2024. There are two possible paths for your company:\n\n1. Your company is already PCI-DSS certified, so until the first deadline you must cover some of the new requirements and until the last deadline all of them, or\n2. Your company is not PCI-DSS certified, so you have to start from the beginning with the new PCI-DSS version and fulfill all requirements according to the specified deadlines.\n\nThis new version of PCI DSS brings considerable changes, and the process of achieving compliance with PCI DSS can be long and cumbersome.\n\nCyscale helps companies accelerate their cloud compliance process and ace audits by providing:\n\n* security controls that check if you’re implementing the requirements correctly, and\n* a page for each standard where you can track your progress and history.\n"},"suggestions":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"The Next Era of Security Scoring: CVSS 4.0 vs CVSS 3.1 and What You Need to Know","seoTitle":"CVSS 4.0 vs CVSS 3.1 and What You Need to Know","description":"The Forum of Incident Response and Security Teams (FIRST) officially launched CVSS 4 in early November. Let’s see how CVSS 4 revolutionizes how we look at vulnerabilities and how it compares to CVSS 3.1. ","seoDescription":"The Forum of Incident Response and Security Teams (FIRST) has launched CVSS 4. See how it compares to CVSS 3.1. ","date":"2023-11-20T10:55:36.862Z","featuredpost":true,"permalink":"security-scoring-cvss4-vs-cvss3-need-to-know","featuredimage":{"publicURL":"/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/cvss4-vs-cvss3.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/2c0f5/cvss4-vs-cvss3.jpg","srcSet":"/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/41be8/cvss4-vs-cvss3.jpg 205w,\n/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/c78f7/cvss4-vs-cvss3.jpg 410w,\n/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/2c0f5/cvss4-vs-cvss3.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/913d0/cvss4-vs-cvss3.webp 205w,\n/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/91660/cvss4-vs-cvss3.webp 410w,\n/static/b0fe4ca7a8cc5a3e4f868c24a738e6fb/888e2/cvss4-vs-cvss3.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"For years, security professionals have used the CVSS (Common Vulnerability Scoring System) to rank software vulnerabilities and assess their severity. It is probably the world’s most used scoring system for [vulnerabilities](https://cyscale.com/blog/critical-vulnerabilities-kubernetes-secrets-risk/), and, despite its updates over the years, it has had its shortcomings.  \n\nCVSS 3.0, updated to CVSS 3.1 in 2019, was the most recent and popular version in use for the last eight years. But in early November the Forum of Incident Response and Security Teams (FIRST) [officially launched CVSS 4](https://www.first.org/cvss/v4-0/index.html) This version promises to address many of the shortcomings of its predecessors.  \n\nLet’s see how CVSS 4 revolutionizes how we look at vulnerabilities and why it’s been a long time coming. \n\n## Timeline of CVSS updates \n\n* February 2005: CVSS Version 1 appears. This version received much criticism due to its ambiguous metric system \n* June 2007: CVSS version 2 is launched, this time with less inconsistencies. \n* June 2015: CVSS version 3.0 is published, introducing the concept of “Scope” to mark a difference between separate components of a system \n* June 2019: CVSS version 3.1 clarified concepts and introduced new metrics, making the new CVSS score easier to use \n* 2023: CVSS version 4.0 is released.  \n\nNotice how it's been over eight years since CVSS version 3.0 appeared. And while it had a patch four years in with 3.1, it still had problems.   \n\n## The shortcomings of CVSS 3.0 and 3.1 \n\nLack of granularity was a big challenge for CVSS 3.0 and 3.1. The flat scoring allowed for two vulnerabilities that impacted an IT system differently to be scored the same. For example, a vulnerability that allowed remote code execution without authentication could have been ranked the same as one that required local access with elevated privileges. While both can lead to disaster in a company, the former poses a higher risk due to its potential exploitation.  \n\n[Temporal metrics](https://www.first.org/cvss/v3-1/cvss-v31-specification_r1.pdf) did not have a significant impact on the CVSS score. The three temporal metrics were: \n\n* Exploit code maturity, which refers to the stage of the exploit (whether it’s “functional” or “proof-of-concept”, for example), \n* Remediation level, which measures the quality of available patches or mitigation (some values included “unavailable”, “workaround”, and “official fix”), \n* Report confidence, or the degree of confidence in the existence of the vulnerability and the supplied technical details, with values like “reasonable” or “unknown”. \n\nThe scoring accuracy was also debatable. Often, vulnerabilities were ranked over 7.0 (High or Critical), which meant people frequently saw high-severity vulnerabilities. And while the impact of such vulnerabilities can’t be denied, desensitization became a problem. An accurate score is more important than marking everything as critical, which meant better metrics were needed.  \n\n## So what’s changed with CVSS 4? \n\n[According to FIRST](https://www.first.org/cvss/v4-0/index.html) (The Forum of Incident Response and Security Teams), the entity that manages CVSS, version 4.0 has a finer granularity, achieved by introducing new base metrics and values, which allow for a better scoring system: \n\n* The new Base metric, Attack Requirements (AT), measures the conditions that have to be met for an attack to be possible (basically, how many things need to go wrong before an attack is possible), \n* New Base metric values: User Interaction (UI), which captures if a human is needed (besides the [attacker](https://cyscale.com/blog/compromising-azure-cloud-as-guest/)) to compromise a vulnerable system. The possible values are None (N), Passive (P), and Active (A). For example, if a user needs to give permissions deliberately for the attack to be possible, the User Interaction is Active. \n\nAs we can see, these important metrics allow for a better scoring system for vulnerabilities.  \n\nExploit Maturity (E) now measures more accurately the likelihood of the vulnerability to be exploited; it is a temporal metric based on the current state of the exploitation techniques. This temporal metric allows the CVSS score to reflect the severity of a vulnerability in real-time. Remediation Level and Report Confidence have been retired, and the new threat metrics are more accessible to follow and understand. \n\nEnvironmental metrics allow for more customized and specific vulnerability assessments because they take into consideration the conditions and setups of companies’ environments. This is a “feature” that the previous versions of CVSS lacked. Environmental metrics include: \n\n* Confidentiality, Integrity, and Availability Requirements (CR, IR, AR), which are metrics that allow companies to assign an adequate importance to each factor. For example, if the integrity of data is of utmost importance, they can rate IR as High and the others as Medium or Low, \n* Safety is a metric that shows the impact on human lives. For example, if a vulnerability were to cause a fintech organization business disruption and financial losses, the Safety of that vulnerability could be assessed as Negligible, in comparison to the same one affecting a healthcare organization where life is put in danger, in which case Catastrophic would be a much more appropriate score. \n\n## The relation between CVSS and EPSS: Brothers in arms \n\nAnother scoring system - EPSS (Exploit Prediction Scoring System) - is designed to predict the likelihood of a vulnerability being exploited in the future. It aims to forecast the probability that a vulnerability will be used in a successful attack, helping security teams anticipate and prepare for potential threats.  \n\nIn conjunction with CVSS, EPSS can help prioritize the vulnerability remediation efforts. \n\nEPSS typically considers various factors, including: \n\n* the vulnerability's exploitability,  \n* presence of known exploits,  \n* trends in threat actor behavior, and  \n* historical data to predict the likelihood of exploitation.  \n\n## Benefits of CVSS 4.0\n\nIt is important to understand that CVSS version 4.0 does not apply retroactively. Only the vulnerabilities discovered after the release of CVSS 4.0 will receive the new scoring. \n\nThe new CVSS version 4.0 will bring much sought after value to companies trying to assess their security posture. At Cyscale, we display the CVSS and the EPSS scores to help users better understand their cloud environment. We show the CVSS score of vulnerabilities to highlight which ones should be prioritized. By factoring in the CVSS value, which is now much more relevant, we can help organizations understand risks more accurately and highlight [cloud security infrastructure](https://cyscale.com/blog/cloud-infrastructure-security/) improvements with the highest impact and the lowest level of effort required. \n\n<img src=\"/img/cve-screen.png\" alt=\"CVE vulnerability info card in Cyscale\" title=\"\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Critical Confluence Authorization Vulnerability Actively Exploited","seoTitle":"Critical Confluence Authorization Vulnerability Actively Exploited","description":"Atlassian has warned that as of November 6th it has observed 'several active exploits' and reports of threat actors using ransomware in association with a critical Improper Authorization Vulnerability in Confluence Data Center and Server.","seoDescription":"Atlassian warns of  active exploits and threat actors using ransomware in critical Improper Authorization Vulnerability in Confluence Data Center and Server.","date":"2023-11-08T11:55:39.247Z","featuredpost":true,"permalink":"critical-authorization-vulnerability-confluence-exploited","featuredimage":{"publicURL":"/static/d806873ee5f93307e67b021fd9e0128e/confluence-criticalvuln-exploit.jpg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/d806873ee5f93307e67b021fd9e0128e/2c0f5/confluence-criticalvuln-exploit.jpg","srcSet":"/static/d806873ee5f93307e67b021fd9e0128e/41be8/confluence-criticalvuln-exploit.jpg 205w,\n/static/d806873ee5f93307e67b021fd9e0128e/c78f7/confluence-criticalvuln-exploit.jpg 410w,\n/static/d806873ee5f93307e67b021fd9e0128e/2c0f5/confluence-criticalvuln-exploit.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/d806873ee5f93307e67b021fd9e0128e/913d0/confluence-criticalvuln-exploit.webp 205w,\n/static/d806873ee5f93307e67b021fd9e0128e/91660/confluence-criticalvuln-exploit.webp 410w,\n/static/d806873ee5f93307e67b021fd9e0128e/888e2/confluence-criticalvuln-exploit.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"Atlassian has warned that as of November 6th it has observed 'several active exploits' and reports of threat actors using ransomware in association with a critical Improper Authorization Vulnerability in Confluence Data Center and Server. \n\nCVE-2023-22518, first published on October 31st, 2023, is a Confluence vulnerability that affects all pre-existing versions of Data Center and Server. It was initially assigned a CVSS score of 9.1, which was increased to 10, the maximum, on November 6th.  \n\nThis is the [second critical vulnerability](https://confluence.atlassian.com/security/cve-2023-22515-privilege-escalation-vulnerability-in-confluence-data-center-and-server-1295682276.html) in Atlassian Data Center and Server discovered in the same month, alongside CVE-2023-22515.   \n\n## Confluence Improper Authorization vulnerability in detail \n\nThis vulnerability occurs due to Improper Authorization. The bug enables the attacker to: \n\n* reset a Confluence instance, and to \n* create a Confluence instance administrator account. \n\nThis means the attacker can either reset the entire instance, causing the company to lose data unless it is backed up, or they can steal the data by creating an administrator account.   \n\n### What you need to do: mitigation of the Confluence Improper Authorization vulnerability \n\nSince all versions prior to the attack are affected, [Atlassian urges users](https://confluence.atlassian.com/security/cve-2023-22518-improper-authorization-vulnerability-in-confluence-data-center-and-server-1311473907.html) to immediately patch to the new versions released:  \n\n* 7.19.16, \n* 8.3.4, \n* 8.4.4, \n* 8.5.3, \n* 8.6.1. \n\nIf patching is not possible straight away, remove the instance from being publicly accessible. This is a temporary measure that allows you to gain time by limiting the attack surface – if your instance is not Internet-facing, attackers cannot reach it as easily. \n\nBesides this, it is recommended to back-up your instance. \n\nIf you cannot patch the instance and remove it from the internet, you can apply the following temporary solutions, which you can also find on [Atlassian’s page](https://confluence.atlassian.com/security/cve-2023-22518-improper-authorization-vulnerability-in-confluence-data-center-and-server-1311473907.html): \n\nBlock access to the following endpoints: \n\n* /json/setup-restore.action \n* /json/setup-restore-local.action \n* /json/setup-restore-progress.action \n\nTo do that, on each node, modify /<confluence-install-dir>/confluence/WEB-INF/web.xml and add the following block of code (just before the </web-app> tag at the end of the file): \n\n```\n\n<security-constraint>\n\t\t<web-resource-collection>\n\t\t\t<url-pattern>/json/setup-restore.action</url-pattern>\n\t\t\t<url-pattern>/json/setup-restore-local.action</url-pattern>\n\t\t\t<url-pattern>/json/setup-restore-progress.action</url-pattern>\n\t\t\t<http-method-omission>*</http-method-omission>\n\t\t</web-resource-collection>\n\t<auth-constraint />\n</security-constraint>\n```\n\nThen, restart your instance.   \n\n### How do you know if you were affected? \n\nIf you cannot login anymore, it could be a sign that your Confluence instance has been compromised. Besides this, look out for: \n\n* requests to /json/setup-restore* in your logs, \n* installed unknown plugins (the malicious plugin web.shell.Plugin was reported, according to Atlassian), \n* corrupted data or encrypted files that were not encrypted before, \n* new and unexpected members of the confluence-administrators group, \n* new and unexpected user accounts. \n\nCyscale customers are already protected, as the [Cyscale cloud security platform](https://cyscale.com/products/cloud-security-posture-management/) surfaces assets affected by the Improper Authorization Vulnerability in Confluence Data Center and Server as long as their vulnerability scanner of choice has been updated.\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"Everything You Need to Know about HITRUST Compliance in the Cloud","seoTitle":"Everything to Know about HITRUST Compliance in the Cloud","description":"HITRUST (Health Information Trust) Alliance is the organization that established the HITRUST CSF (Common Security Framework), a framework for managing and securing information in the healthcare industry. This comprehensive framework regulates how healthcare providers and other health businesses handle sensitive data, store it and protect it. \n\nThe HITRUST framework goes above and beyond what HIPAA requires and while its stringency can make it daunting to implement, the benefits of this certification in terms of credibility and assurance are not to be underestimated. \n\nHITRUST CSF is based on ISO/IEC 27001 and 27002 and incorporates more than 50 regulations, standards, and frameworks, thus providing a complete set of requirements and best practices to ensure security. ","seoDescription":"While it can be daunting to implement, HITRUST is considered best-in-class for data security and privacy healthcare certification.","date":"2023-11-07T08:34:54.146Z","featuredpost":true,"permalink":"hitrust-compliance-in-the-cloud","featuredimage":{"publicURL":"/static/5c8091475f4aa54a455a6cb0cdf46dfc/58_blog-cover-image.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/5c8091475f4aa54a455a6cb0cdf46dfc/2c0f5/58_blog-cover-image.jpg","srcSet":"/static/5c8091475f4aa54a455a6cb0cdf46dfc/41be8/58_blog-cover-image.jpg 205w,\n/static/5c8091475f4aa54a455a6cb0cdf46dfc/c78f7/58_blog-cover-image.jpg 410w,\n/static/5c8091475f4aa54a455a6cb0cdf46dfc/2c0f5/58_blog-cover-image.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/5c8091475f4aa54a455a6cb0cdf46dfc/913d0/58_blog-cover-image.webp 205w,\n/static/5c8091475f4aa54a455a6cb0cdf46dfc/91660/58_blog-cover-image.webp 410w,\n/static/5c8091475f4aa54a455a6cb0cdf46dfc/888e2/58_blog-cover-image.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":true},"rawMarkdownBody":"As well as delivering innovation and improving care for customers, organizations operating in the healthcare industry are also required to demonstrate robust processes in security, data protection and privacy, and HITRUST is considered by many the best-in-class for data security and privacy healthcare certification.   \n\n[HITRUST (Health Information Trust) Alliance](https://hitrustalliance.net/) is the organization that established the HITRUST CSF (Common Security Framework), a framework for managing and securing information in the healthcare industry. This comprehensive framework regulates how healthcare providers and other health businesses handle sensitive data, store it and protect it. \n\nThe HITRUST framework goes above and beyond [what HIPAA requires](https://cyscale.com/blog/hipaa-compliance-in-cloud/) and while its stringency can make it daunting to implement, the benefits of this certification in terms of credibility and assurance are not to be underestimated. \n\nHITRUST CSF is based on ISO/IEC 27001 and 27002 and incorporates more than 50 regulations, standards, and frameworks, thus providing a complete set of requirements and best practices to ensure security. \n\nIn this article, we will look at the requirements that apply specifically to healthtech companies with apps and data in the cloud and how to ensure your security and compliance processes are robust enough to pass HITRUST certification. \n\n## HITRUST control categories and how they relate to cloud security \n\nThe standard contains 14 control categories, numbered from 0 to 13: \n\n1. Information Security Management Program \n2. Access control \n3. Human Resources Security \n4. Risk Management \n5. Security Policy \n6. Organization of Information Security \n7. Compliance \n8. Asset Management \n9. Physical and Environmental Security \n10. Communications and Operations Management \n11. Information Systems, Acquisition, Development, and Maintenance \n12. Information Security Incident Management \n13. Business Continuity Management \n14. Privacy Practices \n\nEach control category has one or more objectives, which define the purpose or scope of its requirements, and each Objective contains control references, which encompass a best practice or requirement. There are 49 objectives and 156 control references.  \n\nThis standard can become overwhelming, especially when looking at the 516 pages of version 11.2.0 (the latest one as of November 2023), making implementation a daunting task for small or inexperienced teams. But as we said, the benefits in terms of credibility and increased confidence from your customers cannot be underplayed. Furthermore, there are solutions out there that can do the heavy lifting, such as [ensuring your cloud security controls are in compliance with the framework](https://cyscale.com/products/cloud-security-posture-management/) and alerting you if drifts are detected.  \n\n## Access control for the cloud under HITRUST CSF \n\nThe \"Access control\" category includes recommendations on user management, password policies, [the Least Privilege principle](https://cyscale.com/blog/check-for-least-privilege/), network segregation, session timeout, teleworking, and many others—everything related to [authentication and authorization](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/). \n\n### Effective cloud user password management \n\nImplementing a robust password policy is very important. Imposing a minimum number of characters, as well as the usage of special characters, lowercase and uppercase letters, numbers, and other conditions, is imperative because users tend to want to choose passwords that are easy to remember and type, which increases the risk of having credentials stolen through brute force. Moreover, users should be prohibited from using the same password twice and having old passwords in use. \n\nHow do you implement an effective password policy in the cloud? \n\nTo ensure users implement secure passwords, use the following checklist: \n\n* a minimum length of 14 characters, \n* no password reuse for 24 months, \n* at least a lowercase character, \n* at least an uppercase character, \n* at least a digit, \n* at least one symbol. \n\nAlthough this seems like a lot to consider, it only takes a few minutes to make a great password policy, and for AWS, for example, you can do this in one quick command:  \n\n```\n\naws iam update-account-password-policy --minimum-password-length 14 --password-reuse-prevention 24 --require-lowercase-characters --require-uppercase-characters --require-numbers --require-symbols\n```\n\n### Network Routing Control for cloud infrastructure \n\nRouting controls should be in place to prevent unnecessary connections and information flows across your cloud infrastucture, according to [HITRUST CSF](https://hitrustalliance.net/product-tool/hitrust-csf/). \n\nFirewalls can block unwanted traffic to your cloud, and we recommend filtering traffic by allowlisting IP addresses and ports to reduce the attack surface and further control the access. [CSPM tools such as Cyscale](https://cyscale.com/products/cloud-security-posture-management//) provide a wide range of security controls that granularly verify that firewall rules are written for the most important ports, such as databases. \n\n<img src=\"/img/58_blog-network-controls.png\" alt=\"Network Routing Controls in Cyscale\" title=\"Network Routing Controls in Cyscale\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n## Securing Human Resources in the cloud  \n\nThe next category is “Human resources” and focuses on security and compliance processes that apply during the entire lifecycle of an employee in a company, starting from “Prior to Employment”, through “During On-Boarding”, “During Employment”, all the way up to “Termination or Change of Employment”. Appropriate application of policies and procedures should ensure that every employee is set up with relevant levels of entitlement and privilege to cloud systems and infrastructure, and that those entitlements and access are revoked when the employee leaves.  \n\nPoor access management processes can result in overprivileged users that unnecessarily expand your attack surface.  \n\n### Cloud Roles and Responsibilities \n\nUnder “Prior to Employment”, the first requirement is “Roles and Responsibilities”. \n\nThere should be a clear definition of roles according to the existing information security policy. This umbrella covers the protection of data by allowing only authorized access. We have a complete guide on [best practices for IAM in the cloud](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/). \n\nWe’ve put our recommendations into a checklist: \n\n* enable MFA for all users, \n* grant users access to resources, services, and data at group level. You can either directly assign the user permissions or add the user to a group and assign permissions at group level. The second one is recommended because you simplify access management. \n* comply with the Least Privilege principle to only assign the necessary permissions for the required amount of time, and others. \n\n## Compliance controls for cloud assets \n\nJumping to the sixth control category, “Compliance”, there are several technical requirements relevant to cloud infrastructure in the healthcare sector. \n\n### Data Protection in the cloud and Privacy of Covered Information \n\nTo ensure the confidentiality of data, encryption should be enabled for cloud assets that contain sensitive information. This section of the HITRUST standard refers to how encryption should be applied. Here is a [comprehensive guide on data encryption in all its states](https://cyscale.com/blog/types-of-encryption/) - data in use, data in motion, and data at rest.  \n\n### Regulation of Cryptographic Controls \n\nEncrypting data is only effective if the used cryptographic algorithms are industry-recommended. For example, if a vulnerable version of SSL/TLS is deployed, data in transit is unprotected. TLS 1.2 is recommended for securely transporting data. \n\nFor [encryption of data at rest](https://cyscale.com/blog/protecting-data-at-rest/), AES-256 (Advanced Encryption Standard with a key of 256 bits) is the standard. \n\n## Protecting your cloud environment and your code \n\nThe 9th control category, “Communications and Operations Management\" in HITRUST CSF covers segregation of duties, change management, malicious code, back-ups, and many other controls. These are most relevant to cloud security: \n\n### Effective change management in the cloud \n\nTo ensure [comprehensive change management in the cloud](https://cyscale.com/blog/cloud-security-posture-management-cspm-guide/), log and monitor all users' actions. This helps you identify and control changes that occur in the cloud environment. To configure a comprehensive change management process, consider logging changes to: \n\n* firewall rules, \n* IAM policies, \n* routing tables, \n* network gateways, \n* VPCs, \n* SQL instances, and others. \n\n### Controls against malicious code in the cloud \n\nThere are a number of things you can do to protect your cloud apps and data against malware. Scan your VMs for malicious programs and make sure their configurations are secure. In Google Cloud, you can deploy your VMs in a hardened state by enabling the “[Shielded VM](https://cyscale.com/blog/securing-google-cloud-compute-shielded-vm/)\" option to prevent malicious code, such as rootkits and backdoors, from infiltrating your cloud environment. \n\nTurning on Shielded VM in Google Cloud takes just a few clicks. Navigate to the VMs' \"Security\" configurations and tick all boxes under this feature.  \n\n<img src=\"/img/58_blog-shieldedvm.png\" alt=\"Enabling Shielded VM in Google Cloud\" title=\"Enabling Shielded VM in Google Cloud\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n## Cloud back-ups best practices \n\nThe “Back-up” category not only recommends performing regular back-ups, but also having recovery procedures in place for highly sensitive cloud resources, such as key vaults.   \n\nMake [cloud data back-ups](https://cyscale.com/blog/cloud-data-security-guide/) and store them separately from the original cloud environment; you can store them in different data centers and regions and use availability zones to ensure that if an unforeseen event occurs at one datacenter, you can still restore a back-up with little to no delay.  \n\nMoreover, enable soft delete for resources that allow this to make sure you’re not deleting a cloud asset that you didn’t mean to delete. For example, Azure Key Vault has soft delete, as well as purge protection. Soft delete allows you to restore the key vault after deletion for a period set by you (between 7 and 90 days), while purge protection will not allow you to purge the key vault (delete forever) manually. You can enable both of these settings quickly with the following command:  \n\n```\n\naz resource update --id <resourceID> --set properties.enablePurgeProtection=true properties.enableSoftDelete=true\n```\n\n### Audit Logging, Monitoring System Use, Protection of Log Information, Administrator and Operator Logs in the cloud \n\nThere are so many control references for logging it can get a bit overwhelming, so let’s break this section apart to make it more manageable. \n\nAudit Logging and Monitoring System Use are quite similar. The first requires you to log user activity and security events, while the latter refers to information processing systems.  \n\nProtection of Log Information recommends that logs are protected from tampering or unauthorized access. Consider securing the bucket or storage account where logs are collected; it is easy for companies to forget to secure logging storage assets because they’re more focused on the sensitive data, especially in regulated sectors like healthcare. \n\nAdministrator and Operator Logs require that high-privilege actions should be logged. For example, the usage of the “root” account in AWS should be logged in order to keep track of who accesses it and why. \n\n## Automating cloud security and HITRUST compliance  \n\nHITRUST CSF is a very complex and detailed compliance standard that can be overwhelming to understand and daunting to implement. What we have covered in this article may only scratch the surface but should serve as a solid foundation on your journey to bringing your cloud compliance in alignment with the framework.  \n\nTo make the overall process more manageable, consider a solution such as the [Cyscale cloud securty platform](https://cyscale.com/) to keep track of your progress, monitor for drifts, and automate security checks that validate your efforts toward achieving HITRUST compliance. Cyscale has over 300 controls that verify your cloud settings against the HITRUST CSF standard and features easily exportable reports to better illustrate your efforts to an auditor, speeding your journey to accreditation. \n\n<img src=\"/img/58_blog-standard-in-cyscale.png\" alt=\"HITRUST in Cyscale\" title=\"HITRUST in Cyscale\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"High-severity Vulnerabilities Put Kubernetes Secrets at Risk","seoTitle":"Critical NGINX Ingress Vulnerabilities Put Kubernetes Secrets at Risk","description":"Three high-severity security vulnerabilities have been disclosed in the NGINX Ingress controller for Kubernetes, which could put credentials and other secrets at risk of theft by threat actors. ","seoDescription":"Three critical vulnerabilities disclosed in the NGINX Ingress controller for Kubernetes could put credentials and other secrets at risk of theft. ","date":"2023-11-06T15:15:20.627Z","featuredpost":true,"permalink":"critical-vulnerabilities-kubernetes-secrets-risk","featuredimage":{"publicURL":"/static/39ce29032b69e2b79bf9fb939dfe5957/kubernetes-critical-vulns.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/39ce29032b69e2b79bf9fb939dfe5957/2c0f5/kubernetes-critical-vulns.jpg","srcSet":"/static/39ce29032b69e2b79bf9fb939dfe5957/41be8/kubernetes-critical-vulns.jpg 205w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/c78f7/kubernetes-critical-vulns.jpg 410w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/2c0f5/kubernetes-critical-vulns.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/39ce29032b69e2b79bf9fb939dfe5957/913d0/kubernetes-critical-vulns.webp 205w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/91660/kubernetes-critical-vulns.webp 410w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/888e2/kubernetes-critical-vulns.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"Three high-severity security vulnerabilities have been disclosed in the NGINX Ingress controller for Kubernetes, which could put credentials and other secrets at risk of theft by threat actors. \n\n## What are the NGINX Ingress controller vulnerabilities? \n\nOn October 27, 2023, three critical vulnerabilities were disclosed and assigned the following CVE numbers: \n\n* [CVE-2023-5043](https://nvd.nist.gov/vuln/detail/CVE-2023-5043),  \n* [CVE-2023-5044](https://nvd.nist.gov/vuln/detail/CVE-2023-5044), and  \n* [CVE-2022-4886.](https://nvd.nist.gov/vuln/detail/CVE-2022-4886) \n\nAll three vulnerabilities allow an attacker to execute arbitrary command execution and obtain the ingress-NGINX controller credentials. These vulnerabilities have been assigned a CVSS score of 7.6 (the first two) and 8.6 (the third one), ranked HIGH. \n\nTo better understand how the vulnerabilities can be exploited, what the impact is on your cloud infrastructure and how they can be patched, let’s dive deeper: \n\n### What is an NGINX Ingress controller? \n\nThe ingress-NGINX controller is a [specialized load balancer](https://www.nginx.com/resources/glossary/kubernetes-ingress-controller/) for Kubernetes and other containerized environments that accepts incoming traffic and routes it to Kubernetes pods. The NGINX Ingress controller is designed to be a central point of entry into a Kubernetes cluster adding a layer of abstraction to reduce routing complexity.  \n\nTo put it simply, it’s like a traffic policeman that tells all vehicles on a road where they are and are not allowed to go. \n\nAn ingress-NGINX controller is a specific implementation of an Ingress controller that uses the NGINX web server, which is known for its speed and efficiency.   \n\n### The 3 NGINX Ingress controller vulnerabilities in detail \n\n**CVE-2023-5043** \n\nAnnotations are key/value pairs that can be attached to Kubernetes objects in order to add additional information to those objects. \n\nDue to poor input sanitization, the annotation nginx.ingress.kubernetes.io/configuration-snippet can be used to inject command execution. \n\nThe “configuration-snippet” annotation, or metadata, allows users to inject custom configuration code into the NGINX configuration file. \n\n**CVE-2023-5044** \n\nThis vulnerability occurs for the nginx.ingress.kubernetes.io/permanent-redirect annotation. This annotation allows you to establish a permanent HTTP redirect (Return Code 301) by injecting arbitrary code via the annotation. As a result, the controller will redirect traffic to that path. \n\n**CVE-2022-4886** \n\nThis issue can be exploited by someone with create or update permissions on ingress API objects.   \n\nThe field spec.rules\\[].http.paths\\[].path allows you to specify where incoming requests to your applications should be routed based on the path in the URL. Since the input is not correctly sanitized, the attacker can specify an internal file as the path, obtaining the credentials of the controller. Thus, by exploiting the poor sanitization, the attacker gains access to sensitive data. \n\n### Impact of the NGINX Ingress controller vulnerabilities \n\nIngress controllers run with high privileges. By default, having access to the credentials of the ingress controller means you have access to all secrets in the cluster. As you can imagine, the impact of these vulnerabilities left unchecked can create significant risk for your data. So, it’s no surprise that the vulnerabilities described have been assigned such high CVSS scores.  \n\n### Mitigation of the NGINX Ingress controller vulnerabilities \n\nTo protect your cloud environment from these vulnerabilities, follow these steps: \n\n* for CVE-2023-5043 and CVE-2023-5044, update NGINX to version 1.19 and set the --enable-annotation-validation flag, \n* for CVE-2022-4886, change the pathType attribute of the controller to Exact or Prefix. This will allow only paths that start with “/” and contain alphanumeric characters, “-“, “_”, and additional “/”.  \n\n### The impact of NGINX Ingress controller vulnerabilities on cloud environments  \n\nThe next question is, are cloud environments impacted by these vulnerabilities? Yes! Many cloud environments run Kubernetes clusters with NGINX-ingress controllers. For a cloud-native company building software that heavily relies on Kubernetes and employs ingress-controllers, there are significant risks involved. If exploited, these bugs can lead to unauthorized access to sensitive information stored in the cluster. \n\nMoreover, the ingress controller manages incoming traffic, so the disruption of such a critical component of an infrastructure can cause availability issues leading to downtime and possible financial losses. \n\nCyscale customers are already protected, as the [Cyscale cloud security platform](https://cyscale.com/products/cloud-security-posture-management/) surfaces assets affected by the NGINX Ingress controller bugs as long as their vulnerability scanner of choice has been updated."}}]}},"staticQueryHashes":["21106388","2199015418","220583031","3058837307","3355083976","4109069157","632500807","981947644"],"slicesMap":{}}