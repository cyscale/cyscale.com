{"componentChunkName":"component---src-template-blog-template-js","path":"/blog/pci-dss-version-4/","result":{"pageContext":{"alldata":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"Compliance Countdown: Navigating the Transition to PCI DSS Version 4","seoTitle":"Compliance Countdown: Navigating the Transition to PCI DSS Version 4","description":"The new PCI DSS version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.\n","seoDescription":"The new PCI DSS version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.","date":"2023-07-20T09:21:54.388Z","featuredpost":true,"permalink":"pci-dss-version-4","featuredimage":{"publicURL":"/static/176523e56bb9c620ee9eca495d6e187c/45_blog-pci-v4.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/176523e56bb9c620ee9eca495d6e187c/888e2/45_blog-pci-v4.webp","srcSet":"/static/176523e56bb9c620ee9eca495d6e187c/913d0/45_blog-pci-v4.webp 205w,\n/static/176523e56bb9c620ee9eca495d6e187c/91660/45_blog-pci-v4.webp 410w,\n/static/176523e56bb9c620ee9eca495d6e187c/888e2/45_blog-pci-v4.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}},"tableOfContents":true},"rawMarkdownBody":"The new [PCI DSS](https://cyscale.com/blog/pci-dss-compliance-in-cloud/) version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.\n\n## Timeline and deadlines\n\nPCI DSS version 4 appeared at the end of March 2022 and its requirements will become mandatory in two phases: the first one is March of 2024, and the final one is March of 2025.\n\nThe new version brings considerable changes, but most of the new requirements will not be mandatory until 2025. However, companies that manage to fulfill them before 2025 can audit them.\n\nThe old version, PCI DSS 3.2.0., will remain active until the 31st of March, 2024, to allow companies enough time to recertify with the new version.\n\n## Changes in PCI DSS version 4, explained\n\nNew requirements have been added to all of the categories to better reflect the current cybersecurity landscape. Some examples of areas covered by the new requirements include the authentication process, logging and monitoring, vulnerability scanning, and others.\n\nMost of the sections have been revised or contain new requirements.\n\nPCI DSS is structured into twelve requirements, and each contains its own sections. The requirements are:\n\n### 1. Install and maintain network security controls\n\nThis requirement now specifies “network security controls” instead of “firewalls”, to cover more network security technologies. All of the sections in this category have been changed to the following:\n\n* 1.1 Processes and mechanisms for installing and maintaining network security controls are defined and understood.\n* 1.2 Network security controls (NSCs) are configured and maintained.\n* 1.3 Network access to and from the cardholder data environment is restricted.\n* 1.4 Network connections between trusted and untrusted networks are controlled.\n* 1.5 Risks to the CDE from computing devices that are able to connect to both untrusted networks and the CDE are mitigated.\n\n### 2. Apply Secure Configurations to All System Components\n\nThis requirement was initially named “Do not use vendor-supplied defaults for system passwords and other security parameters.”. Now, it refers to all of the company’s configurations, and not only to using vendor-supplied defaults. The sections in this category are the following:\n\n* 2.1 Processes and mechanisms for applying secure configurations to all system components are defined and understood.\n* 2.2 System components are configured and managed securely.\n* 2.3 Wireless environments are configured and managed securely.\n\n### 3. Protect Stored Account Data\n\nWith the third requirement, the focus is switched to account data, compared to the old version, where “cardholder data\" was mentioned instead. New sections are added in relation to PAN (Primary Account Number) and SAD (Sensitive Authentication Data) which cover the storage, encryption and hashing of this data.\n\n* 3.1 Processes and mechanisms for protecting stored account data are defined and understood.\n* 3.2 Storage of account data is kept to a minimum.\n* 3.3 Sensitive authentication data (SAD) is not stored after authorization.\n* 3.4 Access to displays of full PAN and ability to copy cardholder data are restricted.\n* 3.5 Primary account number (PAN) is secured wherever it is stored.\n* 3.6 Cryptographic keys used to protect stored account data are secured.\n* 3.7 Where cryptography is used to protect stored account data, key management processes and procedures covering all aspects of the key lifecycle are defined and implemented.\n\n### 4. Protect Cardholder Data with Strong Cryptography During Transmission Over Open, Public Networks\n\n“Strong cryptography” is now part of the 4th requirement name, to highlight the importance of using appropriate algorithms. The new sections introduce rules regarding the storage and usage of keys and certificates. \n\n* 4.1 Processes and mechanisms for protecting cardholder data with strong cryptography during transmission over open, public networks are defined and documented.  \n* 4.2 PAN is protected with strong cryptography during transmission. \n\n### 5. Protect All Systems and Networks from Malicious Software \n\nThis requirement has been renamed, replacing “anti-virus” with “malicious” software to cover a broader range of technologies. Moreover, sections in this category now regulate the frequency of scans and checks, as well as other aspects.\n\n* 5.1 Processes and mechanisms for protecting all systems and networks from malicious software are defined and understood.\n* 5.2 Malicious software (malware) is prevented, or detected and addressed.\n* 5.3 Anti-malware mechanisms and processes are active, maintained, and monitored.\n* 5.4 Anti-phishing mechanisms protect users against phishing attacks.\n\n### 6. Develop and Maintain Secure Systems and Software\n\nIn this requirement, one of the new sections added (6.4) refers to automating the detection and prevention of attacks over public-facing web apps. Sections 6.1 and 6.3 also contain new requirements.\n\n* 6.1 Processes and mechanisms for developing and maintaining secure systems and software are defined and understood.\n* 6.2 Bespoke and custom software are developed securely.\n* 6.3 Security vulnerabilities are identified and addressed.\n* 6.4 Public-facing web applications are protected against attacks.\n* 6.5 Changes to all system components are managed securely.\n\n### 7. Restrict Access to System Components and Cardholder Data by Business Need to Know\n\nThis requirement includes new rules regarding the review of user accounts and their privileges, as well as the management and privileges of applications and system accounts.\n\n* 7.1 Processes and mechanisms for restricting access to system components and cardholder data by business need to know are defined and understood.\n* 7.2 Access to system components and data is appropriately defined and assigned.\n* 7.3 Access to system components and data is managed via an access control system(s).\n\n### 8. Identify Users and Authenticate Access to System Components \n\nMany new sections regarding MFA, credentials and the entire authentication process have been added in this requirement. Two examples of changes that companies compliant with PCI DSS have to implement now are: the minimum length of a user account password has increased from 7 to 12 characters, and companies are not allowed to store passwords/passphrases in scripts or files.\n\n* 8.1 Processes and mechanisms for identifying users and authenticating access to system components are defined and understood.\n* 8.2 User identification and related accounts for users and administrators are strictly managed throughout an account’s lifecycle.\n* 8.3 Strong authentication for users and administrators is established and managed.\n* 8.4 Multi-factor authentication (MFA) is implemented to secure access into the CDE.\n* 8.5 Multi-factor authentication (MFA) systems are configured to prevent misuse.\n* 8.6 Use of application and system accounts and associated authentication factors is strictly managed.\n\n### 9. Restrict Physical Access to Cardholder Data \n\nThis requirement does not have many changes. Some sections that refer to roles and responsibilities, as well as the frequency of device inspections have been added.\n\n* 9.1 Processes and mechanisms for restricting physical access to cardholder data are defined and understood.\n* 9.2 Physical access controls manage entry into facilities and systems containing cardholder data.\n* 9.3 Physical access for personnel and visitors is authorized and managed.\n* 9.4 Media with cardholder data is securely stored, accessed, distributed, and destroyed.\n* 9.5 Point of interaction (POI) devices are protected from tampering and unauthorized substitution.\n\n### 10. Log and Monitor All Access to System Components and Cardholder Data \n\nNew sections in this requirement regulate the automation of logging, prompt response to failed security controls, as well as how often logs should be reviewed:\n\n* 10.1 Processes and mechanisms for logging and monitoring all access to system components and cardholder data are defined and documented.\n* 10.2 Audit logs are implemented to support the detection of anomalies and suspicious activity, and the forensic analysis of events.\n* 10.3 Audit logs are protected from destruction and unauthorized modifications.\n* 10.4 Audit logs are reviewed to identify anomalies or suspicious activity.\n* 10.5 Audit log history is retained and available for analysis.\n* 10.6 Time-synchronization mechanisms support consistent time settings across all systems.\n* 10.7 Failures of critical security control systems are detected, reported, and responded to promptly.\n\n### 11. Test Security of Systems and Networks Regularly\n\nThis category includes the following:\n\n* a new requirement to manage all applicable vulnerabilities,\n* a new requirement to perform internal vulnerability scans via authenticated scanning,\n* a new requirement to deploy a change-and-tamper-detection mechanism to alert for unauthorized modifications to the HTTP headers and contents of payment pages as received by the consumer browser, [according to PCI SSC](https://listings.pcisecuritystandards.org/documents/PCI-DSS-v3-2-1-to-v4-0-Summary-of-Changes-r1.pdf).\n\nThe full list of the sections included in this requirement is:\n\n* 11.1 Processes and mechanisms for regularly testing security of systems and networks are defined and understood.\n* 11.2 Wireless access points are identified and monitored, and unauthorized wireless access points are addressed.\n* 11.3 External and internal vulnerabilities are regularly identified, prioritized, and addressed.\n* 11.4 External and internal penetration testing is regularly performed, and exploitable vulnerabilities and security weaknesses are corrected.\n* 11.5 Network intrusions and unexpected file changes are detected and responded to.\n* 11.6 Unauthorized changes on payment pages are detected and responded to.\n\n### 12. Support Information Security with Organizational Policies and Programs\n\nThe title modification reflects that the focus is on organizational policies and programs. In PCI DSS version 4, requirements specify that the audited company should, at least every 12 months:\n\n* document and review cryptographic cipher suites and protocols,\n* review hardware and software components,\n* document the PCI DSS scope,\n* review and update the security awareness program, among other requirements, which are presented below.\n\n \n\n* 12.1 A comprehensive information security policy that governs and provides direction for protection of the entity’s information assets is known and current.\n* 12.2 Acceptable use policies for end-user technologies are defined and implemented.\n* 12.3 Risks to the cardholder data environment are formally identified, evaluated, and managed.\n* 12.4 PCI DSS compliance is managed.\n* 12.5 PCI DSS scope is documented and validated.\n* 12.6 Security awareness education is an ongoing activity.\n* 12.7 Personnel are screened to reduce risks from insider threats.\n* 12.8 Risk to information assets associated with third-party service provider (TPSP) relationships is managed.\n* 12.9 Third-party service providers (TPSPs) support their customers’ PCI DSS compliance.\n* 12.10 Suspected and confirmed security incidents that could impact the CDE are responded to immediately.\n\n## What do you have to do now? \n\nYou have to become PCI-DSS version 4 certified until the 31st of March 2024. There are two possible paths for your company:\n\n1. Your company is already PCI-DSS certified, so until the first deadline you must cover some of the new requirements and until the last deadline all of them, or\n2. Your company is not PCI-DSS certified, so you have to start from the beginning with the new PCI-DSS version and fulfill all requirements according to the specified deadlines.\n\nThis new version of PCI DSS brings considerable changes, and the process of achieving compliance with PCI DSS can be long and cumbersome.\n\nCyscale helps companies accelerate their cloud compliance process and ace audits by providing:\n\n* security controls that check if you’re implementing the requirements correctly, and\n* a page for each standard where you can track your progress and history.\n"},"suggestions":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News","Cloud Native Security"],"title":"Container Escaping with Leaky Vessels: A New Docker Vulnerability with 8.6 Severity ","seoTitle":"Container Escaping with Leaky Vessels: A New Docker Vulnerability with 8.6 Severity ","description":"Vulnerabilities in the runc CLI tool could allow attackers to escape containers and move laterally though a Kubernetes or cloud environment.","seoDescription":"Vulnerabilities in the runc CLI tool could allow attackers to escape containers and move laterally though a Kubernetes or cloud environment.","date":"2024-02-27T14:48:18.017Z","featuredpost":true,"permalink":"container-escaping-leaky-vessels-docker-vulnerability","featuredimage":{"publicURL":"/static/05f06f8d8982982a16b18b6104ea387f/leaky-vessels-container-escape.jpg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/05f06f8d8982982a16b18b6104ea387f/2c0f5/leaky-vessels-container-escape.jpg","srcSet":"/static/05f06f8d8982982a16b18b6104ea387f/41be8/leaky-vessels-container-escape.jpg 205w,\n/static/05f06f8d8982982a16b18b6104ea387f/c78f7/leaky-vessels-container-escape.jpg 410w,\n/static/05f06f8d8982982a16b18b6104ea387f/2c0f5/leaky-vessels-container-escape.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/05f06f8d8982982a16b18b6104ea387f/913d0/leaky-vessels-container-escape.webp 205w,\n/static/05f06f8d8982982a16b18b6104ea387f/91660/leaky-vessels-container-escape.webp 410w,\n/static/05f06f8d8982982a16b18b6104ea387f/888e2/leaky-vessels-container-escape.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"New vulnerabilities revealed in the runc command line tool could be exploited to allow attackers to escape containers and potentially get unauthorized access to the host operating system and move laterally though a Kubernetes or cloud environment.  \n\n## What are the Leaky Vessels vulnerabilities? \n\nOn the 31st of January 2024, Snyk revealed four Docker container vulnerabilities with a critical security score ranging between 8.6 and 10. These vulnerabilities allow attackers to escalate privileges and escape containers, gaining access to the underlying instance and possibly compromising secrets and other resources.  \n\nAn attacker exploiting an orchestration-based setup utilizing runc, such as Kubernetes, could execute a breakout onto the underlying Kubernetes node. In multi-tenant environments, pods from different tenants can share nodes, meaning a breakout could lead to unauthorized access to other pods belonging to other tenants. \n\nThe vulnerabilities affect runc, a container runtime, and Buildkit, a builder for docker: \n\n* [CVE-2024-21626](https://nvd.nist.gov/vuln/detail/CVE-2024-21626) \n* [CVE-2024-23651](https://nvd.nist.gov/vuln/detail/CVE-2024-23651) \n* [CVE-2024-23653](https://nvd.nist.gov/vuln/detail/CVE-2024-23653) \n* [CVE-2024-23652](https://nvd.nist.gov/vuln/detail/CVE-2024-23652) \n\nCVE-2024-21626, which affects runc, has a severity of 8.6. It occurs in runc versions 1.1.11 and earlier, so updating the CLI tool to version 1.1.12 would patch this vulnerability. \n\n## How does the Leaky Vessels exploit work? \n\nBy leveraging the “WORKDIR” command, the attacker can spawn a new process and have a working directory in the host’s filesystem. This can be done either by running a malicious image or by building a container image using a malicious Dockerfile. These two attacks can also be used to overwrite host binaries, thus escaping the container. \n\nContainer escape elevates the attackers’ privileges and opens up other possibilities; by having access to the underlying system of a container, a hacker can access files and secrets on the host and even move laterally to compromise other systems. \n\n<img src=\"/img/vulnerability-cyscale-leaky-vessels.png\" alt=\"\" title=\"\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n## How do you fix it? \n\nTo determine if this vulnerability exists in your cloud or Kubernetes environment, you can [start a free risk assessment with Cyscale](https://cyscale.com/cloud-security-risk-assessment/). The Cyscale cloud security platform immediately detects vulnerabilities that can affect your cloud security posture and provides actionable remediation steps to help you fix findings quickly.\n\n<div class='col-span-12 lg:col-span-6 flex items-center justify-center'>\n         <p class='font-montserrat font-bold' id=\"paragraph-text-button\">\n            See How Cyscale Helps Protect Against<span id=\"font-gradient\">Leaky Vessel</span> Vulnerabilities\n        </p>\n    </div>\n    <div class='col-span-12 lg:col-span-4 flex justify-center items-center'>\n        <a class='mx-auto bg-gradient-to-r from-\\\\[#0F26AA] to-\\\\[#FF4A56] hover:from-\\\\[#FF4A56] hover:to-\\\\[#0F26AA] block font-medium rounded uppercase text-center no-underline hover:no-underline max-w-sm lg:inline-block font-hind' href='https://cyscale.com/cloud-security-risk-assessment/>\n            <span style='padding: 0.625rem 2.5rem' class='text-white block'>\n                Start Risk Assessment\n            </span>\n        </a>\n    </div>\n</div>"}},{"node":{"frontmatter":{"authors":"Ovidiu Cical","categories":["News","IAM"],"title":"Human and Non-Human Identity Management for Multi-Cloud","seoTitle":"Human and Non-Human Identity Management for Multi-Cloud","description":"To effectively use the cloud, you need to be able to trust non-human identities like service accounts used by applications, and third-parties. ","seoDescription":"To effectively use the cloud, you need to be able to trust non-human identities like service accounts used by applications, and third-parties. ","date":"2024-02-21T14:45:48.245Z","featuredpost":true,"permalink":"human-non-human-identity-management-multi-cloud","featuredimage":{"publicURL":"/static/2d02fbd03b9db96ca496e25efb12f75b/human-non-human-identity-cloud.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/2d02fbd03b9db96ca496e25efb12f75b/d6cae/human-non-human-identity-cloud.png","srcSet":"/static/2d02fbd03b9db96ca496e25efb12f75b/ac644/human-non-human-identity-cloud.png 205w,\n/static/2d02fbd03b9db96ca496e25efb12f75b/89b47/human-non-human-identity-cloud.png 410w,\n/static/2d02fbd03b9db96ca496e25efb12f75b/d6cae/human-non-human-identity-cloud.png 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/2d02fbd03b9db96ca496e25efb12f75b/913d0/human-non-human-identity-cloud.webp 205w,\n/static/2d02fbd03b9db96ca496e25efb12f75b/91660/human-non-human-identity-cloud.webp 410w,\n/static/2d02fbd03b9db96ca496e25efb12f75b/888e2/human-non-human-identity-cloud.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"So far, Cyscale has focused on making it easy to see **who** (colleagues, collaborators, guests, fellow humans) has access to your cloud environments. Now you can also see **what**.  \n\n## Why are non-human identities important? \n\nNearly 90% of organizations routinely provide access privileges to non-humans, and 50% admit they have granted inappropriate access to non-humans*. But a similar number (54%) also revealed that inappropriate access granted to a non-employee or non-human has resulted in severe incidents, such as lost control of resources, data loss, and direct security breaches.    \n\n## Non-humans run the cloud \n\nIt’s become widely accepted that to effectively use the cloud, you need to trust non-human identities with access to resources and data in your environment. Such identities include service accounts used by applications, services, and third-party vendors. \n\nBut we frequently encounter environments among our own customer base with a non-human identity attached to a machine that has high or inappropriate privileges, is publicly accessible from the internet, and has a vulnerability.  \n\nAny attacker capable of exploiting that identity will be able to move laterally in the environment. \n\n## But humans use the cloud \n\nWhile it’s well established that [IAM (Identity and Access Management) plays an important role in a company’s security and compliance posture](https://cyscale.com/products/ciem/), and most organizations have specific policies in place so that the process of handling identities and access is well documented and manageable, the life of a CISO, CTO, or security analyst gets more difficult if they need to go into more depth. \n\nLet’s say you have an employee that’s leaving in a month, and you need to see a list of all the resources they have access to? Or you discover some unusual logs on one of your VMs and need to know who has access to it? These questions are not so easy to answer from your AWS, Azure, or Google Cloud console. \n\n<div class='grid grid-cols-12 mt-12 gap-2'>\n  <div class='col-span-12 lg:col-span-6'>\n    <img src=\"/img/inventory-permissions.png\" alt=\"Inventory display of assets accessible to user\" class=\"rounded-md\" style=\"width: 100%; margin: 0;\" />\n  </div>\n  <div class='col-span-12 lg:col-span-6'>\n    <img src=\"/img/inventory-accessible.png\" alt=\"Inventory view of database access control\" class=\"rounded-md\" style=\"width: 100%; margin: 0;\" />\n  </div>\n</div>\n\n\n<div class='mt-16 rounded-tl-2xl rounded-b-2xl grid grid-cols-12 gap-4 bg-zircon py-8 px-4 lg:py-4' style='borderTopRightRadius: 3rem'>\n    <div class='col-span-12 lg:col-span-2'>\n        <div class='flex justify-center'>\n            <img src='/img/cloud-icon-widget.svg' alt='' id='img-text-button' />\n        </div>\n    </div>\n    <div class='col-span-12 lg:col-span-6 flex items-center justify-center'>\n         <p class='font-montserrat font-bold' id=\"paragraph-text-button\">\n            See How Cyscale Helps Protect <span id=\"font-gradient\">Human and Non-Human</span> Identities\n        </p>\n    </div>\n    <div class='col-span-12 lg:col-span-4 flex justify-center items-center'>\n        <a class='mx-auto bg-gradient-to-r from-[#0F26AA] to-[#FF4A56] hover:from-[#FF4A56] hover:to-[#0F26AA] block font-medium rounded uppercase text-center no-underline hover:no-underline max-w-sm lg:inline-block font-hind' href='https://cyscale.com/products/ciem/'>\n            <span style='padding: 0.625rem 2.5rem' class='text-white block'>\n                Show me\n            </span>\n        </a>\n    </div>\n</div>\n\n## Cloud identity management is hard \n\nPopular security tools offered by the public cloud providers suffer from two main problems:  \n\n**1a)** They don’t really support comprehensive identity and access management functionality at all. They display users, roles, policies other IAM related entities, up to Permissions but that’s where they draw the line. The result is that you can’t state “User X has access to Resources A, B and C”.  \n\n**1b)** Let’s not even get started with non-human identities where a resource can use a service identity to access another resource.  \n\n **2)** They’re not meant specifically for this use case and require mastering some tools and languages beforehand such as Azure Resource Graph.  \n\nThis particular challenge is compounded by multi-cloud environments because the tools and the skills to use them, are not cross compatible.  \n\nLet’s say you’ve decided to go for the in-house tools from cloud providers and that you have an identity provider that helps you provision your users, groups and roles in your AWS and Azure environments. At this point, the users will receive access to both clouds.  \n\nSo, this means that managing identities will require two distinct sets of skills: both familiarity with the AWS IAM Access Analyzer and skills for easily getting from policies to resources AND knowledge of the query language used by Azure for exploring its Resource Graph.  \n\nOf course, there’s the alternative of using CLI tools to perform this analysis. There are even some great open-source tools to help you achieve the goal. However, this approach has its own limitations, like any CLI tool, and, if you’d like to go more in depth and see how the accessibility of a resource can impact other parts of the infrastructure, your journey stops there. \n\n## Managing human and non-human identities in Cyscale \n\nOur updated Identity dashboard now gives you an overview of the identities of your workloads across compute services (VMs, serverless, containers) and deep dive options to better understand the permissions, both human and non-human, when necessary, so you can now see: \n\n* A simplified view for each asset in your inventory, which tells you: \n* Who / What can access that asset  \n* What other resources can be accessed by that asset as a machine or non-human identity \n\n<img src=\"/img/identity-dashboard-service-accs.png\" alt=\"The Cyscale Identity dashboard\" title=\"\" class=\" blog-image-shadow \" style=\"width:90%;height:auto;\"/>\n\n\\*﻿\\*SailPoint: <https://www.sailpoint.com/blog/survey-finds-non-employee-and-non-human-identities-leading-to-major-security-issues/>\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security","Cloud Native Security"],"title":"Multi-Cloud Security: What CISOs & CTOs Need to Know ","seoTitle":"Multi-Cloud Security: What CISOs & CTOs Need to Know ","description":"While multi-cloud gives several advantages, be careful not to compromise on security and visibility, giving the CISO or CTO sleepless nights. ","seoDescription":"While multi-cloud gives several advantages, be careful not to compromise on security and visibility, giving the CISO or CTO sleepless nights.","date":"2024-02-19T11:40:03.512Z","featuredpost":true,"permalink":"multi-cloud-security-what-ciso-cto-needs-to-know","featuredimage":{"publicURL":"/static/3058bebce95f82354b0fdf82bb3ef1cc/multicloud-security-ciso-cto.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/3058bebce95f82354b0fdf82bb3ef1cc/d6cae/multicloud-security-ciso-cto.png","srcSet":"/static/3058bebce95f82354b0fdf82bb3ef1cc/ac644/multicloud-security-ciso-cto.png 205w,\n/static/3058bebce95f82354b0fdf82bb3ef1cc/89b47/multicloud-security-ciso-cto.png 410w,\n/static/3058bebce95f82354b0fdf82bb3ef1cc/d6cae/multicloud-security-ciso-cto.png 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/3058bebce95f82354b0fdf82bb3ef1cc/913d0/multicloud-security-ciso-cto.webp 205w,\n/static/3058bebce95f82354b0fdf82bb3ef1cc/91660/multicloud-security-ciso-cto.webp 410w,\n/static/3058bebce95f82354b0fdf82bb3ef1cc/888e2/multicloud-security-ciso-cto.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":true},"rawMarkdownBody":"## Why go multi-cloud? It’s not always by choice \n\nA multi-cloud strategy can combine the best of two (or more!) worlds, allowing cloud-native organizations to choose best-of-breed options for building apps and storing data in the cloud. At least this is true when the multi-cloud approach is by design.  \n\nIt’s not unheard of for a multi-cloud approach to happen by accident. Along with [mergers and acquisitions that force two IT estates together](https://cyscale.com/blog/cloud-security-assessment-vital-part-mergers-acquisitions/), so-called ‘shadow IT’ is a significant problem – where teams make use of an unapproved solution resulting in a complex cloud infrastructure that spans across different cloud vendors.  \n\nWhile [multi-cloud](https://cyscale.com/blog/cloud-native-tools-multi-cloud/) companies can gain numerous advantages - each public cloud has its own strengths - the downsides should not be disregarded, especially if they mean compromising on security and visibility and giving the CISO or CTO sleepless nights. \n\n## Advantages and disadvantages of multi-cloud \n\nCTOs in cloud-native businesses typically choose multiple cloud providers, such as AWS, Azure, Google Cloud, Alibaba, and others, to maximize the potential of their tech stack and access a broader range of features. Azure is known for its tight integration with other Microsoft products, AWS has strong support for general enterprise compute and storage, while Google Cloud has sought to differentiate with a focus on Machine Learning. The latest battleground is on AI and LLM support.  \n\nBut companies with legacy infrastructure, or those in highly regulated industries such as finance and healthcare, may also have on-premises assets as well, resulting in a hybrid mix of private and public cloud infrastructure. \n\n### Key reasons to consider a multi-cloud approach: \n\n* **Flexibility:** Since you have access to multiple cloud providers, you can choose the service that best suits your needs out of a pool of options. For example, if you want to store data in a storage asset, you don’t necessarily have to go with a bucket from AWS; you can also consider a storage account in Azure or weigh out your options based on integration with other software, pricing variables, or even geography.  \n* **Optimizing costs:** Although broadly speaking, different clouds stack up in a like-for-like comparison, there are subtle but important differences in how each provider does things and charges for them. So, the flexibility of choosing services from different providers allows organizations to optimize costs effectively, avoiding unnecessary expenses and ensuring that resources are allocated efficiently. \n* **Redundancy and high availability:** Distributing data across multiple cloud platforms ensures high availability and redundancy. If one provider experiences downtime or disruptions, data remains accessible from alternative sources, minimizing the risk of service interruptions. \n* **Geo-location options:** By distributing data across vendors, you can be closer to end-users from all around the world, reducing latency and improving overall user experience. Moreover, for data sovereignty reasons, you can also ensure compliance with various standards that may require that data stays inside a particular country or geographical location. This is a particularly important consideration in regulated sectors but can just as easily apply to any company that deals with customer data – which is pretty much every company. The EU’s GDPR privacy regulation is a prime compliance example, and the US is catching up now with state-specific considerations, like California’s CCPA.  \n\n## Risks and downsides of multi-cloud \n\n* **Added complexity:** An infrastructure that spans across cloud vendors is inherently more complex and more challenging to manage and secure. This is a daunting task for any CTO and engineering team. Each cloud provider has its own naming conventions, service structures, deployment models, API endpoints, and more, meaning both engineering and security professionals often forget best practices for each specific service, which can and will introduce security gaps in the company. \n* **Reduced visibility:** This is a big one. There is no security without [visibility](https://cyscale.com/blog/provide-visibility-in-cloud-okta-integration/) in the cloud, after all, you can’t secure what you can’t see. And something that’s less obvious but even more important in the cloud is context. When you can’t see all your assets, you can’t understand the relations between them and how a misconfiguration on one asset affects another. This also goes for users (both human and non-human identities) and their permissions. Without comprehensive visibility and inventory, you cannot identify vulnerabilities and gaps in your security.  \n* **The need for cloud-specific skills:** Being an expert in Azure does not directly translate to AWS and vice-versa. Same with any other cloud. All vendors have different assets, each with their own technologies, settings, security best practices, even naming conventions.  \n\n\n<div class='mt-16 rounded-tl-2xl rounded-b-2xl grid grid-cols-12 gap-4 bg-zircon py-8 px-4 lg:py-4' style='borderTopRightRadius: 3rem'>\n    <div class='col-span-12 lg:col-span-2'>\n        <div class='flex justify-center'>\n            <img src='/img/cloud-icon-widget.svg' alt='' id='img-text-button' />\n        </div>\n    </div>\n    <div class='col-span-12 lg:col-span-6 flex items-center justify-center'>\n         <p class='font-montserrat font-bold' id=\"paragraph-text-button\">\n             See How Cyscale Helps Protect<br class=\"hidden lg:block\"/> Your <span id=\"font-gradient\">Multi-Cloud Estate</span>\n        </p>\n    </div>\n    <div class='col-span-12 lg:col-span-4 flex justify-center items-center'>\n        <a class='mx-auto bg-gradient-to-r from-[#0F26AA] to-[#FF4A56] hover:from-[#FF4A56] hover:to-[#0F26AA] block font-medium rounded uppercase text-center no-underline hover:no-underline max-w-sm lg:inline-block font-hind' href='/full-platform-tour/'>\n            <span style='padding: 0.625rem 2.5rem' class='text-white block'>\n                Show me\n            </span>\n        </a>\n    </div>\n</div>\n\n## Making multi-cloud work and keeping your estate protected \n\nSo, how do you leverage the advantages of multi-cloud and keep the downsides of having to manage and secure a multi-cloud environment under control? Let’s look at some best practices along with actionable insights to enhance data security in multi-cloud deployments. \n\n### 1. Achieve visibility of your multi-cloud estate \n\nContinuous visibility is the first step to securing a multi-cloud infrastructure. To achieve this, centralize an inventory of your clouds in one single place using a [CNAPP](https://cyscale.com/products/cnapp/) (Cloud-Native Application Protection Platform). Having one or two dashboards that showcase your entire inventory across cloud service providers is more manageable and gives you an integrated picture versus switching tabs and constantly having to look up resources in each specific cloud console or portal.  \n\n### 2. Continuous monitoring to keep up with your clouds \n\nMonitoring goes hand in hand with visibility. By ensuring continuous logging and monitoring, your security team can identify suspicious behavior in real-time, and be aware of what’s happening in the cloud. Sudden spike in resource usage or anomalous behavior? Time to investigate. Centralize logs to have everything in one place and obtain a comprehensive view of the cloud. \n\n### 3. Achieve and maintain compliance with international frameworks \n\nInternational standards and laws like ISO 27001, SOC 2, GDPR, and HIPAA enforce security requirements that are meant to prevent data breaches within companies. By becoming compliant with such frameworks, you're not only strengthening your organization's cloud security posture but also showing customers that you're making efforts toward securing their data. In fact, even as the cloud skills gap has increased, so has the expectation of provable security. ISO saw an increase of 51% in ISO 27001 certifications between 2020 and 2022, as more buyers demand compliance from suppliers. Compliance applies across all security providers, and multi-cloud companies are not exempted. You should use a CNAPP to track your efforts and ace your audits by showing comprehensive reports that demonstrate your ongoing efforts. \n\n### 4. Prioritize cloud resources to optimize security efficiency  \n\nSegment your assets based on their criticality to business operations and data sensitivity. Identify the core components that, if compromised, could have severe consequences for your organization. By categorizing assets, you establish a hierarchy that guides the allocation of security resources and efforts, and in a world where both cloud and cyber skills are in short supply, optimizing your efforts is key. A CNAPP tool can help perform this prioritization based on the severity of existing vulnerabilities and misconfigurations, as well as how many other assets a cloud resource impacts or is related to. This can make the difference between a quick fix in a typical workday or a data breach that can cost a company a fortune in remediation, fines, or reputational damage.  \n\n### 5. Use automation to make security teams more efficient \n\nDepending on the skills and human resources available to you, some CTOs and CISOs might be able to easily accomplish the things we’ve discussed in a simple cloud environment, while those with reduced resources might struggle already. But there’s no denying that when you introduce another cloud provider (or two) into the discussion, a manageable manual workload quickly turns into an overwhelming mountain. For example, access reviews in a multi-cloud infrastructure are nearly impossible to do traditionally; you would have to go back and forth between identity providers and clouds and assess each permission at a time. Not only is this a very tedious job that creates lots of room for mistakes, it’s the soul-destroying kind of task that stops security teams doing work they find enriching and putting them on the lookout for other opportunities.  \n\nModern cloud security solutions such as a CNAPP however, aggregate all this information in one place, making your people more efficient, and suddenly applying the Least Privilege Principle no longer seems daunting.  \n\n## Overcoming the complexity of multi-cloud  \n\nThe complexities introduced by added infrastructure layers, each with their own approaches, and the need for cross-cloud expertise demand a proactive approach to security. While multi-cloud environments promise significant opportunities, it is important to address the associated risks, especially those related to complexity, reduced visibility, and the evolving skill set requirements. In this case, prevention really is better than cure, but as with all security, some ‘cure’ is inevitable.  \n\nWith a lack of cloud experience and cyber skills on the market, cloud native organizations should really be looking at CNAPP (Cloud-Native Application Protection Platform)-type solutions to enhance and augment existing human resources and skills with the aim of achieving a robust cloud security posture in a multi-cloud setup. \n\n[Cyscale’s CNAPP](https://cyscale.com/full-platform-tour/) is the only tool of its kind that has been designed to be deployed and used by smaller teams, helping the CTO or CISO and your security team gain the confidence to acquire visibility, prioritize assets, ace audits for compliance benchmarks, and perform other operations that actually serve the business, rather than endless firefighting across the multi-cloud estate.  \n\n\n<div class='mt-16 rounded-tl-2xl rounded-b-2xl grid grid-cols-12 gap-4 bg-zircon py-8 px-4 lg:py-4' style='borderTopRightRadius: 3rem'>\n    <div class='col-span-12 lg:col-span-2'>\n        <div class='flex justify-center'>\n            <img src='/img/cloud-icon-widget.svg' alt='' id='img-text-button' />\n        </div>\n    </div>\n    <div class='col-span-12 lg:col-span-6 flex items-center justify-center'>\n         <p class='font-montserrat font-bold' id=\"paragraph-text-button\">\n             Take a Tour of<span id=\"font-gradient\">Cyscale's CNAPP</span>Today\n        </p>\n    </div>\n    <div class='col-span-12 lg:col-span-4 flex justify-center items-center'>\n        <a class='mx-auto bg-gradient-to-r from-[#0F26AA] to-[#FF4A56] hover:from-[#FF4A56] hover:to-[#0F26AA] block font-medium rounded uppercase text-center no-underline hover:no-underline max-w-sm lg:inline-block font-hind' href='/full-platform-tour/'>\n            <span style='padding: 0.625rem 2.5rem' class='text-white block'>\n                Start now\n            </span>\n        </a>\n    </div>\n</div>"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security","Cloud Native Security","CNAPP"],"title":"Azure Key Vault Explained: Data Plane vs. Management Plane, Access Roles and More","seoTitle":"Azure Key Vault Explained: Access Roles and More","description":"Azure Key Vault securely stores secrets, certificates, and cryptographic keys and facilitates their usage by applications and services. ","seoDescription":"Azure Key Vault securely stores secrets, certificates, and cryptographic keys and facilitates their usage by applications and services. ","date":"2024-02-07T11:00:24.062Z","featuredpost":true,"permalink":"azure-key-vault-explained","featuredimage":{"publicURL":"/static/5b67d3e57f404fbc2a0a65566e9551de/azure-key-vault-explained.jpg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/5b67d3e57f404fbc2a0a65566e9551de/2c0f5/azure-key-vault-explained.jpg","srcSet":"/static/5b67d3e57f404fbc2a0a65566e9551de/41be8/azure-key-vault-explained.jpg 205w,\n/static/5b67d3e57f404fbc2a0a65566e9551de/c78f7/azure-key-vault-explained.jpg 410w,\n/static/5b67d3e57f404fbc2a0a65566e9551de/2c0f5/azure-key-vault-explained.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/5b67d3e57f404fbc2a0a65566e9551de/913d0/azure-key-vault-explained.webp 205w,\n/static/5b67d3e57f404fbc2a0a65566e9551de/91660/azure-key-vault-explained.webp 410w,\n/static/5b67d3e57f404fbc2a0a65566e9551de/888e2/azure-key-vault-explained.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"<!--StartFragment-->\n\nAzure Key Vault is a safe place for cloud security professionals who want to keep their secrets… well, secret! And while it’s your safest bet to keep your crypto keys, certificates, and other secrets safe, it can become your worst enemy if you don’t manage it correctly. \n\n## What is Azure Key Vault? \n\nBefore we begin looking at best practices and security features of Key Vault, let’s go over the basics. \n\nAzure Key Vault is a Microsoft Azure product that securely stores secrets, certificates, and cryptographic keys and facilitates their usage by applications and services. It also allows users to manage a key's lifecycle, from key generation to destruction. \n\n*Did you know that if you create a key in a Key Vault, you can never actually see it? This is to safeguard against a human leaking the key. This also applies to imported keys.* \n\nAzure Key Vault has two service tiers: Standard and Premium. The only difference between them is that Premium allows HSM protection for keys. HSM (Hardware Security Module) provides hardware security on top of the software security supplied by Azure as a fully managed, single tenant, premium safeguard. This is the most stringent security measure that can be applied to crypto keys. \n\n## Access control management in Azure Key Vault \n\nKey Vault authorization is done on two different planes: \n\n* The management plane, which allows users to delete key vaults, update access policies, and see properties, and \n* The data plane, where Key Vault objects can be added, deleted and modified. \n\nBasically, if you have access to the management plane, you can modify the cloud resource but have no access to the actual data in it. The opposite goes for the data plane, where you can make operations on the secrets, keys, and certificates but cannot, for example, add or remove access policies. You can delete a key, but not the actual key vault. \n\nNow that we know the difference between the two planes, let's look at some of the most used built-in RBAC roles for Key Vaults. Remember that Role Base Access Controls (RBAC) are used to restrict access to the network based on the user’s role. \n\n*Authorization for the data plane can be done using Azure Key Vault access policies as well as RBAC roles, but for the management plane, only RBAC roles can be used. Access policies are now considered legacy, and we recommend using RBAC.* \n\nAnd while access control policies help you define fine-grained control over objects and resources, this is not the way to go anymore. Policies are not a centralized management solution, meaning that you can’t just see and change permissions in one place; you would have to check each policy to see what a user's effective permissions are. Moreover, removing permissions can be difficult; the user no longer needs access to keys? Instead of going over one or more policies and unchecking the boxes that give them access, you can just remove their Key Vault Crypto Officer role, and you’re done! That way you don’t risk forgetting about a policy in the process. \n\nTo transition from access policies to RBAC, assess current permissions for all users, change to an RBAC permission model, establish the correct roles for them (and follow the Least Privilege Principle), assign those roles, and thoroughly test the setup. And to know which Key Vault Roles to use, keep reading this article! \n\n## Roles in Azure Key Vault \n\nManaging access control correctly and using the appropriate role for the job is good practice for cloud security. Following the Least Privilege Principle and only providing the necessary permissions are the keys to minimizing attack surfaces and giving your cloud environment the best chance against attackers. \n\nLet’s look at some of the available built-in Key Vault roles provided by Microsoft Azure. Remember that these roles only work if you've set Azure RBAC as the permission model (which is recommended). \n\n1. **Key Vault Reader**: This role provides the user with permission to read metadata of key vaults and their objects (certificates, keys, secrets). \n2. **Key Vault Administrator**: As an Administrator, you have all data plane permissions on all types of objects. \n3. **Key Vault Secrets Officer, Key Vault Certificates Officer, Key Vault Crypto Officer**: These three roles allow users to perform all actions on the type of Key Vault object the role is for, except managing permissions. So, a Key Vault Certificates Officer would have permissions on certificates, and so on. \n4. **Key Vault Secrets User, Key Vault Crypto User**: These roles are similar to the previous one but have fewer permissions. The Secrets user can see the secret contents. The Crypto user can perform cryptographic operations using the keys stored in the Key Vault. *Notice how there’s no Key Vault Certificates User? The Secrets user can also read the secret portion of a certificate with a private key, so apps use this role to retrieve certificates.* \n\nKeep in mind that users who can manage permissions over the Key Vault can grant themselves data plane permissions by modifying the access policies, so this plane segregation only goes so far. For this reason, I will once again remind you – follow the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/)! Don't give users more permissions than the bare minimum they need to do their job.  \n\nExcess privileges can be a gateway to disaster.  \n\n## Safety and recovery features in Azure Key Vault \n\nAzure Key Vault has a very useful feature called **soft-delete**. This allows for Key Vaults and Key Vault objects to remain recoverable for a period of 7 to 90 days (if no period is specified, then the default is set to 90). So, if someone accidentally deletes something, it can still be recovered within that timeframe. \n\n*Soft-delete is set to Enabled by default for new Key Vaults, and if a Key Vault has soft-delete enabled, it can never be disabled.* By design, Azure Key Vault makes it hard for users to lose their keys! \n\nBesides soft-delete, there’s also **purge protection**. This is another safety feature that goes beyond soft-delete, by preventing accidental **permanent** deletion. If you want to protect your Azure Key Vault from deletion while it is in its soft-deleted state, it ensures that no-one can delete it before the soft-delete period is over. **Once purge protection is enabled, just like soft-delete, it cannot be disabled.**  \n\nTo purge a Key Vault or a Key Vault object, you must have special permissions that are not, by default, given to any role. *The argument –enable-purge-protection can also be set to true to prevent anyone from purging a resource.*  \n\nIf this sounds all complicated, we can sum it up easily: once you delete a soft-delete-enabled Key Vault resource, it goes into the soft-delete state for a set period. If you also have purge protection enabled, you can't force delete it before that period is up. It's a layered protection model; you must go through multiple steps to delete a resource, making it as fool-proof as possible.  \n\nIn terms of backup, Azure recommends that you only backup secrets that are business critical; due to the nature of Key Vaults, the objects stored in them are already ensured availability: “Key Vault maintains availability in disaster scenarios and will automatically failover requests to a paired region without any intervention from a user”.  \n\nYou also can't back up your vault. It can be an annoyance, but you must back up each object and then restore them one by one. To do this, you download a blob containing the secret in an encrypted form, which you can then upload back in your Azure Key Vault. You have to upload it back in the same subscription to be able to use it (and, of course, in Azure Key Vault, not somewhere else). \n\n## Logging and protection in Azure Key Vault \n\nBesides following the best practices described in this article, you can also enable **Microsoft Defender for Key Vault**. This enables: \n\n* threat detection,  \n* threat intelligence,  \n* anomaly detection, and  \n* behavior analytics. \n\nAlso, don't forget about logging! Ensure to log user activity to identify suspicious behavior and obtain an audit trail to identify who accessed Key Vaults and when. \n\nYou can find all of these best practices and more in the Cyscale app, where we highlight misconfigurations and give you step-by-step instructions on configuring Azure Key Vaults correctly and keeping your secrets safe. \n\n<video width=\"auto\" height=\"auto\" controls=\"\" tabindex=\"2\"><source src=\"https://d3n52qn7viv754.cloudfront.net/videos/data-security-tour.mp4\" type=\"video/mp4\">Your browser does not support the video tag.</video>\n\n<!--EndFragment-->"}}]}},"staticQueryHashes":["1117504136","120001781","2024892666","2199015418","220583031","273821743","3058837307","3355083976","3722074465","4068795820","4109069157","81406208","981947644"],"slicesMap":{}}