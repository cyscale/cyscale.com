{"componentChunkName":"component---src-template-blog-all-posts-template-js","path":"/blog/9/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["IAM"],"title":"Okta Security Best Practices ","seoTitle":"Okta Security Best Practices ","description":"Okta is an identity and access management (IAM) service built for the cloud. Best practices for cloud access recommended by Okta are: multi-factor authentication (MFA), using passwordless authentication, complying to the least privilege principle, ensuring the separation of duties, monitoring and logging the activity in the company and automating onboarding and offboarding of employees. Cyscale ensures your company does not drift away from some of these best practices.","seoDescription":"Okta is an identity and access management (IAM) service built for the cloud that connects persons with applications through SSO, AD, LDAP MFA, B2B Integration, Mobile Identity Management, User Management etc. Best practices for cloud access recommended by Okta are: multi-factor authentication (MFA), using passwordless authentication, complying to the least privilege principle, ensuring the separation of duties, monitoring and logging the activity in the company and automating onboarding and offboarding of employees. Cyscale ensures your company does not drift away from some of these best practices.","date":"2022-05-19T07:40:18.390Z","featuredpost":true,"permalink":"iam-okta-security-best-practices","featuredimage":{"publicURL":"/static/92efc187d453834e74edca1259bb1e9c/okta-security-best-practices.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/92efc187d453834e74edca1259bb1e9c/888e2/okta-security-best-practices.webp","srcSet":"/static/92efc187d453834e74edca1259bb1e9c/913d0/okta-security-best-practices.webp 205w,\n/static/92efc187d453834e74edca1259bb1e9c/91660/okta-security-best-practices.webp 410w,\n/static/92efc187d453834e74edca1259bb1e9c/888e2/okta-security-best-practices.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nWhat is Okta? \n\nOkta is an [identity and access management (IAM)](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/) service built for the cloud. \n\nIt connects any person with any application securely through its features, such as: \n\n* Single Sign-On (SSO), \n* Active Directory (AD) and LDAP Integration, \n* Multi-Factor Authentication (MFA), \n* User Management, \n* B2B Integration for 3rd party access, \n* Mobile Identity Management, and others. \n\n### Okta Security Best Practices for Cloud Access \n\nOkta can be configured as an external identity provider to enable SSO in the cloud. \n\nLet's look at the best practices recommended by Okta and how you can make sure you're implementing them correctly to secure your cloud environment and keep your solutions protected.\n\n<br/>\n\n#### 1. Use multi-factor authentication (MFA) \n\n### Scenario \n\nAn employee uses a weak password for their accounts. The password was cracked through a brute-force attack by an attacker. \n\nThe employee re-uses their password for Okta SSO, and MFA is not implemented in the company, so the attacker now has full access to all of the employee's accounts. \n\n### Best practice \n\n[MFA](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/#MFA) is a type of authentication that requires an entity to provide at least two different types of credentials. \n\nThey should be of the following:  \n\n* What you know (example: a PIN)  \n* What you have (example: a security token)  \n* What you are (example: a fingerprint)  \n\nOkta recommends you use a one-time password or a biometric verification in your authentication scheme in order to add an extra layer of security. \n\n<br/>\n\n#### 2. Stop using passwords \n\n### Scenario \n\nAn employee writes their password on a post-it note and leaves it on their desk. \n\nAn employee from another department finds it and can now login into the employee's account. \n\n### Best practice \n\nPasswordless authentication is possible by providing a public identifier (such as a username or an email address) and then using a different way of proving your identity (through a phone or a token, for example), thus eliminating the use of passwords. \n\nThis type of authentication is secure because: \n\n* Weak passwords are no longer a concern for your company \n* Solutions for password storage are not an issue anymore \n* The credentials cannot be breached; therefore, you're reducing the number of points of failure \n\nOkta suggests solutions that can help you go passwordless. You can use: \n\n* Okta Fastpass, which allows you to authenticate passwordless from any device or location to any Okta-managed application; \n* WebAuthn, a standard that simplifies authentication. \n\n<br/>\n\n#### 3. Manage user access by following the Least Privilege Principle \n\n### Scenario \n\nAlthough they do not require such privileges, an employee was assigned administrative rights. \n\nThe employee accidentally deletes an asset—this action results in permanent data loss. \n\n### Best practice \n\nThe Least Privilege Principle states that users should not have more permissions than they require to perform their tasks. \n\nUser access control management is a security best practice recommended by [Okta](https://www.okta.com/) that helps minimize the risk of data breaches or accidental misconfigurations. \n\nFor example, a regular user should not have administrator rights unless they need them for daily tasks. \n\nMake sure to restrict users as much as possible in accordance with their jobs. \n\n<br/>\n\n#### 4. Ensure the Separation of Duties \n\n### Scenario \n\nThe administrator goes on vacation. They are the only ones with administrator privileges.  \n\nA critical vulnerability appears in the cloud infrastructure, but nobody has the necessary rights to patch it. The administrator cannot be contacted and is out of the office for a few weeks. \n\n### Best practice \n\nThe Separation of Duties Principle helps eliminate a single point of failure by assuring no entity has the rights to execute a critical task by themselves. \n\nConfiguring at least two administrators eliminates the single point of failure. It ensures that if one of them is missing, the other can still perform tasks requiring administrative privileges. \n\n<br/>\n\n#### 5. Monitor activity \n\n### Scenario \n\nAn attacker manages to gain control of an employee's account and authenticates from a different device or an unusual location. \n\nThis authentication is logged, but the logs are not carefully monitored, so the breach goes undetected. \n\nThe hacker can now move laterally and compromise workstations, databases, and other accounts without raising any alarms in the company. \n\n### Best practice \n\nLogging and monitoring are two features that should be implemented in your cloud environment. \n\nThese technologies can help you identify suspicious behavior, such as: \n\n* **an impossible log-in**, for example when a user authenticates from two different parts of the world in a few minutes, \n* **a user connecting to an application from a different device than expected**, and others. \n\nOkta recommends that you constantly look for odd activity in your cloud infrastructure and make sure you take actions when you identify them, such as verifying a user's identity through MFA. \n\n<br/>\n\n#### 6. Automate onboarding and offboarding \n\n### Scenario \n\nA software developer leaves the company, but their account is not correctly deprovisioned.  \n\nThey can still contribute to GitHub repositories and modify production code. \n\n### Best practice \n\nThe process of onboarding or offboarding an employee can be tedious. \n\nThere should be a well-defined set of steps when an employee leaves the company. Automate as many of them as possible, to make sure that: \n\n* You correctly deprovision their account, and \n* They cannot access and make changes to your systems anymore. \n\nAlong with these Okta-centric recommendations, it's essential to ensure that your organization adheres to broader **[cloud security best practices](https://cyscale.com/blog/cloud-data-security-guide/)**. Diversifying your security strategies and keeping abreast of best practices in the wider cloud ecosystem provides a layered defense against potential threats.\n\n<br/>\n\nAre you following these best practices in your company? \n\nWith [Cyscale - Cloud Security Platform](https://cyscale.com/), you can detect drifts from some of these best practices recommended by Okta. \n\nCyscale checks if access to your cloud environment is correctly configured and is implementing the following: \n\n* Multi-Factor Authentication (MFA), \n* Logging and monitoring, \n* Access control, \n* Strong credential policies and many more. \n\nFurthermore, you can [onboard your Okta account into Cyscale](https://cyscale.com/use-cases/okta-cyscale-integration/) and get full visibility over identities in your organization and cloud permissions, along with a contextual analysis of access, cloud assets and sensitive data to reveal toxic combinations that put your organization at risk. \n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["IAM"],"title":"IAM Best Practices for AWS, Google Cloud and Azure","seoTitle":"IAM Best Practices for AWS, Google Cloud and Azure","description":"We look at best practices recommended by AWS, Azure and Google Cloud regarding securing IAM, like enabling MFA, rotating credentials and keys regularly, complying to the least privilege principle, implementing logging and monitoring, assigning permissions at group level. Examples of controls from the Cyscale application are shown.","seoDescription":"We look at best practices recommended by AWS, Azure and Google Cloud regarding securing IAM, like enabling MFA, rotating credentials and keys regularly, complying to the least privilege principle, implementing logging and monitoring, assigning permissions at group level. Examples of controls from the Cyscale application are shown.","date":"2022-05-11T06:39:36.105Z","featuredpost":true,"permalink":"iam-best-practices-from-aws-azure-gcp","featuredimage":{"publicURL":"/static/2ac40e1f538ac411f31af89f7bb00616/securing-iam.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/2ac40e1f538ac411f31af89f7bb00616/888e2/securing-iam.webp","srcSet":"/static/2ac40e1f538ac411f31af89f7bb00616/913d0/securing-iam.webp 205w,\n/static/2ac40e1f538ac411f31af89f7bb00616/91660/securing-iam.webp 410w,\n/static/2ac40e1f538ac411f31af89f7bb00616/888e2/securing-iam.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nAfter we've described the [IAM implementations for AWS, Google Cloud, and Azure](https://cyscale.com/blog/iam-services-in-aws-azure-gcp/), let's look at some of the security best practices they recommend and how to check if your cloud environment is implementing them. \n\nWith Cyscale, you can efficiently scan your cloud infrastructure and verify whether it follows the [IAM best practices](https://cyscale.com/blog/iam-best-practices-identity/) that we're going to describe in this article. \n\n<div id=\"MFA\">\n\n### Enable Multi-Factor Authentication (MFA) \n\nMulti-Factor Authentication is a form of authenticating where the user needs to provide at least two different credentials of different types.  \n\nThey should be of the following: \n\n* What you know (example: a password) \n* What you have (example: a smart card) \n* What you are (example: a fingerprint) \n\nA prevalent scenario of MFA is using a password and a code received on your phone to log in. This example combines \"What you know\" with \"What you have\".  \n\nHere are some of the controls implemented in Cyscale that check if MFA is configured for your cloud environment: \n\n* *Ensure multi-factor authentication (MFA) is enabled for all IAM users that have a console password* for AWS \n* *Ensure that multi-factor authentication is enabled for all privileged users* for Microsoft Azure \n* *Ensure that multi-factor authentication is enabled for all non-privileged users* for Microsoft Azure \n\nSSO (Single Sign-On) should also be integrated in the authentication scheme to grant access to individual users across multiple environments using just one set of credentials. \n\n</div>\n\n### Rotate credentials and keys regularly \n\nThis best practice is recommended across all vendors and should be implemented in your cloud infrastructure.  \n\nThis method helps minimize the impact if a key or a set of credentials is breached. \n\nIn the case of user credentials, passwords should be changed with new, different ones. \n\nWhen rotating keys, the old ones should be retired, and new keys should be generated. \n\nWe suggest that you rotate your keys and credentials at least every 90 days. \n\nSome examples of validation controls offered by Cyscale that check if credentials or keys are rotated regularly are: \n\n* *Ensure access keys are rotated every 90 days or less* for AWS (Amazon Web Services) \n* *Ensure API keys are rotated every 90 days* for Google Cloud\n* *Ensure IAM password policy expires passwords within 90 days or less* for AWS \n\nMoreover, a strong password policy should be implemented to prevent individuals from using weak passwords. \n\n### Comply with The Principle of Least Privilege \n\nConforming to The Principle of Lease Privilege is another essential best practice instilled in cloud security and recommended by the vendors we've discussed.  \n\nIn order to comply with this concept, you need to restrict user access to the least privileged access and eliminate all administrator and root user accounts that are not strictly necessary.  \n\nAWS recommends that you start setting up your policies with a minimum of possible permissions and add more on the go, if necessary, to correctly manage access control.  \n\nMake sure you're not missing anything when implementing the concept of least privilege by using controls offered by Cyscale that detect misconfigurations, like the ones below: \n\n* *Ensure that ServiceAccount has no Admin privileges* for Google Cloud\n* *Eliminate use of the \"root\" user for administrative and daily tasks* for AWS \n\n### Assign permissions at group level  \n\nAnother best practice we recommend to ensure IAM Cloud Security is managing specific permissions at group level and not at the user level. \n\nWhenever you're adding a new user or trying to manage multiple users, assign them to a group with very well-defined rules and privileges. \n\nHere are some controls from Cyscale that check if you're implementing this IAM security best practice: \n\n* *Ensure IAM Users receive permissions only through Groups* for AWS Cloud \n* *Ensure IAM Policies are attached only to groups or roles* for AWS Cloud \n\n### Implement logging and monitoring \n\nAWS, Google Cloud, and Azure recommend that you implement logging and monitoring for your cloud environment. All three vendors provide these features.  \n\nFor AWS IAM, you can use one of the following IAM services: \n\n* AWS CloudTrail \n* Amazon CloudFront \n* Amazon CloudWatch \n* AWS Config \n* Amazon S3 \n\nGoogle Cloud supplies Cloud Audit Logs, a service that audits your IAM policy, access to cloud service account keys, and other components of Google Cloud. \n\nFor Azure, you can use Azure AD activity logs which can be supplemented by Azure Monitor logs to alert you on significant events. \n\nExamples of controls across all three cloud providers can be seen below: \n\n* *Ensure CloudTrail trails are integrated with CloudWatch Logs* for AWS \n* *Ensure that Diagnostic Logs are enabled for all services which support it* for Microsoft Azure \n* *Ensure that Cloud Audit Logging is configured properly across all services and all users from a project* for Google Cloud\n\nIdentity and Access Management is a crucial component of the cloud and should be adequately secured to prevent data breaches and other cybersecurity incidents. Reduce the attack surface by eliminating any vulnerabilities in the authentication process and keeping hackers away.\n\nUse Cyscale to identify any [misconfigurations](https://cyscale.com/blog/common-cloud-misconfigurations-how-to-avoid-them/) or gaps in your cloud infrastructure and secure it with our over 400 controls. \n\nIn the following article, we will look at [IAM best practices](https://cyscale.com/blog/iam-best-practices-identity/) described by these vendors and how to check if your cloud infrastructure is implementing them correctly.\n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["IAM"],"title":"IAM Services in AWS, Azure, and Google Cloud - A Cloud Industry Overview","seoTitle":"IAM Services in AWS, Azure, and Google Cloud - a Cloud Industry Overview","description":"An industry overview of the IAM Services. We look at AWS, Azure and Google Cloud and understand what identity and management is. The components of IAM are described for all three vendors.","seoDescription":"An industry overview of the IAM Services. We look at AWS, Azure and Google Cloud and understand what identity and management is. The components of IAM are described for all three vendors. Authentication methods are described, such as Single Sign-On (SSO) and Multi-Factor Authentication (MFA).","date":"2022-05-06T05:44:34.049Z","featuredpost":true,"permalink":"iam-services-in-aws-azure-gcp","featuredimage":{"publicURL":"/static/efb95d84a5f1a4760ffb7bb47eeaadba/iam-services-in-aws-azure-and-gcp-a-cloud-industry-overview.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/efb95d84a5f1a4760ffb7bb47eeaadba/888e2/iam-services-in-aws-azure-and-gcp-a-cloud-industry-overview.webp","srcSet":"/static/efb95d84a5f1a4760ffb7bb47eeaadba/913d0/iam-services-in-aws-azure-and-gcp-a-cloud-industry-overview.webp 205w,\n/static/efb95d84a5f1a4760ffb7bb47eeaadba/91660/iam-services-in-aws-azure-and-gcp-a-cloud-industry-overview.webp 410w,\n/static/efb95d84a5f1a4760ffb7bb47eeaadba/888e2/iam-services-in-aws-azure-and-gcp-a-cloud-industry-overview.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->  \n\nIdentity and Access Management (IAM) refers to all the good practices and rules that must be followed when establishing authentication and authorization for a user to an organization’s systems and applications. \n\nIn the past, different measures were implemented to assure security in an organization by only allowing users to access company resources through company devices on premises. \n\nHowever, as companies adopt the remote working model, this is no longer an option. For the cloud, IAM is the solution to ensure security. \n\nUsers can nowadays [connect to the cloud from all around the world](https://cyscale.com/use-cases/remote-work-security/) with their personal devices. \n\nMoreover, access is not restricted to human users; applications and other types of identities also require access to different types of resources. \n\nTherefore, strong IAM policies need to be implemented. \n\nLet’s first clarify some important concepts. Then, we will look into IAM policies and what different cloud vendors offer for their IAM infrastructure.\n\n### Identity \n\nIdentity refers to who can authenticate (sign in) into a cloud account.  \n\nIn order to allow someone to access cloud resources, you need to ensure that the user trying to authenticate is who they claim to be. \n\nAuthentication should be implemented using technologies like Single Sign-On (SSO) and Multi-Factor Authentication (MFA) to increase security.  \n\nAfter a user authenticates, access management is needed.  \n\nJust because a user successfully authenticated doesn’t mean that they should have full access to all the available resources. \n\n### Access management \n\nTo regulate access inside the cloud environment, strong access control policies need to be implemented. \n\nHaving groups with well-defined rules and privileges at different granularity levels is an excellent solution to manage access to cloud resources. \n\nIn this way, you do not have to assign permissions to each new user but rather add them to the appropriate group that already has the correct permissions. \n\nAccess management also refers to keeping track of users’ actions. Therefore, logging and monitoring are essential parts of IAM and should be implemented. \n\nNow that we’ve understood the purpose of IAM, let’s look at three big vendors in the cloud industry and their approach to access management: AWS Cloud, Google Cloud Platform, and Microsoft Azure. \n\n### IAM implementations - An industry overview \n\n### Amazon Web Services (AWS) \n\nFor access management, the IAM service provided by AWS has three types of assets: user, role and policy.  \n\nAlong with the creation of an account, an AWS account root user is created. \n\nWhen looking at [AWS Cloud](https://cyscale.com/use-cases/aws-cloud-security/), we can identify 6 concepts in IAM: \n\n1. **Principal**, which represents the entity (user or application) that is trying to authenticate using an AWS account root user, an IAM user, or an IAM role. \n2. **Request**, which is made by a principal to AWS and holds information about the operation they want to perform. \n3. **Authentication**, which refers to the credentials you need, such as an access key or a username and password. \n4. **Authorization**, which refers to the permissions and policies that define what a principal can do in an account. \n5. **Actions and operations**, which must be included in policies in order to allow a principal to execute them. \n6. **Resources**, which define the objects that exist within a service and to which the principal requires access; they can be, for example, Amazon S3 buckets, IAM users, and Amazon EC2 instances. \n\n Policies define permissions and can be attached to: \n\n* users.\n* groups of users, \n* roles,\n* resources. \n\nThere are multiple types of policies that can be applied in AWS. A user can create their own custom policies or can use the ones offered by AWS.  \n\nYou can see below the different types of AWS policies, ordered from the most frequently used to the least: \n\n1. Identity-based (attached to IAM identities) \n2. Resource-based (attached to resources) \n3. Permissions boundaries (they define the highest level of permissions an identity-based policy can apply) \n4. Organization Service Control Policies (used to define the highest level of permissions an identity-based or resource-based policy can apply for account members of an organization) \n5. Access Control Lists or ACLs (are similar to resource-based policies and define which principals can access a resource) \n6. Session policies (they limit the permissions granted by identity-based policies in an AWS CLI or API session)\n\n### Google Cloud Platform\n\nIn Google Cloud, permissions to access resources are organized into roles. To understand how IAM works in Google, we must look at the 3 IAM asset types: \n\n* **Roles**, which represent a collection of permissions \n* **Principals**, who are assigned to roles and can be: \n\n  * a Google Account, \n  * a Service Account, \n  * a Google group, \n  * a Google Workspace account, \n  * a Cloud Identity domain, \n  * all authenticated users, \n  * all users.\n* **Policies**, which define associations of principals and roles  \n* **Resources**, which are physical assets, such as computers and hard disk drives, and virtual assets, for example virtual machines. \n\nIn Google Cloud, permissions cannot be applied to principals directly. Instead, principals must be assigned to roles and thus receive all the permissions allowed for that role. \n\nBelow, you can see a diagram of the IAM components found in Google Cloud. \n\n![Google Cloud IAM Components](/img/gcp-iam.webp#shadow \"Google Cloud IAM Components\")\n\nImage source – [Google Cloud Platform](https://cloud.google.com/iam/docs/overview) \n\n### Microsoft Azure \n\n[Azure Active Directory](https://cyscale.com/use-cases/azure-cloud-security/) (Azure AD) is an IAM service provided by Microsoft for the cloud. Azure AD is the identity system used to connect to Microsoft 365, the Azure portal, and other SaaS applications. \n\nLet’s look at components of Azure AD: \n\n**1. Identity** \n\nAn identity is an entity that can be authenticated.  \n\nIdentities can be of the following types: \n\n* Users,\n* Groups,  \n* Applications. \n\n**2. Role** \n\nA role is a collection of permissions. \n\nAccess to Azure resources is managed by **RBAC (Role-based Access Control)**. \n\nAzure RBAC provides high granularity with four built-in roles: \n\n1. Owner (can perform all actions on all resource types) \n2. Contributor (can perform any action an owner can except managing RBAC) \n3. Reader (can perform all read actions on all resource types) \n4. User Access Administrator (can manage user access to Azure resources) \n\nOther roles are also provided for granular management of access. Moreover, custom roles can be created to cater to every organization’s needs. \n\n**3. Scope** \n\nScopes are sets of resources that define what an identity can access.  \n\nThey are important because, when you assign a role, it is crucial to only grant a principal the access they need. \n\nScopes can be: \n\n* subscriptions, \n* resource groups, \n* resources. \n\n**4. Resource** \n\nResources are manageable items available through Azure, such as virtual machines, databases, web applications and others. \n\nAccess to resources is granted by assigning: \n\n* a user, \n* a group, or \n* a Service Principal (process or application) \n\nto a specific role and a specific scope. \n\nCyscale integrates with AWS, Azure, Google Cloud and other vendors to check for vulnerabilities and [improve its customers‘ cloud security posture](https://cyscale.com/blog/improve-cloud-security-posture/). \n\nIn the following article, we will look at [IAM best practices](https://cyscale.com/blog/iam-best-practices-identity/) described by these vendors and how to check if your cloud infrastructure is implementing them correctly. \n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Misconfigurations"],"title":"Common Cloud Misconfigurations and How to Avoid Them","seoTitle":"Common Cloud Misconfigurations and How to Avoid Them","description":"Cloud misconfigurations are the number one reason for security breaches. The first step towards securing your environment and improving your cloud security posture is acknowledging and knowing how to avoid mistakes.","seoDescription":"5 of the most common cloud misconfigurations are: poor storage access configuration, broken access control, unrestricted inbound and outbound traffic, missing encryption, disabled or unconfigured logging and monitoring. Learn how to avoid them and improve your cloud security posture with Cyscale.","date":"2022-04-20T07:01:46.443Z","featuredpost":true,"permalink":"common-cloud-misconfigurations-how-to-avoid-them","featuredimage":{"publicURL":"/static/9af1415197c714721ab329e1204d8353/common-cloud-misconfigurations.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/9af1415197c714721ab329e1204d8353/888e2/common-cloud-misconfigurations.webp","srcSet":"/static/9af1415197c714721ab329e1204d8353/913d0/common-cloud-misconfigurations.webp 205w,\n/static/9af1415197c714721ab329e1204d8353/91660/common-cloud-misconfigurations.webp 410w,\n/static/9af1415197c714721ab329e1204d8353/888e2/common-cloud-misconfigurations.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"Cloud misconfigurations are the number one reason for security breaches.  \n\nThe first step towards securing your environment and improving your cloud security posture is acknowledging and knowing how to avoid mistakes. \n\nAccording to [Gartner](https://www.gartner.com/smarterwithgartner/is-the-cloud-secure), 99% of cloud security failures will occur due to human error through 2025. \n\n5 of the most common [cloud misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/) are: \n\n1. Poor storage access configuration \n2. Broken access control \n3. Unrestricted inbound and outbound traffic \n4. Missing encryption \n5. Disabled or unconfigured logging and monitoring \n\nThis article will explain these misconfigurations and help you work them out.  \n\nWe will also give you some examples of the controls Cyscale implements to ensure foolproof configurations for your company’s cloud. \n\n<div id=\"storage-access\">\n\n## **1. Poor storage access configuration**\n\nStorage access misconfigurations usually make cloud assets open to the public view. \n\nWe can take as an example Amazon S3 buckets. A significant security vulnerability is making an S3 bucket that contains sensitive data public. This means that everyone on the internet can access your data. \n\nThere are two ways in which public access over a bucket can lead to cybersecurity incidents: \n\n* Public “READ” access \n* Public “WRITE” access \n\nPublic “READ” access over a company’s buckets creates the risk of a data breach.  \n\n“WRITE” access over a bucket is arguably worse – this means that entities from the internet can infiltrate malware such as \n\n* backdoors,\n* ransomware,\n\nor even crowd your bucket with their data in order to obtain free storage. \n\n### **Solution**\n\nBlock public access using access lists and policies.  \n\nAn access control list (ACL) is a set of rules that limit access to buckets through permissions. It defines the access level an account has over a bucket (for example, READ or WRITE). \n\nLet’s look at some examples of controls offered by Cyscale that check if you have storage access misconfigurations: \n\n* *Ensure that S3 Buckets are configured with 'Block public access (bucket settings)'* for AWS Cloud \n* *Ensure network access rule for storage bucket is not set to publicly accessible* for Alibaba Cloud\n\n</div>\n\n## **2. Broken access control**\n\nWhen talking about access control misconfigurations, we refer to overly permissive rights. \n\nThe Principle of Least Privilege states that a user should not be given more permissions than they need to perform their job. \n\nBadly implemented access control can lead to cybersecurity incidents because: \n\n* an employee may accidentally misconfigure other assets because they are given the right to, even though they shouldn’t have it, \n* an attacker that gets ahold of an employee’s account may leverage the broad range of permissions they have to further penetrate the infrastructure or gain access to secrets. \n\nAdministrator or root privileges should only be given to those users who absolutely require them. \n\n### **Solution**\n\nRestrict access to the lowest privilege every user needs and eliminate all administrator/root accounts that are not strictly necessary. \n\nTwo examples of the many controls Cyscale has that regulate this issue are: \n\n* *Ensure that ServiceAccount has no Admin privileges* for Google Cloud Platform \n* *Eliminate use of the \"root\" user for administrative and daily tasks* for AWS Cloud \n\nAnother best practice to mention is having groups with very well-defined rules and privileges. \n\nIn this way, you can assign a user to the correct group and minimize the risk of making a mistake when adding permissions for a new user or when trying to manage multiple users. \n\nThe implementation of this feature is checked by Cyscale using, for example, the following controls: \n\n* *Ensure IAM Users receive permissions only through Groups* for AWS Cloud \n* *Ensure RAM policies are attached only to groups or roles* for Alibaba Cloud \n\n## **3. Unrestricted inbound and outbound traffic**\n\nWhen we talk about cloud networking, we have two types of traffic: \n\n1. Inbound\n2. Outbound\n\nEach one involves a different type of risk. \n\nWith inbound traffic, unnecessarily open ports may be a door inside for an attacker. \n\nOn the other hand, outbound unrestricted traffic allows a perpetrator to: \n\n* exfiltrate data \n* pivot to other assets in your cloud environment (otherwise known as lateral movement) \n* scan your infrastructure and gather data about your company \n\n### **Solution**\n\nMake sure to close or restrict ports that are not necessary. Use access lists to restrict ranges of IPs and ports. \n\nLet’s look at two of the hundreds of controls implemented in Cyscale that restrict unnecessary traffic from your cloud.  \n\n* *Ensure firewall rule does not allow all traffic for MySQL (port 3306)* for Google Cloud Platform \n* *Ensure firewall rule does not allow all traffic on all ports* for Google Cloud Platform \n\n## **4. Missing encryption**\n\nWhen we’re considering encryption in the cloud, there are numerous cloud assets we need to have in mind. For example: \n\n* S3 buckets, \n* virtual machine disks, \n* databases and others. \n\nEncryption assures confidentiality. If your sensitive data is accidentally exposed or someone gains access to it, strong encryption can still protect it. \n\nTherefore, it is important to make sure your data is encrypted in the cloud. \n\n### **Solution**\n\nImplement strong encryption and use industry-recommended cryptographic algorithms with strong keys.  \n\nSome examples of controls implemented in Cyscale that check if encryption is correctly assured in your cloud environment are: \n\n* *Ensure all S3 buckets employ encryption-at-rest* for AWS Cloud \n* *Ensure that 'Data encryption' is set to 'On' on a SQL Database* for Microsoft Azure \n* *Ensure VM disks for critical VMs are encrypted with Customer-Supplied Encryption Keys (CSEK)* for Google Cloud Platform \n\n## **5. Disabled or unconfigured logging and monitoring**\n\nIt is extremely important to log actions taken in your cloud environment. This can help you: \n\n* identify mistakes and other misconfigurations \n* provide accountability for employees’ actions \n* notice suspicious behavior \n\nMoreover, a key feature would be having targeted alerts alongside logging. This can help you cut through the noise of logs. \n\nEffectiveness can be increased in this way because you do not have to skim through all of the generated logs, since targeted alerts point out specific problems.\n\n### **Solution**\n\nImplement logging and monitoring with automated, targeted alerts. \n\nSome of the many controls provided by Cyscale that help you configure logging correctly are: \n\n* *Ensure that activity log alert exists for the Delete Network Security Group Rule* for Microsoft Azure\n* *Ensure S3 bucket access logging is enabled on the CloudTrail S3 bucket* for AWS Cloud\n\n<br/>\n\nNow that we’ve looked at the most common cloud misconfigurations and showed you how to identify and fix them, make sure to check out [Cyscale](https://cyscale.com/) to solidify your cloud security posture.  \n\nYou will find: \n\n* controls that check for the misconfigurations presented in this article and more,\n* an explanation of what those misconfigurations are,\n* instructions on how to fix them.\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"5 Steps to Improve Your Company’s Cloud Security Posture","seoTitle":"5 Steps to Improve Your Company’s Cloud Security Posture","description":"Improve your company's cloud security posture by assuring discovery and visibility of cloud assets, detecting misconfigurations and applying remediation for them, ensuring logging and monitoring and assuring compliance with security standards. Cyscale is a CSPM that provides solutions to all of the problems raised. ","seoDescription":"Improve your company's cloud security posture by assuring discovery and visibility of cloud assets, detecting misconfigurations and applying remediation for them, ensuring logging and monitoring and assuring compliance with security standards. Cyscale is a CSPM that provides solutions to all of the problems raised. ","date":"2022-04-15T06:10:31.315Z","featuredpost":true,"permalink":"improve-cloud-security-posture","featuredimage":{"publicURL":"/static/b4be0a73a12406a9b06930df91b77167/featured_image.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/b4be0a73a12406a9b06930df91b77167/888e2/featured_image.webp","srcSet":"/static/b4be0a73a12406a9b06930df91b77167/913d0/featured_image.webp 205w,\n/static/b4be0a73a12406a9b06930df91b77167/91660/featured_image.webp 410w,\n/static/b4be0a73a12406a9b06930df91b77167/888e2/featured_image.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nSecuring your cloud environment can be a very difficult task.  \n\nWhen configuring and maintaining your cloud environment, mistakes and misconfigurations are bound to happen. And, because of that, \n\n* understanding how cloud assets are interconnected, \n* establishing correct policies, \n* regulating access control \n\nare all tasks that should be carefully approached when thinking about your company’s cloud. \n\nTherefore, it is necessary to take some steps to make sure your company’s cloud is secure. \n\nIn order to minimize risks and secure your cloud environment, you need to manage your cloud security posture.  \n\nIn this article, you will see how to improve it and provide a safe environment for your assets. \n\nHere are some key actions that you need to take to make sure that your cloud is secure. \n\n1. Assure discovery and visibility of cloud assets \n2. Detect misconfigurations  \n3. Implement remediation for findings \n4. Ensure logging and monitoring \n5. Assure compliance with security standards \n\nLet us talk more about these tasks and how to accomplish them. \n\n<br/>\n\n**1. Assure discovery and visibility of cloud assets** \n\nLooking at many configurations at once may become overwhelming very fast. \n\nIt is hard to notice flaws in your security design if discovery and visibility are not assured. \n\nDiscovery and visibility in cloud imply being able to visualize cloud assets in an organized and easily readable way, for example in a dashboard.  \n\nEven more useful is when visibility for each asset is enriched by additional context that may be provided in a graph view.\n\n![A graph from the Cyscale application.](/img/graph_image.webp#shadow \"The Cyscale Security Knowledge Graph™\")\n\nLooking at: \n\n* policies, \n* configurations, \n* connections between assets \n\nin a centralized fashion can help in pointing out: \n\n1. unnecessarily permissive rights \n2. vulnerabilities in your cloud configuration.  \n3. odd changes in your infrastructure. \n\nIt is critical to make sure that visibility is satisfied, in order to enable threat discovery. \n\nFor example, [a graph that maps networks of cloud assets. identities and workloads](https://cyscale.com/products/security-knowledge-graph/) can help you properly understand relationships, properties, and types of assets in your cloud environment. \n\nVisually examining the characteristics of your infrastructure may aid you in taking the right measures to improve security. \n\n<br/>\n\n**2. Detect misconfigurations** \n\nAccording to [Continuity Central](https://www.continuitycentral.com/index.php/news/technology/7117-misconfiguration-was-the-number-one-cause-of-cloud-security-incidents-in-2021), misconfigurations in the cloud environment were the main cause of cloud security breaches in 2021. It is easy to overlook: \n\n* a badly configured access list (ACL) \n* a bad policy for access control \n* an open port that should not be there, and others. \n\nHumans make mistakes. Even a minor misconfiguration that does not impact the activity in your cloud may lead to catastrophic events such as: \n\n* public access to your containers, \n* malware intrusion, \n* lateral movement.  \n\nDiscovering these mistakes before they are exploited is critical.  \n\nIdeally, you should have an automated way to check for common cloud misconfigurations. \n\nWe will provide you with a solution later in this article to easily keep misconfigurations under control and be notified when new ones appear. \n\n<br/>\n\n**3. Implement remediation for findings** \n\nIt is not enough to only discover threats in your design. \n\nYou need to also be able to remediate the flaws in your cloud infrastructure.  \n\nKnowing how to properly fix misconfigurations and vulnerabilities is a key factor in improving your cloud security. \n\nExamples of misconfigurations remediations are: \n\n* restricting overly permissive access to users, \n* closing unnecessarily open ports, \n* blocking inbound & outbound traffic. \n\n<br/>\n\n**4. Ensure logging and monitoring** \n\nIt is very important to catch threats before they become incidents.  \n\nA good measure to take is keeping logs and documenting every event that occurs. \n\nIn this case, **targeted alerts** can save your company from disaster by pinpointing: \n\n* misconfigurations \n* suspicious activity \n* attacks coming from outside.  \n\nSpotting threats immediately or within a short period of time may save your cloud environment from being breached. \n\n<br/>\n\n**5. Assure compliance with international standards** \n\nMaking sure that your company is compliant with international standards such as [ISO 27001](https://cyscale.com/blog/ISO-27001-certification-standard-policies-procedures/) not only consolidates your data protection services but also shows your clients that you acknowledge the importance of cybersecurity. \n\nFollowing [best practices](https://cyscale.com/blog/5-cspm-best-practices-and-strategies/) recommended by standards can greatly improve your cloud security posture. \n\nHowever, fulfilling all of the requirements consistently to become compliant with an international standard is a very tedious and time-consuming job. \n\nA solution to this would be automating controls and compliance checks that scan your platform for every requirement and show if you are fulfilling every request. \n\n<br/>\n\nWe have reached the end of the article and now you are probably wondering: \n\n**How do you implement all of the mentioned steps?** \n\nThe tasks described above can be implemented using a [CSPM product (Cloud Security Posture Management)](https://cyscale.com/products/cloud-security-posture-management/).  \n\nCSPM is a component of cloud security that analyzes your cloud environment and alerts you on what controls are failing in your infrastructure. \n\nYour cloud security posture would be improved significantly and promptly when using a CSPM.  \n\nCyscale is a CSPM that provides solutions to all of the problems raised in this article. \n\nWith Cyscale, you can: \n\n* get an overview of your assets and configurations, \n* easily manage misconfigurations, \n* receive targeted and precise alerts, \n* remediate accidents and flaws in your cloud environment faster, \n* become compliant with international standards. \n\nStart automating tasks, make these processes easier for you and generate reliable results, with [Cyscale](https://cyscale.com/). \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"SOC 2 vs ISO 27001: What every SaaS needs to know","seoTitle":"SOC 2 vs ISO 27001: What every SaaS needs to know","description":"When looking into consolidating your data protection services, you may decide to implement SOC 2 or ISO 27001. Acquiring one of these accreditations is a thorough process and choosing the right one for your company is the first step. In case you are a SaaS provider and are not certain which one to choose, this article maps out the key differences between them.\n","seoDescription":"A comparison between the standards SOC 2 and ISO 27001 and how to acquire them, including price, duration and others.","date":"2022-03-29T06:31:44.659Z","featuredpost":true,"permalink":"soc-2-vs-ISO-27001-SaaS","featuredimage":{"publicURL":"/static/48809b2bb298642ad9c8e20940f43f8f/microsoftteams-image.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/48809b2bb298642ad9c8e20940f43f8f/888e2/microsoftteams-image.webp","srcSet":"/static/48809b2bb298642ad9c8e20940f43f8f/913d0/microsoftteams-image.webp 205w,\n/static/48809b2bb298642ad9c8e20940f43f8f/91660/microsoftteams-image.webp 410w,\n/static/48809b2bb298642ad9c8e20940f43f8f/888e2/microsoftteams-image.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"When looking into consolidating your data protection services, you may decide to implement one of the following two standards:\n\n* SOC 2\n* ISO 27001\n\nAcquiring one of these accreditations is a thorough process and choosing the right one for your company is the first step.\n\n**In case you are a SaaS provider** and are not certain which one to choose, keep reading to understand the key differences between them.\n\n**What are these accreditations** and what is their scope?\n\nThe SOC 2 and [ISO 27001](https://cyscale.com/use-cases/iso-27001-compliance/) standards are normally acquired by B2B (Business-to-business) companies.\nThey:\n\n* represent international standards for Information Security Management Systems (ISMSs)\n* describe best practices for service providers who manage customer data\n\nAs a SaaS, in order to obtain one of the two accreditations, you must implement all the policies of that standard that apply to your organization.\n\n**What do these standards say about your company?**\n\nSOC 2 and ISO 27001 are very similar.\nAcquiring one of them promotes the following principles about your organization:\n\n* You recognize the importance of cybersecurity\n* Your company is making efforts to mitigate information security risks\n* You are properly managing information security\n\nGiven the statements above, you can safely assume that a customer will prefer an organization with one of the described accreditations in their possession, to the detriment of one without any.\n\n### A comparison\n\n#### Geographical recognition\n\n* SOC 2 is governed by The American Institute of Certified Public Accountants (AICPA)\n* ISO 27001 was developed by ANSI-ASQ National Accreditation Board (ANAB)\n\n#### Duration\n\n* SOC 2: an audit takes **between 3 to 12 months**, depending on the type of audit\n* ISO 27001: takes **between 12 to 18 months** to complete\n\n#### Validity duration\n\n* For SOC 2: one year\n* For ISO 27001: three years (with surveillance audits once every year)\n\n##### Requirements\n\n**For SOC 2**, you need to fulfill **64 criteria** integrated through five trust service criteria (TSC), as seen below (along with a few criteria examples):\n\n1. Security\n\n   * Contains Security Incidents\n   * Communicates Remediation Activities\n2. Availability\n\n   * Identify environmental threats\n   * Measure Current Usage\n3. Processing Integrity\n\n   * Create and maintain records of system inputs\n   * Defines processing activities\n4. Confidentiality\n\n   * Identify confidential information\n   * Destroy confidential information\n5. Privacy\n\n   * Use clear and conspicuous language\n   * Collect information from reliable sources\n\n**For ISO 27001**, you need to:\n\n1. Implement an ISMS (Information Security Management Systems)\n2. Fulfill **7 requirements with 114 suggested controls** divided into 14 sections.\n\nThe requirements are described in the following clauses:\n\n* Clause 4: Context of the organization\n* Clause 5: Leadership\n* Clause 6: Planning\n* Clause 7: Support\n* Clause 8: Operation\n* Clause 9: Performance evaluation\n* Clause 10: Improvement\n\nIn the Annex of ISO 27001, you can find a list of controls and objectives to help you meet the requirements.\n\nYou can find more information [here](https://cyscale.com/blog/ISO-27001-certification-standard-policies-procedures/).\n\n**Price (of audit)**\n\n* For SOC 2, the cost depends on the type of audit and can range **between $5,000 and $60,000** with an average of about $20,000.\n* For ISO 27001, the price of an audit depends on the number of employees in the organization. It can go **as low as $5,400 up to $27,000**.\n\nIt is important to note that the price of implementing the standards may significantly increase the total cost of obtaining the accreditation.\n\nOne thing to note is that, although SOC 2 and ISO 27001 seem very different, their specifications overlap.\n\nThe level of similarity between the requirements of the two depends on:\n\n* The type of business you run\n* The scope of the audit\n\nThe similarity can be between 53% and 90%, according to AICPA’s mapping to ISO 27001.\n\nTaking into account all of the differences and similarities of the SOC 2 accreditation and the ISO 27001 certification, you can now choose the best standard for your company.\n\nFinally, implementing all the policies required by the described standards can be a difficult and time-consuming task.\n\nYou can make this process easier for you.\n\nWith [Cyscale](https://cyscale.com/), you can ensure easy and continuous compliance for ISO 27001.\n\nCyscale helps you meet the much-needed requirements described by this standard.\n"}},{"node":{"frontmatter":{"authors":"Manuela Țicudean","categories":["Compliance"],"title":"PSD2 Requirements through the Technical Security Lens","seoTitle":null,"description":"A deeper look at the most important regulation for payment services in Europe (PSD2), surfacing security requirements for the technology at the core of these businesses, tech-governance included.","seoDescription":null,"date":"2022-03-04T13:12:59.854Z","featuredpost":true,"permalink":"PSD2-technical-requirements","featuredimage":{"publicURL":"/static/f7099646cc0f3e38c229f2faa1f6ee44/cyscale_psd2.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/f7099646cc0f3e38c229f2faa1f6ee44/888e2/cyscale_psd2.webp","srcSet":"/static/f7099646cc0f3e38c229f2faa1f6ee44/913d0/cyscale_psd2.webp 205w,\n/static/f7099646cc0f3e38c229f2faa1f6ee44/91660/cyscale_psd2.webp 410w,\n/static/f7099646cc0f3e38c229f2faa1f6ee44/888e2/cyscale_psd2.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"\nThe fintech sector has known an impressive growth in funding over the past year. A recent Insider Intelligence [report](https://www.emarketer.com/content/insider-intelligence-fintech-trends-watch-2022) shows that the global funding for fintech in the first three quarters of 2021 reached $94.7 billion, which is shy of the total for 2019 and 2020 combined. [In the UK](https://member.fintech.global/2021/12/15/uk-fintech-funding-nearly-doubled-in-the-first-three-quarters-of-2021-outpacing-global-average/) alone, fintech funding nearly doubled in the mentioned timeframe, as compared to the year before (2020).\n\nAround the fintech businesses, entire ecosystems have emerged. There are national as well as international level organizations that collaborate and launch initiatives to drive the competition as well as innovation in the sector. Regulatory bodies are part of the ecosystems as well, making sure that businesses are doing the best they can to protect fintech consumers.\n\nThe purpose of this article is to take a deeper look at the most important regulations for payment services (which is a large subset of fintech services) in Europe, trying to showcase the security requirements for the technology at the core of these businesses, its governance included.\n\nWe keep in mind that although the UK has left the European Union, they decided to adopt a great part of the regulation under their legislation as well.\n\n## The PSD2 Directive\n\nProbably the most important European regulation that impacts fintech is the PSD2 Directive. Developed by the European Parliament and the European Council, introduced in 2015, and enforced since 2018, it describes rules, rights and obligations of Payment Service Providers and the users of these services. In the next sections, we go through the structure of the document, emphasizing the articles that regulate the “tech” in “fintech”.\n\nIt starts with 113 points that set up the context for the regulation and then follows with 6 main sections (also called titles).\n\n### Scope\n\n**The first section** clarifies the subject matter (who is affected), and that is Payment Service Providers. As we’ll see below, this includes traditional financial services providers, for example banks, but also new providers, such as fintechs. There’s also an article regarding scope: it applies to payment services provided within the European Union.\n\nPayment Service Providers are grouped under 6 distinct categories, but most fintechs fall under **payment institutions** and **electronic money institutions**.\n\nAny institution that provides payment services (enumerated below) after being authorized to do so, becomes a **payment institution**.\n\nThe different types of **payment services**, as understood from Annex 1 of the Directive are:\n\n-   operating a payment account for a user\n-   placing or withdrawing cash from a payment account\n-   payment transactions (i.e. transfers of funds) within the same provider, or to an external provider\n-   issuing of payment cards\n-   issuing sets of rules agreed between the issuer and the user that are then used to initiate a payment\n-   accepting and processing payment transactions\n-   money remittance, which is transfer of money without any payment accounts being created or used (think Western Union)\n-   payment initiation — initiate payment orders on behalf of the user (with his previous consent), from a payment account that is held at a different provider. This is possible due to the open banking framework.\n-   account information — provides information on payment accounts held by the user at a different provider. Again, this service has been made possible through open banking.\n\nAn **electronic money institution** is a legal entity that is authorized to issue electronic money. An electronic money institution can at the same time be a payment institution. There is a specific authorization license for each of these types of providers.\n\n### Becoming a PSP\n\n**The second section**, or title, adds further provisions for Payment Service Providers, including the procedure to become licensed as one.\n\n_Article 5_, titled “Applications for authorization”, contains the list of artefacts to submit when applying to become a payment institution. Among these, the directive requires **a security policy document** that must contain \"a detailed risk assessment\", along with the \"security control and mitigation measures taken\" to protect users against identified risk. It also explicitly states that the policy must indicate how the institution ensures \"a high level of **technical security and data protection**, including of the software and IT systems used\", and even when these are entirely or partly outsourced.\n\nAs we can see, already during the application process, a fintech business must have technical security controls in-place, as well as ways to describe them.\n\n**The third section** (title) of the directive refers to the transparency of conditions, as well as information requirements for payment service providers, meaning data regarding the payments which must be communicated to the service user at specific points in time. It does not contain any requirements for tech.\n\n### Proper Security\n\n**The fourth section** (title) details the rights and obligations around the provision and use of payment services, of both the providers and the users. This section is again relevant for those in charge of technology inside fintech companies providing payment services.\n\n*Article 66* and *Article 67* describe the obligations of PISPs (Payment Initiation Service Providers) and AISPs (Account Information Service Providers), which are both types of payment service providers.\n\nAn example of a PISP would be an application that, based on previously given user consent, makes regular (i.e. monthly) payments from the user’s bank account, and invests those funds on behalf of the user. In other words, by providing payment initiation services, the app makes payment transactions without the user having to do anything.\n\nTo understand an AISP, think of an application that queries information about a user’s bank account and then analyzes that data in order to give the user insights about his financial behavior. Previously given user consent is, of course, mandatory.\n\nUnder PSD2, the PISP and the AISP must:\n\n-   Protect user's personalized security credentials (PSC), if used, by transmitting them safely, and making sure they are not shared with other parties.\n\n    **PSCs** are, for example, your internet banking password, the code you use to authenticate to your neobank's mobile app, or any other means of authenticating with a Payment Service Provider. These credentials should not be shared with a PISP, or, when they are, they must be handled securely.\n\n-   Ensure that any information received about the payment service user is only provided to the payee (with user consent)\n-   When communicating with the entity that provides the user's payment account (i.e the bank), use common and secure open standards of communication\n-   Not store sensitive payment data of the user\n-   Not request from the user data that is not needed, in order to provide the services\n-   Not use, access, or store any user data for purposes other than the provided service\n-   In case of payment transactions, not modify the transaction amount\n\n*Article 70* states the obligations of a Payment Service Provider in relation to payment instruments (remember, these may be payment cards, but also procedures agreed between the user and the service provider on how to initiate payment orders). Again, the protection of personalized security credentials is required, by making sure that they are not accessible to other parties.\n\n*Article 74* states that when a Payment Service Provider doesn’t enforce strong customer authentication (**SCA**; think MFA) to protect transactions, it is liable for any financial losses incurred by the payer because of that.\n\n*Article 89* details the liability of Payment Service Providers in case they fail to correctly and in-time execute payment transactions. This part stresses out the importance of a solid **business continuity policy** and plan.\n\n*Article 95* requires two things from the Payment Service Providers:\n\n-   mitigation measures and control mechanisms in place, to manage operational and security risks\n-   to regularly provide operational and security risk assessments to competent authorities, as well as evidence that mitigation measures are adequate\n\n_Article 97_ requires from the PSP the implementation of strong customer authentication, meaning multi-factor authentication, involving something the user knows, something the user possesses or something that the user is (knowledge, possession or inherence). It also requires that “payment service providers have in place adequate security measures to protect the confidentiality and integrity of payment service users’ personalized security credentials”.\n\n### Ending Notes\n\nFinally, *Article 98* requires that, by July 2017, the Euro Bank Association (which is another EU institution) will have drafted regulatory technical standards to address the security requirements from previous articles (strong customer authentication and protecting the users’ personalized security credentials).\n\nThe **last two sections** refer to procedures for the settlement of disputes, user information rights, and final provisions, respectively, but neither of them contains additional technical requirements.\n\nThe regulatory technical standards developed by the EBA will be the subject of the next article in the series, where we will take a deeper dive into what they mean for a fintech.\n"}},{"node":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["Product"],"title":"Integrating NATS Into the Cyscale Platform","seoTitle":"Integrating NATS Into the Cyscale Platform","description":"Some concepts and techniques we leveraged to switch to a cloud-native message broker.","seoDescription":"Discover how Cyscale has enhanced cloud security integration by utilizing NATS on Kubernetes for efficient, scalable message-based communication. Read about the journey, benefits, and technical implementation on our blog.","date":"2021-12-22T10:11:16.968Z","featuredpost":true,"permalink":"integrating-nats-into-the-cyscale-platform","featuredimage":{"publicURL":"/static/cb4216e63701672e106156941ccdecaf/nats-horizontal-color.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/cb4216e63701672e106156941ccdecaf/02dc4/nats-horizontal-color.webp","srcSet":"/static/cb4216e63701672e106156941ccdecaf/913d0/nats-horizontal-color.webp 205w,\n/static/cb4216e63701672e106156941ccdecaf/85995/nats-horizontal-color.webp 410w,\n/static/cb4216e63701672e106156941ccdecaf/02dc4/nats-horizontal-color.webp 820w,\n/static/cb4216e63701672e106156941ccdecaf/62a3a/nats-horizontal-color.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":461}}}},"rawMarkdownBody":"\n<!--StartFragment-->\n\n## Backstory\n\nCyscale helps you secure your cloud infrastructure. To achieve this, the platform must be able to read (sync) the cloud resources, perform assessments against a set of controls (security and architecture guidelines and best practices), send notifications, generate reports, perform scheduled tasks, and so on. Given the highly distributed and segregated nature of the platform, we chose a microservices architecture on top of Kubernetes. Also, by design, these processes are mostly asynchronous, happening in the background as a result of a certain event or trigger.\n\nBesides direct HTTP communication (REST mostly for the account/user management and GraphQL for everything cloud-related), we make heavy use of message-based communication.\n\nUp until recently, Redis served as our backbone for sending messages. We used Redis Lists to simulate queues (e.g., for sending emails) and Redis Pub/Sub for, well, implementing the publish-subscribe pattern (e.g., for triggering the synchronization of the cloud resources). We knew since the beginning that Redis will not serve as the messaging middleware forever, but we started with it since it was already there for caching and tasks (through [Go Celery](https://github.com/gocelery/gocelery)).\n\nDue to a mix of accumulated technical debt and a desire for simplicity, we decided to invest in integrating a purpose-built technology for handling messages. After a good amount of research covering topics such as operational simplicity, community, and documentation, we decided to go with [NATS](https://nats.io/). As a side note, we continue to love Redis and there are plenty of well-established companies using it as their messaging middleware with great success.\n\nThe rest of the article will cover the main steps we took to integrate NATS into our platform such as understanding the NATS ecosystem, deploying the relevant tools on our Kubernetes cluster using Helm - this will form the main part since this is where we faced the most challenges, and, of course, sending and consuming messages.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\n**The NATS Ecosystem**\n\n![The NATS ecosystem encompassing the core NATS server, JetStream, the NATS clients and CLI, and the NATS resources for Kubernetes](/img/cyscale-nats.webp 'The NATS ecosystem')\n\n### Core NATS\n\nAt its core, **the NATS server** is a **publish/subscribe** message broker. It offers **at most once delivery** and works based on **subjects**. These can have a hierarchical structure such as `sync.aws` and `sync.gcp`. Services concerned with messages related to syncing operations for AWS will only subscribe to `sync.aws` while other services might listen for all sync-related messages on `sync.*` (which covers both subjects) or even `sync.>` (which will also cover `sync.aws.ec2` - a separate subject).\n\nAnother feature that provides us with great value is called **queue groups**. This helps us horizontally scale our consumers while making sure that only one instance of a service receives a certain message. If you have experience with Kafka, it resembles consumer groups. What’s nice about queue groups is that they are automatically created when consumers subscribe to a subject and provide the queue group parameter (a simple string that, just like subjects, can have a hierarchical structure). For example, we use the name of the service (e.g. notifier) as the queue group.\n\nWhile the core functionality is great and simple, plain old pub/sub with at most once delivery will not cover all use cases. Subscribers might be under heavy load or even down, there might be a network partition or we might even want to keep messages and follow an approach based on event sourcing (you can find more examples in the [NATS docs](https://docs.nats.io/using-nats/developer/develop_jetstream)). In other words, as soon as we need **temporal decoupling** between publishers and subscribers, we need **persistence**, which for NATS is provided by JetStream.\n\n### JetStream\n\nJetStream adds the concept of **streams** on top of the core NATS subjects. Basically, if you want your messages to be persisted, you can enable JetStream on the NATS server and create a stream that will actually store the messages sent to a subject (or multiple subjects - this is mostly to optimize resource utilization; for example, we have one stream called sync that stores all messages sent to any sync subject - i.e. sync.>).\n\nIf your system takes full advantage of JetStream, at most once delivery transforms into **at least once** and even **exactly once** by leveraging [message deduplication](https://docs.nats.io/using-nats/developer/develop_jetstream/model_deep_dive#message-deduplication) (NATS will discard a message if another message with the same publisher-provided ID exists in the stream over a window of a certain time - 2 minutes by default).\n\nOne confusion we had at the beginning was whether we actually had to do anything to take advantage of JetStream besides enabling it. Again, bringing the simplicity up front, publishers will not require any modification unless you are looking for exactly-once delivery (you will have to add the message ID). They still send messages on a certain subject and, behind the scenes, JetStream will persist them in the configured stream.\n\nOn the other hand, **you do have to create the actual streams** (we will talk about this below) and **adjust the subscribers to use the JetStream API** (part of the client NATS library). Note that you can still use the core NATS API, but your subscribers will not receive messages sent before they started listening (even though they are stored in the stream). The reason behind this is that JetStream actually creates consumers that handle the delivery of messages for each subscriber. You will have to manually create the consumer when using the CLI, but the client libraries will handle this automatically when subscribing to a subject through the JetStream API.\n\nHaving the messages persisted also enables us to take different approaches based on what we want to achieve. We might still follow a pub/sub approach for certain subscribers (these are known as **push consumers**) (e.g. we use this approach for generating user-requested reports) or we might want to have more control over how messages are retrieved in which case we will use a **pull consumer**. This enables us to batch messages (e.g. we do this for sending notifications). Here is how we handle the messages in our notifier service:\n\n```typescript\nexport type MessageHandler = (data: NotificationDto[]) => Promise<void>;\n\nexport const handleNotificationMessages = async (handler: MessageHandler) => {\n    try {\n        const nc = await getNatsClient();\n\n        if (!process.env.NOTIFICATIONS_SUBJECT) {\n            throw Error('NOTIFICATIONS_SUBJECT not set');\n        }\n\n        const jc = JSONCodec<NotificationDto>();\n\n        const psub = await nc.jetstream().pullSubscribe(process.env.NOTIFICATIONS_SUBJECT, {\n            queue: 'notifier',\n            config: { durable_name: 'notifier' }\n        });\n\n        const done = (async () => {\n            let notifications: NotificationDto[] = [];\n            for await (const m of psub) {\n                try {\n                    notifications.push(jc.decode(m.data));\n                    m.ack(); // Wait to gather all messages from the current batch\n                    if (m.info.pending === 0) {\n                        await handler(notifications);\n                        logger.info(`Processing ${notifications.length} messages`);\n                        notifications = [];\n                    }\n                } catch (error) {\n                    logger.error(error);\n                }\n            }\n        })();\n\n        setInterval(() => {\n            psub.pull({ batch: 30, expires: 1000 });\n        }, 1000 * 30);\n\n        logger.info(`Listening for messages on ${process.env.NOTIFICATIONS_SUBJECT}`);\n\n        await done;\n        await psub.destroy();\n    } catch (e) {\n        logger.error(`Failed to initiate message listening ${e}`);\n    }\n};\n```\n\n(yes, most of our services are actually written in Go, hence the naming of some variables)\n\nAnother dilemma we faced was regarding **stream creation**. Who/what is responsible for creating the streams? One option is using the client libraries which expose a method to **idempotently** create streams. While this can work just fine, we didn’t want our services to bother with the technical details of NATS. Also, streams felt more like being part of the infrastructure than part of the actual services. So we continued our research and found [NACK](https://github.com/nats-io/nack) which we cover below.\n\nAs a side note regarding persistence/streaming with NATS, the precursor of JetStream is called STAN, which is now deprecated. We are mentioning this because there are still plenty of tutorials that focus on STAN, but JetStream is the way forward.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\n## NATS on Kubernetes with Helm\n\nBeing part of the CNCF, we can expect NATS to have first-class support for Kubernetes. And it does.\n\nSince the entire Cyscale platform is specified as a Helm chart we just needed to add the [NATS](https://github.com/nats-io/k8s/tree/main/helm/charts/nats) subchart as a dependency and configure the values. You can check the [values file](https://github.com/nats-io/k8s/blob/main/helm/charts/nats/values.yaml) from the chart repo for reference. One small detail that cost us a few hours was how we were specifying the values for NATS. If you look at [the documentation](https://docs.nats.io/running-a-nats-service/introduction/running/nats-kubernetes/helm-charts#jetstream), you will notice the `nats` object. However, since we are deploying NATS as a subchart, we will need an additional parent `nats` object to instruct Helm to pass the values down to the nats subchart. Here are our values for NATS on the dev cluster:\n\n```yaml\nnats:\n  nats:\n    image: nats:alpine\n    resources:\n      requests:\n        cpu: 100m\n        memory: 100Mi\n      limits:\n        cpu: 200m\n        memory: 200Mi\n    jetstream:\n      enabled: true\n      memStorage:\n        enabled: true\n        size: 80Mi\n      fileStorage:\n        enabled: true\n        size: 1Gi\n        storageDirectory: /data/\n        storageClassName: default\n```\n\n(notice the two `nats`)\n\nBesides the actual NATS server (which is a container running in the NATS pod along with the monitoring and config reloader containers), we also have a **NATS Box** pod (comes with the NATS Helm chart) that helps us with testing and administrative tasks - basically its a **preconfigured NATS CLI**. We access it using the command `kubectl exec -it <nats-box-container> -- /bin/sh -l`. The other alternative would have been to install the NATS CLI on our machines and port forward the NATS server from the cluster.\n\n### Creating the Streams with NACK\n\nBesides NATS, we also added the [NACK subchart](https://github.com/nats-io/k8s/tree/main/helm/charts/nack) which requires the NACK **CRDs** (install using `kubectl apply -f <https://raw.githubusercontent.com/nats-io/nack/v0.6.0/deploy/crds.yml>`). That’s because it enables us to treat JetStream streams as Kubernetes resources deployed as part of the rest of the platform.\n\nInstead of having our services handle the stream creation or manually creating them from the NATS box, we specify them declaratively as follows (`templates/nats-streams.yaml`):\n\n```yaml\n# See https://github.com/nats-io/nack/blob/main/deploy/crds.yml for more properties\n{{- range .Values.nack.streams }}\napiVersion: jetstream.nats.io/v1beta2\nkind: Stream\nmetadata:\n  name: {{ .name | quote }}\nspec:\n  name: {{ .name }}\n  subjects: {{ .subjects }}\n  storage: {{ .storage | quote | default \"file\" }}\n  retention: {{ .retention | quote | default \"limits\" }}\n---\n{{- end }}\n```\n\nWe also declare the streams as a list in the values file (notice the `range`).\n\nOnce these are deployed, you can inspect the streams just like any other k8s resource using `kubectl get streams`. One issue we faced was that the streams were not actually created in JetStream (`nats stream ls` from the nats box) even though the k8s resources existed. We simply manually deleted them from the cluster (`kubectl delete streams.jetstream.nats.io --all`) and re-deployed the helm chart.\n\nThere is another alternative we considered - the [jetstream Terraform provider](https://registry.terraform.io/providers/nats-io/jetstream/latest/docs). While we do use Terraform to declare our infrastructure on top of which the Kubernetes cluster is running, we chose NACK because it fit our abstraction layers best and because the terraform provider, running locally or in our pipelines, has to somehow reach the NATS server. In our case, the NATS server is not exposed outside of the cluster (again, port-forwarding is an option).\n\n### Ending Notes\n\nWhile there are more subjects to cover such as [authentication](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro) and [authorization](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/authorization), clustering (and [super-clusters](https://docs.nats.io/running-a-nats-service/configuration/gateways)), and multi-tenancy using [accounts](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/accounts), we hope this article helps you better understand how NATS works and how to deploy it. This is our way of giving back to a growing community and expressing our appreciation for getting to work with such great technologies.\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Virginia Mitea","categories":["CNAPP"],"title":"CNAPP: A mix of CSPM & CWPP","seoTitle":"CNAPP: A mix of CSPM & CWPP - Cyscale","description":"Gartner has defined a new category that is focused on securing cloud services and cloud-native applications, the so-called CNAPP- Cloud-Native Application Protection Platform.\n\nAccording to Gartner, “CNAPP is an integrated set of security and compliance capabilities designed to help secure and protect cloud-native applications across development and production.”\n\nThe legitimate question would be: Why do I need another security tool?","seoDescription":"Unveil CNAPP, a blend of CSPM & CWPP for advanced cloud security. Learn the benefits, compare it with separate tools, and understand its impact on the future of cybersecurity. A comprehensive guide by Cyscale on the latest trend in cloud protection.","date":"2021-11-24T15:35:49.333Z","featuredpost":true,"permalink":"cnapp-a-mix-of-cspm-cwpp","featuredimage":{"publicURL":"/static/e94d8cb96cb8569f098d571aba981b9e/cspm-cwpp.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/e94d8cb96cb8569f098d571aba981b9e/1946f/cspm-cwpp.webp","srcSet":"/static/e94d8cb96cb8569f098d571aba981b9e/19b88/cspm-cwpp.webp 205w,\n/static/e94d8cb96cb8569f098d571aba981b9e/f7577/cspm-cwpp.webp 410w,\n/static/e94d8cb96cb8569f098d571aba981b9e/1946f/cspm-cwpp.webp 820w,\n/static/e94d8cb96cb8569f098d571aba981b9e/d54ec/cspm-cwpp.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":547}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nEven before the Covid-19 pandemic, it was clear that more and more companies were adopting a cloud-first strategy.\n\nOver the last 2 years, the number of companies using the services of at least one public cloud provider continued to grow.\n\nAs a result, Gartner predicted that by the end of 2021 “public cloud deployments will outnumber private data center workloads”.\n\nOnce again, security specialists insist that cloud security is a complex subject that should be considered a high priority.\n\nThere already are a lot of tools to take into consideration when you're concerned with cloud security. Up until now, cloud professionals were talking about three main security solutions: [Cloud Security Posture Management (CSPM)](https://cyscale.com/blog/cloud-security-posture-management-cspm-guide/), Cloud Workload Protection Platform (CWPP), and Cloud Access Security Broker (CASB).\n\nBut recently, Gartner has defined a new category that is focused on securing cloud services and cloud-native applications, the so-called CNAPP- Cloud-Native Application Protection Platform. CNAPP combines the capabilities of Cloud Security Posture Management (CSPM) and Cloud Workload Protection Platform (CWPP) to provide comprehensive [cloud native application security](https://cyscale.com/blog/cnapp-secure-native-applications/) across development and production environments.\n\nThe legitimate question would be: ***Why do I need another security tool?***\n\nWell, the idea is to focus not only on your [cloud infrastructure's security](https://cyscale.com/blog/cloud-infrastructure-security/) configurations but also on your applications that run in the cloud.\n\nYou could argue that your CWPP or your CSPM is already doing something about this - and you would be right!\n\nIf you dig deeper, CNAPP is basically a mix of 2 separate solutions:  Cloud Security Posture Management (CSPM) & Cloud Workload Protection Platform (CWPP)\n\n### What is CSPM?\n\n[Cloud Security Posture Management solutions (CSPM)](https://cyscale.com/products/cloud-security-posture-management/) have as main purpose the [detection of misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/). They will continuously monitor the cloud environment in order to provide visibility across multi-cloud and alert the company about compliance drift or risky behavior. CSPMs focus on cloud infrastructure.\n\n### What is CWPP?\n\nCloud Workload Protection Platforms (CWPPs) are designed to protect the workloads deployed in the cloud. They will perform vulnerability assessments and handle the security of the applications. Based on assessment results, you can implement security controls or you can remediate the threats. CWPPs focus on the applications running in the cloud.\n\n## **Which is better? CNAPP vs CSPM+CWPP**\n\nThe increasing features overlap between these two solutions will make this \"merge\" inevitable.\n\n You can still use separate tools, or you can try a CNAPP, that's entirely up to you.\n\n#### ***Advantages of using CNAPP:***\n\n* better visibility and control of cloud-native application risk (when using separate tools, the identification and remediation actions can be fragmented, and not as efficient as having it all in one tool)\n* better collaboration for development and operations teams\n* simpler CI/CD pipelines (reduced complexity and cost since fewer tools are involved)\n* it scans all the source code, containers, VM images, IaC scripts, API\n\n#### ***Advantages of using separate tools:***\n\nThe most important one is the *maturity of the tools*.\n\nYou need to consider that Gartner expects this new category to have a high impact, but also predicts that it will take five to ten years before CNAPP is established in regular use.\n\nSince this is a new category of products, the market for CNAPP has just started to evolve and vendors need time to integrate all these capabilities.\n\nCWPP vendors have started to add new features capabilities, including IaC scanning.\n\nSome CSPMs have cutting edge-technology in place and can already give you some of the features promised a [CNAPP solution](https://cyscale.com/products/cnapp/).\n\nThis is the case of [Cyscale Cloud Security Platform](https://cyscale.com), the solution that offers advanced visibility, but more importantly, gives you context so you can better prioritize.\\\nThe [Security Knowledge Graph](https://cyscale.com/products/security-knowledge-graph/)™ built within the platform may reveal, for example, that one of the resources usually reported to have a high-security risk, is not as vulnerable as it seems. (Let's think about a VM that has unencrypted disks attached, but is not being used in a production environment, or is not externally accessible from the internet).\\\nThis type of approach can make you realize that you need a more advanced risk analysis and a look beyond the classic list of logs, where the vulnerable components are reported without taking into consideration the bigger picture.\n\nRegardless of your choice of tool, just remember to give security posture the importance it deserves.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\nPhoto by Markus Spiske\n\n<!--EndFragment-->"}}]}},"pageContext":{"limit":9,"skip":72,"numPages":10,"currentPage":9,"category":"All","seoTitle":"Blog Page 9 - Cyscale","seoDescription":"Cloud and Data Security Blog","categoriesList":["News","IAM","Cloud Security","Cloud Native Security","CNAPP","Compliance","Product","CSPM","Misconfigurations","Encryption"],"heading":"All you need to know about protecting SaaS apps and data in the cloud"}},"staticQueryHashes":["1117504136","2024892666","220583031","273821743","3722074465","4068795820","4109069157","81406208","981947644"],"slicesMap":{}}