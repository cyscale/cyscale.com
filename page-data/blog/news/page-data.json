{"componentChunkName":"component---src-template-blog-categories-template-js","path":"/blog/news/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News"],"title":"Inside the Mind of an Attacker: How Contextual Security Can Save Your Cloud","seoTitle":"Inside the Mind of an Attacker: How Contextual Security Can Save Your Cloud","description":"The future of cloud security is contextual security. To fully understand how secure an asset is, you need to understand what users have permissions to interact with it and what resources it communicates with. It might seem that a VM is completely secure because you put it behind a firewall, but if a compromised user can access it, it’s game over. \n\nThe perfect recipe for contextual security is a Cloud Security Knowledge Graph. Based on it, we can represent in a visual and interactive way how cloud resources interact, what kind of relations they have, what users have permissions to read/write on them, and so on.  \n\nTo illustrate my point, I will show you some scenarios where the difference between a secure cloud and a breach is made by fixing misconfigurations and limiting users' access. These measures are easier to identify using a graph, because it helps you understand the risks your environment is exposed to.  ","seoDescription":"The future of cloud security is contextual security. To fully understand how secure an asset is, you need to understand what users have permissions to interact with it and what resources it communicates with. It might seem that a VM is completely secure because you put it behind a firewall, but if a compromised user can access it, it’s game over.   The perfect recipe for contextual security is a Cloud Security Knowledge Graph. Based on it, we can represent in a visual and interactive way how cloud resources interact, what kind of relations they have, what users have permissions to read/write on them, and so on.    To illustrate my point, I will show you some scenarios where the difference between a secure cloud and a breach is made by fixing misconfigurations and limiting users' access. These measures are easier to identify using a graph, because it helps you understand the risks your environment is exposed to.  ","date":"2023-09-19T09:01:02.199Z","featuredpost":true,"permalink":"contextual-security-google-cloud","featuredimage":{"publicURL":"/static/7fbef8aa4e6e383ec434207181f0d892/blog_54-cover.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/7fbef8aa4e6e383ec434207181f0d892/2c0f5/blog_54-cover.jpg","srcSet":"/static/7fbef8aa4e6e383ec434207181f0d892/41be8/blog_54-cover.jpg 205w,\n/static/7fbef8aa4e6e383ec434207181f0d892/c78f7/blog_54-cover.jpg 410w,\n/static/7fbef8aa4e6e383ec434207181f0d892/2c0f5/blog_54-cover.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/7fbef8aa4e6e383ec434207181f0d892/913d0/blog_54-cover.webp 205w,\n/static/7fbef8aa4e6e383ec434207181f0d892/91660/blog_54-cover.webp 410w,\n/static/7fbef8aa4e6e383ec434207181f0d892/888e2/blog_54-cover.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"When public cloud providers such as Google Cloud and AWS first appeared, their benefits were hard to ignore. And although companies were reluctant to put their infrastructure and applications in the hands of a different company, cloud solutions have grown in popularity.  \n\nWith more and more complex setups, it is hard for an organization to understand and keep track of the implication of every resource they have in the cloud, the risk it poses to the entire infrastructure or how many other assets it impacts. \n\nI believe the future of cloud security is contextual security. To fully understand how secure an asset is, you need to understand what users have permissions to interact with it and what resources it communicates with. It might seem that a VM is completely secure because you put it behind a firewall, but if a compromised user can access it, it’s game over. \n\nThe perfect recipe for contextual security is a [Cloud Security Knowledge Graph](https://cyscale.com/blog/security-knowledge-graph-integrations/). Based on it, we can represent in a visual and interactive way how cloud resources interact, what kind of relations they have, what users have permissions to read/write on them, and so on.  \n\nTo illustrate my point, I will show you some scenarios where the difference between a secure cloud and a breach is made by fixing misconfigurations and limiting users' access. These measures are easier to identify using a graph, because it helps you understand the risks your environment is exposed to.  \n\n## Case Study \n\nLet’s assume we use BigQuery in Google Cloud for a health analytics application. We have a table that contains some datasets of patients from a hospital, including PII data. These datasets are very valuable and cannot fall in the hands of outsiders. \n\nNow, we want to make sure that the data is securely stored. We look at the BigQuery table’s graph to see if the table poses any risk and, low and behold, it does! \n\n<img src=\"/img/blog_54-graf-0.png\" alt=\"Contextual security through the graph\" title=\"Contextual security through the graph\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nWe can observe, in the image above, that no less than 7 Cloud Functions and 4 VMs can access it across 9 Service Accounts that have permissions on the BigQueryTable, as well as 7 IAM Users. Does this alarm you? It should. \n\nBut just because a VM, or a function, can have access to the table does not mean anything, right? Wrong! I’m going to show you exactly how bad things can get in this situation. I’m going to put my hacker shoes on and show you potential scenarios that might lead to data being stolen. \n\n### Scenario 1: compromised VM \n\nOut of the 4 VMs that we see in the image, one is an Internet-facing one. The compute instance “dev-1” hosts an application that has the Log4J vulnerability, a classic. A hacker leverages the vulnerability and gains access to the instance, being able to execute commands on it, and the disaster begins. **Because a Service Account is associated to the VM, the attacker has that account’s permissions.** In our scenario, the application running on the Instance needs to process data in the dataset, so the associated Service Account was given the roles/bigquery.dataEditor permission. \n\nMoreover, in a VM, credentials used to manually authenticate are stored on the Compute Instance after the first time a user authenticates as a Service Account, in */.config/gcloud/credentials.db*, as you can see in the image below. \n\n<img src=\"/img/blog_54-ss1.png\" alt=\"Credentials stored in Google Cloud VM\" title=\"Credentials stored in Google Cloud VM\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nThis is a standard location and it stores the last private key that was used to authenticate as a Service Account.  You can also find access tokens in the same folder, in *access_tokens.db*. Moreover, you can see any other private keys used previously (which may still be valid, if they were not deleted in the Google Cloud Console) in */.config/gcloud/legacy_credentials/<serviceAccountEmail>/adc.json*. \n\nLooking at the file credentials.db, we notice that the information is not stored in the standard format for a private key for a Service Account. With a few adjustments, we obtain a valid private key that we then use to authenticate. To authenticate as a Service Account with a private key, simply use the following command:  \n\n```\ngcloud auth activate-service-account <serviceAccountEmail> --key-file=<keyFile>\n```\n\n<img src=\"/img/blog_54-ss2.png\" alt=\"Authenticating using the secret key\" title=\"Authenticating using the secret key\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nHowever, what happens when no one has authenticated as a Service Account on the VM? There is no *credentials.db* file (actually, there is no *.config* folder).  \n\nDevelopers tend to find ways to do things faster, and they get comfortable. It is not uncommon to find secrets in environment variables or plain-text files. If a developer were to store a secret key file on the Compute Instance, we could abuse it. Simply log in using the private RSA key file: \n\n<img src=\"/img/blog_54-ss3.png\" alt=\"Private key on the VM\" title=\"Private key on the VM\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n<img src=\"/img/blog_54-ss4.png\" alt=\"Authenticating as Service Account\" title=\"Authenticating as Service Account\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nChecking the current permissions, and… bingo! roles/bigquery.dataEditor is one of the available roles. \n\n<img src=\"/img/blog_54-ss5.png\" alt=\"Service Account with roles/bigquery.dataEditor\" title=\"Service Account with roles/bigquery.dataEditor\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nIf we expand the graph’s nodes that we used in this chain of attacks, you can clearly see the attack path: \n\n<img src=\"/img/blog_54-primul-graf.png\" alt=\"Attack path through the VM\" title=\"Attack path through the VM\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nWith the bigquery.dataEditor role, the attacker can now: \n\n* view data and metadata, \n* modify data and metadata, \n* delete tables. \n\n This breach could be avoided by: \n\n* ensuring the VM does not have vulnerabilities, and patching the Log4J one, \n* isolating the Compute Instance from the Internet by closing the exposed port, if possible, \n* restricting the Service Account’s permissions as much as possible,\n* making sure secrets are cleared from the VM files.   \n\n<img src=\"/img/blog_54-ss6.png\" alt=\"Access to the BigQueryTable datasets\" title=\"Access to the BigQueryTable datasets\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n### Scenario 2: compromised user \n\nExpanding the Users node, we see that there are three users that have access to the BigQueryTable.  \n\n<img src=\"/img/blog_54-ultimul-graf.png\" alt=\"Attack path through user compromise\" title=\"Attack path through user compromise\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nIf a hacker were to take over any of those accounts, for example, by stealing credentials, our customer’s data would be at risk. If one of the three users that have access to the table does not have MFA enforced, then the attacker can compromise the account.  \n\nEnabling MFA would prevent this. \n\nBesides this, a common mistake is focusing on protecting your environment from the outside, and forgetting about your own users. If one of the employees in the organization has too many permissions, they may produce damage without intention. By exploring the account and looking at resources, a user can accidentally modify or delete an asset. \n\nThis is why the Least Privilege Principle is so important – always limit the users’ access as much as possible and only assign the necessary permissions. \n\nWe believe that context is the future of cloud security. We’ve seen how the most simple relations between assets can be leveraged by attackers to take over cloud assets; and if your customers’ data is stored in those assets, the greater the prize is for hackers – and they will do anything to get it."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News"],"title":"Cyber Safety Review Board Rings Alarm Bells for Shared Responsibility in the Cloud","seoTitle":"Cyber Safety Review Board Rings Alarm Bells for Shared Responsibility in the Cloud","description":"The Cyber Safety Review Board (CSRB) of the Department of Homeland Security is now embarking on its third cyber vulnerability review since the body was created in February 2022. During August, when lots of people were on summer vacation, a critical vulnerability in the authentication process for Azure Active Directory was exposed.\nAs with the two vulnerabilities the CSRB reviewed previously - Log4J in July of 2022 and Lapsus$ also in August of 2023 – the Azure Active Directory vulnerability highlights significant challenges in terms of remediation, due to the sprawling nature of cloud resources and their direct and indirect dependencies on assets that might, or might not, be affected.  ","seoDescription":"The Cyber Safety Review Board (CSRB) of the Department of Homeland Security is now embarking on its third cyber vulnerability review since the body was created in February 2022. During August, when lots of people were on summer vacation, a critical vulnerability in the authentication process for Azure Active Directory was exposed. As with the two vulnerabilities the CSRB reviewed previously - Log4J in July of 2022 and Lapsus$ also in August of 2023 – the Azure Active Directory vulnerability highlights significant challenges in terms of remediation, due to the sprawling nature of cloud resources and their direct and indirect dependencies on assets that might, or might not, be affected.","date":"2023-09-07T09:02:20.333Z","featuredpost":true,"permalink":"cyber-safety-review-board-on-cloud-security","featuredimage":{"publicURL":"/static/87ae3652b6af1c7dbe17d3182650a181/53_blog-csrb.jpeg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/87ae3652b6af1c7dbe17d3182650a181/2c0f5/53_blog-csrb.jpg","srcSet":"/static/87ae3652b6af1c7dbe17d3182650a181/41be8/53_blog-csrb.jpg 205w,\n/static/87ae3652b6af1c7dbe17d3182650a181/c78f7/53_blog-csrb.jpg 410w,\n/static/87ae3652b6af1c7dbe17d3182650a181/2c0f5/53_blog-csrb.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/87ae3652b6af1c7dbe17d3182650a181/913d0/53_blog-csrb.webp 205w,\n/static/87ae3652b6af1c7dbe17d3182650a181/91660/53_blog-csrb.webp 410w,\n/static/87ae3652b6af1c7dbe17d3182650a181/888e2/53_blog-csrb.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"The Cyber Safety Review Board (CSRB) of the Department of Homeland Security is now embarking on its third cyber vulnerability review since the body was created in February 2022. During August, when lots of people were on summer vacation, a critical vulnerability in the authentication process for Azure Active Directory was exposed.  \n\nAs with the two vulnerabilities the CSRB reviewed previously - Log4J in July of 2022 and Lapsus$ also in August of 2023 – the Azure Active Directory vulnerability highlights significant challenges in terms of remediation, due to the sprawling nature of cloud resources and their direct and indirect dependencies on assets that might, or might not, be affected.  \n\nEven for large organizations with sizeable security teams, navigating a complex dependency graph to understand which resources have dependencies on affected assets is a challenge. For SaaS startups with perhaps a handful of people building out their technology stack, such investigations are impossible.  \n\nAs a result, the findings of the CSRB’s reports and its recommendations for best practice build a strong case for contextually aware cloud security practices.  \n\n## How does this affect you (and everyone else)? \n\nIn its most recent announcement, the CSRB made it clear that identity access management (IAM) and authentication are in focus due to being one of the most vulnerable areas in a cloud environment. Identity management vulnerabilities are a key entry point for hackers, and SaaS companies and large enterprises are falling victim repeatedly. From IAM misconfigurations that CTOs and developers miss when setting up and managing their environment, to cloud service provider bugs, this area needs critical attention to ensure safe and secure cloud environments. \n\n## Did I just say cloud service provider bugs?  \n\nYes, I did. The incident in question that kicked off this latest review less than two months ago, was the discovery of a critical vulnerability in the authentication process for Azure Active Directory (soon to be renamed Microsoft Entra ID) that was allowing hackers to fabricate authentication tokens. Around 25 organizations including US government entities were impacted by this bug before it was discovered, with attackers stealing mailbox data and obtaining access to sensitive emails.  \n\nFor cloud native organizations building their entire business on public cloud platforms, this shared responsibility model is one of the most misunderstood (or ignored) aspects.  \n\nWhen the terms & conditions say that the cloud is a ‘shared responsibility’, it really is. It’s the cloud service provider’s job to secure the platform or infrastructure, and your job to secure the apps and data, and if one party fails (in this case, the cloud service provider – Microsoft Azure), your company, and potentially your customers and partners, are left exposed. \n\nThe CSRB’s previous two reports on [Log4j](https://www.cisa.gov/resources-tools/resources/csrb-log4j-key-findings-and-recommendations-summary) and [Lapsus$](https://www.cisa.gov/resources-tools/resources/review-attacks-associated-lapsus-and-related-threat-groups-executive-summary) have been very thorough and made some great recommendations that we hope will advance cybersecurity practices, which is why we’re eagerly waiting for CSRB’s report on cloud security. It not only promises a thorough set of recommendations for CISOs, CTOs, and developers, but it will also sound the alarm for cloud service providers.  \n\nAlthough the Cyber Safety Review Board has no regulatory power, its findings are transmitted to US President Biden and used to develop Executive Orders, so we can expect to see its influence in regulations such as [HIPAA](https://cyscale.com/blog/hipaa-compliance-in-cloud/), and perhaps best practices adopted into SOC 2, ISO 27001, and others. \n\n## The importance of contextual security \n\nWhat’s become evident is that simply informing businesses and cloud providers of the discovery of far-reaching misconfigurations and vulnerabilities is not enough. In fact, the potential workload created by responding to these challenges can be just as dangerous in that it can consume all an organization’s security resources.  \n\nContext is important and [contextual security](https://cyscale.com/blog/security-knowledge-graph-integrations/) is the most significant development in cloud infrastructure security in recent years. Identifying that a VM has the Log4J vulnerability is not the same as saying that an Internet-facing VM has the same vulnerability. Of course, they are both just as vulnerable, but if the first VM is running in a private network, the severity is not as high as for the one accessible from the Internet. The risk is not the same, but the alert will be, and we all know alert fatigue is a very real problem.  \n\nWrong prioritization, or no prioritization at all, can make all the difference between a secure cloud environment and a breach."}},{"node":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["News"],"title":"IPv4 Billing Changes in AWS: Impact on Cloud Costs & Security","seoTitle":"IPv4 Billing Changes in AWS: Impact on Cloud Costs & Security","description":"Explore how AWS's new IPv4 billing changes, effective from February 2024, will influence both your financial and security strategies. Understand the implications for small startups to large enterprises, from cost optimization to IPv6 transition, NAT64, and security enhancements.","seoDescription":"Explore how AWS's new IPv4 billing changes, effective from February 2024, will influence both your financial and security strategies. Understand the implications for small startups to large enterprises, from cost optimization to IPv6 transition, NAT64, and security enhancements.","date":"2023-08-31T09:03:04.258Z","featuredpost":true,"permalink":"aws-ipv4-impact-on-cloud-costs-and-security","featuredimage":{"publicURL":"/static/e4eb30151713435e89ec3c37c4832ca7/aws-ipv4-article.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/e4eb30151713435e89ec3c37c4832ca7/2c0f5/aws-ipv4-article.jpg","srcSet":"/static/e4eb30151713435e89ec3c37c4832ca7/41be8/aws-ipv4-article.jpg 205w,\n/static/e4eb30151713435e89ec3c37c4832ca7/c78f7/aws-ipv4-article.jpg 410w,\n/static/e4eb30151713435e89ec3c37c4832ca7/2c0f5/aws-ipv4-article.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/e4eb30151713435e89ec3c37c4832ca7/913d0/aws-ipv4-article.webp 205w,\n/static/e4eb30151713435e89ec3c37c4832ca7/91660/aws-ipv4-article.webp 410w,\n/static/e4eb30151713435e89ec3c37c4832ca7/888e2/aws-ipv4-article.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"Beginning February 1, 2024, Amazon Web Services (AWS) will usher in a significant change by charging for public IPv4 addresses. Whether you are a seasoned cloud engineer or a business decision-maker this shift by one of the world's leading cloud providers will likely have broad implications.\n\nAWS's decision aligns with other major cloud providers that have adopted similar practices, reflecting an industry-wide trend. AWS's involvement is particularly significant given its substantial market presence, and it will likely influence various organizations across different scales and industries.\n\nIn terms of your business and the tech landscape, this change goes beyond additional costs, with the new model affecting network planning, igniting considerations about transitioning to IPv6, and opening opportunities to reassess cloud security strategies.\n\n## The Financial Implications of AWS's New Charging Model for IPv4 Addresses\n\n### Detailed Explanation of Pricing\n\nStarting February 1, 2024, AWS will charge for all public IPv4 addresses at a rate of 0.5 cents per hour. While this figure may initially seem inconsequential, it is vital to understand how swiftly it can accumulate. \n\nFor small businesses or individual projects, the impact might be marginal. Our example considers a small organization with 10 public IP addresses:\n\n*10 IPs x 0.5 cents per hour x 730 hours in a month = $36.5 per month, or $438 per year.*\n\nContrast this with an enterprise operating with 11,000 public IPs: \n\n*11,000 IPs x 0.5 cents per hour x 730 hours in a month = $40,150 per month, or nearly **$500,000 per year**.*\n\n1﻿1,000 IP addresses might sound like an overestimation, but we are seeing organizations with tens of thousands of EC2 instances. Assuming 20-30% of these need public IPs is not out of reach.\n\nThis striking difference highlights the importance of understanding and planning for the financial consequences, particularly for organizations heavily reliant on public IPv4 addresses.\n\n### Budget Considerations for Organizations\n\nAWS's decision to charge for public IPv4 addresses extends beyond a simple financial concern; it prompts businesses to reevaluate their entire approach to IP address utilization. Key considerations include:\n\n* **Reviewing existing usage:** Analyzing current usage patterns is essential for predicting additional costs and identifying opportunities for optimization.\n* **Considering IPv6 migration:** Some may find transitioning to IPv6 a cost-effective alternative, though it must be balanced against compatibility and technical constraints.\n* **Utilizing tools and insights:** Automated security platforms like Cyscale can offer comprehensive insights into your inventory of public IP addresses, helping you understand the big picture and delivering insight that can aid in cost control.\n\nThis policy change serves as a catalyst for reimagining how organizations approach cloud infrastructure financially. The ripple effects will be felt differently across the spectrum, but the core message is clear: understanding, planning, and adapting will be pivotal in navigating this change without unforeseen financial setbacks.\n\nWhether you are a decision-maker concerned about the bottom line or a cloud professional tasked with optimization, these changes necessitate close scrutiny and proactive planning.\n\n## Technical Aspects and Considerations\n\n### Impact on EC2 Instances, RDS, EKS, etc.\n\nThe new charging model impacts a broad array of resources, including EC2 instances, RDS, EKS, load balancers, and more. Managing complex architectures now entails a new layer of complexity, possibly requiring a reassessment of networking strategies and configurations.\n\n### The Complexity of Managing Multiple IP Addresses per Resource\n\nSome resources may have more than one public IPv4 address. Managing these involves not just technical configuration but also financial planning. Understanding how these multiple IPs interact within your infrastructure and contribute to overall costs is essential. \n\n### Discussion on the Feasibility and Challenges of Switching to IPv6\n\nThe move to IPv6 seems logical, but it's not devoid of challenges. Compatibility with services and APIs managed by others might become a hurdle. AWS has made progress, such as enabling communication from EC2 to Lambda functions over IPv6 (note that you cannot reach an EC2 instance from Lambda over IPv6), yet some cases may still hinder a complete switch.\n\n### IPv4 to IPv6 Transition Mechanisms\n\nDuring the transition, Network Address Translation (NAT), specifically NAT64, becomes vital. This mechanism translates IPv6 to IPv4 addresses, bridging communication between newer IPv6 systems and legacy IPv4 systems. Understanding and utilizing NAT64 is crucial for modernizing without losing functionality. Equally important is DNS64 which performs the translation at the DNS level. More specifically, in the case a domain is mapped only to an IPv4 address (i.e., it only has A records), DNS64 translates an A record (specific to IPv4) to an AAAA record (specific to IPv6), thus allowing an IPv6 client to reach an IPv4 server.\n\n### Proficiency with Security Groups and Other Network Considerations\n\nWith all IPv6 addresses being public, mastering security groups and leveraging egress-only internet gateways become even more critical. Properly configuring security rules and comprehending their interaction with different IP versions plays a significant role in upholding security and functionality within your network.\n\nThe new AWS charging model for public IPv4 addresses is more than a financial consideration. It intertwines with a multifaceted web of technical aspects that must be thoughtfully navigated. Embracing the right strategies and tools can pave the way for a seamless transition, preserving both efficiency and budget.\n\n## Security Implications\n\n### Reevaluation of Network Exposure\n\nThe new charges for public IPv4 addresses might encourage organizations to scrutinize network exposure more closely. Reducing the number of public IPs could be both a cost-saving measure and a strategy to enhance security by limiting the **attack surface.**\n\n### Importance of Secure Configuration in IPv6 Transition\n\nTransitioning to IPv6, while potentially cost-effective, demands careful consideration of security configurations. Understanding IPv6 security nuances is vital in safeguarding systems during and after the shift. While NAT64 facilitates communication between IPv6 and IPv4 systems, it also introduces unique security considerations. Proper implementation and continuous vigilance are required to ward off vulnerabilities that might arise during the translation process. In practice, most organizations will leverage the AWS NAT Gateway which already supports NAT64 and DNS64 (through Route 53) so our responsibility includes proper route configuration and keeping DNS resolvers up to date. However, other organizations might choose to deploy their own NAT instance to optimize cost.\n\n### Tools and Platforms for Security Management\n\nAutomated cloud security platforms like Cyscale can play a pivotal role in this secure transition. By providing insights into all public IP addresses, their attachments, and alternative communication paths, they can facilitate a more secure and cost-effective migration. Utilizing specialized security platforms and tools is fundamental to maintaining control over complex cloud environments.\n\nThis new AWS charging model for public IPv4 addresses is more than a technical and financial hurdle; it's an opportunity to rethink and potentially enhance security strategies. By understanding the interplay between IPv4 and IPv6, the role of the transition mechanisms, and the necessity of proper security configurations, organizations can navigate this transition without compromising security.\n\n## The Role of Cloud Security Platforms\n\nAutomated cloud security platforms like Cyscale are more than just a reactive measure to changes like AWS's new charging model for public IPv4 addresses; they represent a proactive approach to modern cloud infrastructure management. By providing tools that cut across cost optimization, security enhancement, migration planning, and collaboration, these holistic solutions enable organizations to thrive in an evolving cloud landscape."}},{"node":{"frontmatter":{"authors":"Manuela Țicudean","categories":["News","Product"],"title":"What’s new: Major updates for Cyscale Automated Cloud Security Platform","seoTitle":"What’s new: Major updates for Cyscale Automated Cloud Security Platform","description":"In the newest major update, Cyscale has added to the Cloud Security Platform scopes, asset security score, enhanced graphs, improved alerts, integration with AWS inspector, more controls, improved compliance reports, and many others. Cyscale is building the most user-friendly agentless cloud-native security platform, that automates the assessment and gives you contextual analysis of cloud misconfigurations, vulnerabilities, access, and data, to provide an accurate and actionable assessment of risk.","seoDescription":"In the newest major update, Cyscale has added to the Cloud Security Platform scopes, asset security score, enhanced graphs, improved alerts, integration with AWS inspector, more controls, improved compliance reports, and many others. Cyscale is building the most user-friendly agentless cloud-native security platform, that automates the assessment and gives you contextual analysis of cloud misconfigurations, vulnerabilities, access, and data, to provide an accurate and actionable assessment of risk.","date":"2023-08-10T14:17:48.511Z","featuredpost":true,"permalink":"major-update-cyscale","featuredimage":{"publicURL":"/static/b6639e68bb5a4e241f66f5dbabab63a6/cyscale_major-release-photo.jpg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/b6639e68bb5a4e241f66f5dbabab63a6/2c0f5/cyscale_major-release-photo.jpg","srcSet":"/static/b6639e68bb5a4e241f66f5dbabab63a6/41be8/cyscale_major-release-photo.jpg 205w,\n/static/b6639e68bb5a4e241f66f5dbabab63a6/c78f7/cyscale_major-release-photo.jpg 410w,\n/static/b6639e68bb5a4e241f66f5dbabab63a6/2c0f5/cyscale_major-release-photo.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/b6639e68bb5a4e241f66f5dbabab63a6/913d0/cyscale_major-release-photo.webp 205w,\n/static/b6639e68bb5a4e241f66f5dbabab63a6/91660/cyscale_major-release-photo.webp 410w,\n/static/b6639e68bb5a4e241f66f5dbabab63a6/888e2/cyscale_major-release-photo.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"*More context, better visibility, asset-based risk scoring*\n\nThe world of cloud security moves fast and the Cyscale team has been sprinting to build the most requested features our customers need to keep their applications and data secure in the cloud.\n\nIn our latest major update, we’ve added:\n\n* **Scopes** – Customizable logical groupings that let you organize your cloud assets however you like – by applications, environments, customer accounts, audit scopes, or anything that makes sense in terms of your business context to better align cloud security with your business process. Filter all dashboards and the entire platform based on Scopes that you define.\n* **Support for containers** - Easily track where container images are running in your infrastructure.\n* **Enhanced graphs** - All the info you need in one place, no matter how many clouds. Now with increased support for misconfigurations and vulnerabilities for greater context, as well as revealing the relationships between cloud assets, data and permissions, resulting in accurate security scores that help identify and prioritize critical findings. \n* **Attack paths** - Eliminate security blind spots in the case of asset misconfigurations that propagate risk to other cloud assets with easy-to-understand highlights.\n* **Asset security score** - Prioritize remediation based on a percentage score for each individual asset, computed from criteria including: the number and severity of asset misconfigurations, and the number and severity of vulnerabilities where applicable.\n\n\n* **More controls** – Support for AWS EC2 Launch Templates, EC2, SageMaker Notebooks, ECS, Azure MFA, and more. Enhanced filtering of the library of controls and now eliminate false positives with exemptions.\n* **Improved inventory interrogation** - Chain multiple filters together to refine the search and gain even more contextual and valuable information on your security posture.\n* **Integration with AWS Inspector** – Correlate findings from native cloud security tools into one dashboard to reduce click fatigue and the need to jump between tools.\n* **Improved alerts** - Customizable alerts mean you can prioritize what's important to you and understand your current security posture immediately.\n* **Check and alert on missing MFA** - Identity dashboard updates including support for Azure MFA controls.\n* **Compliance improvements** - Instantly see your level of compliance for a standard or policy, now with a historical log of performance. Set your own risk threshold with real-time monitoring of customizable compliance scores and alerts. Out-of-the-box policies and standards are now fully customizable.\n* **Improved reports** – Build better bridges between development and CISO with easy-to-understand reports that can be exported as a PDF and shared with other stakeholders.\n* **Support for new standards** – Our continually expanding library of supported standards now includes ISO 27001:2022, PCI-DSS v4, MAS TRM, and the new CIS Benchmarks among others.\n\nCyscale is building the most user-friendly agentless cloud-native security platform, that automates the assessment and gives you contextual analysis of cloud misconfigurations, vulnerabilities, access, and data, to provide an accurate and actionable assessment of risk.\n\nOur solution takes away the requirement for specialist security skills in-house and identifies the 20% of fixes that will solve 80% of your cloud security challenges in just a few minutes. If you want to see Cyscale in action, [book a demo](https://cyscale.com/request-demo/).\n\nOur updated product data sheet, which puts all the above updates into context, is also available [here](https://cyscale.com/resources/cyscale-cloud-data-security-datasheet.pdf).\n"}},{"node":{"frontmatter":{"authors":"Ovidiu Cical","categories":["News"],"title":"Cyscale Makes Sifted’s Ones to Watch List in RegTech and DeepTech","seoTitle":"Cyscale Makes Sifted’s Ones to Watch List in RegTech and DeepTech","description":"Cyscale – the cloud security platform – has been listed in Sifted’s 100 Companies to Watch in both RegTech and DeepTech, as demands for compliance and regulation technology accelerate in line with interest in risk management and AI.  Cyscale can be found in Sifted’s RegTech briefing in the Compliance Management Solutions part of the map, and in the DeepTech briefing as an early-stage startup to watch. When it comes to both cloud security and compliance, identifying failure is only part of the process - you also need context to understand how to fix the problem. This context is provided by the Cyscale Security Knowledge Graph.  ","seoDescription":"Cyscale – the cloud security platform – has been listed in Sifted’s 100 Companies to Watch in both RegTech and DeepTech, as demands for compliance and regulation technology accelerate in line with interest in risk management and AI.  Cyscale can be found in Sifted’s RegTech briefing in the Compliance Management Solutions part of the map, and in the DeepTech briefing as an early-stage startup to watch. When it comes to both cloud security and compliance, identifying failure is only part of the process - you also need context to understand how to fix the problem. This context is provided by the Cyscale Security Knowledge Graph.  ","date":"2023-08-01T13:09:00.109Z","featuredpost":true,"permalink":"cyscale-top-100-sifted-regtech-deeptech","featuredimage":{"publicURL":"/static/61d7c1f4b0ac6df7bacf548ca7d65537/news_blog-cover.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/61d7c1f4b0ac6df7bacf548ca7d65537/2c0f5/news_blog-cover.jpg","srcSet":"/static/61d7c1f4b0ac6df7bacf548ca7d65537/41be8/news_blog-cover.jpg 205w,\n/static/61d7c1f4b0ac6df7bacf548ca7d65537/c78f7/news_blog-cover.jpg 410w,\n/static/61d7c1f4b0ac6df7bacf548ca7d65537/2c0f5/news_blog-cover.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/61d7c1f4b0ac6df7bacf548ca7d65537/913d0/news_blog-cover.webp 205w,\n/static/61d7c1f4b0ac6df7bacf548ca7d65537/91660/news_blog-cover.webp 410w,\n/static/61d7c1f4b0ac6df7bacf548ca7d65537/888e2/news_blog-cover.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"We are excited to reveal that Cyscale – the [cloud security platform](https://cyscale.com) – has been listed in Sifted’s 100 Companies to Watch in both RegTech and DeepTech, as demands for compliance and regulation technology accelerate in line with interest in risk management and AI.  \n\nRegTech funding this year has nearly caught 2022’s total already, and over 1,000 legal acts have been [adopted by the EU](https://eur-lex.europa.eu/statistics/legislative-acts-statistics.html) so far in 2023, driving demand for solutions to help companies navigate more, and more complex, red tape.  \n\nMeanwhile, DeepTech has moved on from stumbling blockchain and last-mile delivery innovations to resurface in several facets of AI, with automation helping companies do more with fewer resources - especially in the field of regulatory compliance and security.   \n\nWhen it comes to both [cloud security and compliance](<cloud security and compliance>), identifying failure is only part of the process - you also need context to understand how to fix the problem. This context is provided by the Cyscale [Security Knowledge Graph](https://cyscale.com/products/security-knowledge-graph/).  \n\nCyscale can be found in Sifted’s [RegTech briefing](https://sifted.eu/pro/briefings/regtech/) in the Compliance Management Solutions part of the map, and in the [DeepTech briefing](https://sifted.eu/pro/briefings/deeptech/) as an early-stage startup to watch.   \n\nWith so many companies in heavily regulated sectors needing to be seen as trustworthy, there is an exploding demand for solutions to help under-resourced teams secure their public cloud infrastructure and ensure they are operating in compliance with tough, fast-changing rules. \n\nWe are already helping companies secure and monitor their multi-cloud assets and data with our Security Knowledge Graph, and we are now looking to harness the power of AI to replace existing security tools with prompts and make an automated and scalable security team available to every cloud-centric company. This recognition by Sifted validates our approach."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News","Compliance"],"title":"Compliance Countdown: Navigating the Transition to PCI DSS Version 4","seoTitle":"Compliance Countdown: Navigating the Transition to PCI DSS Version 4","description":"The new PCI DSS version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.\n","seoDescription":"The new PCI DSS version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.","date":"2023-07-20T09:21:54.388Z","featuredpost":true,"permalink":"pci-dss-version-4","featuredimage":{"publicURL":"/static/176523e56bb9c620ee9eca495d6e187c/45_blog-pci-v4.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/176523e56bb9c620ee9eca495d6e187c/888e2/45_blog-pci-v4.webp","srcSet":"/static/176523e56bb9c620ee9eca495d6e187c/913d0/45_blog-pci-v4.webp 205w,\n/static/176523e56bb9c620ee9eca495d6e187c/91660/45_blog-pci-v4.webp 410w,\n/static/176523e56bb9c620ee9eca495d6e187c/888e2/45_blog-pci-v4.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"The new [PCI DSS](https://cyscale.com/blog/pci-dss-compliance-in-cloud/) version has been released, and the old PCI DSS standard will be deprecated as of the 31st of March, 2024. In this article, we will discuss all the deadlines by which you have to become compliant, details about the new requirements, and everything else you need to know about PCI DSS version 4.\n\n## Timeline and deadlines\n\nPCI DSS version 4 appeared at the end of March 2022 and its requirements will become mandatory in two phases: the first one is March of 2024, and the final one is March of 2025.\n\nThe new version brings considerable changes, but most of the new requirements will not be mandatory until 2025. However, companies that manage to fulfill them before 2025 can audit them.\n\nThe old version, PCI DSS 3.2.0., will remain active until the 31st of March, 2024, to allow companies enough time to recertify with the new version.\n\n## Changes in PCI DSS version 4, explained\n\nNew requirements have been added to all of the categories to better reflect the current cybersecurity landscape. Some examples of areas covered by the new requirements include the authentication process, logging and monitoring, vulnerability scanning, and others.\n\nMost of the sections have been revised or contain new requirements.\n\nPCI DSS is structured into twelve requirements, and each contains its own sections. The requirements are:\n\n### 1. Install and maintain network security controls\n\nThis requirement now specifies “network security controls” instead of “firewalls”, to cover more network security technologies. All of the sections in this category have been changed to the following:\n\n* 1.1 Processes and mechanisms for installing and maintaining network security controls are defined and understood.\n* 1.2 Network security controls (NSCs) are configured and maintained.\n* 1.3 Network access to and from the cardholder data environment is restricted.\n* 1.4 Network connections between trusted and untrusted networks are controlled.\n* 1.5 Risks to the CDE from computing devices that are able to connect to both untrusted networks and the CDE are mitigated.\n\n### 2. Apply Secure Configurations to All System Components\n\nThis requirement was initially named “Do not use vendor-supplied defaults for system passwords and other security parameters.”. Now, it refers to all of the company’s configurations, and not only to using vendor-supplied defaults. The sections in this category are the following:\n\n* 2.1 Processes and mechanisms for applying secure configurations to all system components are defined and understood.\n* 2.2 System components are configured and managed securely.\n* 2.3 Wireless environments are configured and managed securely.\n\n### 3. Protect Stored Account Data\n\nWith the third requirement, the focus is switched to account data, compared to the old version, where “cardholder data\" was mentioned instead. New sections are added in relation to PAN (Primary Account Number) and SAD (Sensitive Authentication Data) which cover the storage, encryption and hashing of this data.\n\n* 3.1 Processes and mechanisms for protecting stored account data are defined and understood.\n* 3.2 Storage of account data is kept to a minimum.\n* 3.3 Sensitive authentication data (SAD) is not stored after authorization.\n* 3.4 Access to displays of full PAN and ability to copy cardholder data are restricted.\n* 3.5 Primary account number (PAN) is secured wherever it is stored.\n* 3.6 Cryptographic keys used to protect stored account data are secured.\n* 3.7 Where cryptography is used to protect stored account data, key management processes and procedures covering all aspects of the key lifecycle are defined and implemented.\n\n### 4. Protect Cardholder Data with Strong Cryptography During Transmission Over Open, Public Networks\n\n“Strong cryptography” is now part of the 4th requirement name, to highlight the importance of using appropriate algorithms. The new sections introduce rules regarding the storage and usage of keys and certificates. \n\n* 4.1 Processes and mechanisms for protecting cardholder data with strong cryptography during transmission over open, public networks are defined and documented.  \n* 4.2 PAN is protected with strong cryptography during transmission. \n\n### 5. Protect All Systems and Networks from Malicious Software \n\nThis requirement has been renamed, replacing “anti-virus” with “malicious” software to cover a broader range of technologies. Moreover, sections in this category now regulate the frequency of scans and checks, as well as other aspects.\n\n* 5.1 Processes and mechanisms for protecting all systems and networks from malicious software are defined and understood.\n* 5.2 Malicious software (malware) is prevented, or detected and addressed.\n* 5.3 Anti-malware mechanisms and processes are active, maintained, and monitored.\n* 5.4 Anti-phishing mechanisms protect users against phishing attacks.\n\n### 6. Develop and Maintain Secure Systems and Software\n\nIn this requirement, one of the new sections added (6.4) refers to automating the detection and prevention of attacks over public-facing web apps. Sections 6.1 and 6.3 also contain new requirements.\n\n* 6.1 Processes and mechanisms for developing and maintaining secure systems and software are defined and understood.\n* 6.2 Bespoke and custom software are developed securely.\n* 6.3 Security vulnerabilities are identified and addressed.\n* 6.4 Public-facing web applications are protected against attacks.\n* 6.5 Changes to all system components are managed securely.\n\n### 7. Restrict Access to System Components and Cardholder Data by Business Need to Know\n\nThis requirement includes new rules regarding the review of user accounts and their privileges, as well as the management and privileges of applications and system accounts.\n\n* 7.1 Processes and mechanisms for restricting access to system components and cardholder data by business need to know are defined and understood.\n* 7.2 Access to system components and data is appropriately defined and assigned.\n* 7.3 Access to system components and data is managed via an access control system(s).\n\n### 8. Identify Users and Authenticate Access to System Components \n\nMany new sections regarding MFA, credentials and the entire authentication process have been added in this requirement. Two examples of changes that companies compliant with PCI DSS have to implement now are: the minimum length of a user account password has increased from 7 to 12 characters, and companies are not allowed to store passwords/passphrases in scripts or files.\n\n* 8.1 Processes and mechanisms for identifying users and authenticating access to system components are defined and understood.\n* 8.2 User identification and related accounts for users and administrators are strictly managed throughout an account’s lifecycle.\n* 8.3 Strong authentication for users and administrators is established and managed.\n* 8.4 Multi-factor authentication (MFA) is implemented to secure access into the CDE.\n* 8.5 Multi-factor authentication (MFA) systems are configured to prevent misuse.\n* 8.6 Use of application and system accounts and associated authentication factors is strictly managed.\n\n### 9. Restrict Physical Access to Cardholder Data \n\nThis requirement does not have many changes. Some sections that refer to roles and responsibilities, as well as the frequency of device inspections have been added.\n\n* 9.1 Processes and mechanisms for restricting physical access to cardholder data are defined and understood.\n* 9.2 Physical access controls manage entry into facilities and systems containing cardholder data.\n* 9.3 Physical access for personnel and visitors is authorized and managed.\n* 9.4 Media with cardholder data is securely stored, accessed, distributed, and destroyed.\n* 9.5 Point of interaction (POI) devices are protected from tampering and unauthorized substitution.\n\n### 10. Log and Monitor All Access to System Components and Cardholder Data \n\nNew sections in this requirement regulate the automation of logging, prompt response to failed security controls, as well as how often logs should be reviewed:\n\n* 10.1 Processes and mechanisms for logging and monitoring all access to system components and cardholder data are defined and documented.\n* 10.2 Audit logs are implemented to support the detection of anomalies and suspicious activity, and the forensic analysis of events.\n* 10.3 Audit logs are protected from destruction and unauthorized modifications.\n* 10.4 Audit logs are reviewed to identify anomalies or suspicious activity.\n* 10.5 Audit log history is retained and available for analysis.\n* 10.6 Time-synchronization mechanisms support consistent time settings across all systems.\n* 10.7 Failures of critical security control systems are detected, reported, and responded to promptly.\n\n### 11. Test Security of Systems and Networks Regularly\n\nThis category includes the following:\n\n* a new requirement to manage all applicable vulnerabilities,\n* a new requirement to perform internal vulnerability scans via authenticated scanning,\n* a new requirement to deploy a change-and-tamper-detection mechanism to alert for unauthorized modifications to the HTTP headers and contents of payment pages as received by the consumer browser, [according to PCI SSC](https://listings.pcisecuritystandards.org/documents/PCI-DSS-v3-2-1-to-v4-0-Summary-of-Changes-r1.pdf).\n\nThe full list of the sections included in this requirement is:\n\n* 11.1 Processes and mechanisms for regularly testing security of systems and networks are defined and understood.\n* 11.2 Wireless access points are identified and monitored, and unauthorized wireless access points are addressed.\n* 11.3 External and internal vulnerabilities are regularly identified, prioritized, and addressed.\n* 11.4 External and internal penetration testing is regularly performed, and exploitable vulnerabilities and security weaknesses are corrected.\n* 11.5 Network intrusions and unexpected file changes are detected and responded to.\n* 11.6 Unauthorized changes on payment pages are detected and responded to.\n\n### 12. Support Information Security with Organizational Policies and Programs\n\nThe title modification reflects that the focus is on organizational policies and programs. In PCI DSS version 4, requirements specify that the audited company should, at least every 12 months:\n\n* document and review cryptographic cipher suites and protocols,\n* review hardware and software components,\n* document the PCI DSS scope,\n* review and update the security awareness program, among other requirements, which are presented below.\n\n \n\n* 12.1 A comprehensive information security policy that governs and provides direction for protection of the entity’s information assets is known and current.\n* 12.2 Acceptable use policies for end-user technologies are defined and implemented.\n* 12.3 Risks to the cardholder data environment are formally identified, evaluated, and managed.\n* 12.4 PCI DSS compliance is managed.\n* 12.5 PCI DSS scope is documented and validated.\n* 12.6 Security awareness education is an ongoing activity.\n* 12.7 Personnel are screened to reduce risks from insider threats.\n* 12.8 Risk to information assets associated with third-party service provider (TPSP) relationships is managed.\n* 12.9 Third-party service providers (TPSPs) support their customers’ PCI DSS compliance.\n* 12.10 Suspected and confirmed security incidents that could impact the CDE are responded to immediately.\n\n## What do you have to do now? \n\nYou have to become PCI-DSS version 4 certified until the 31st of March 2024. There are two possible paths for your company:\n\n1. Your company is already PCI-DSS certified, so until the first deadline you must cover some of the new requirements and until the last deadline all of them, or\n2. Your company is not PCI-DSS certified, so you have to start from the beginning with the new PCI-DSS version and fulfill all requirements according to the specified deadlines.\n\nThis new version of PCI DSS brings considerable changes, and the process of achieving compliance with PCI DSS can be long and cumbersome.\n\nCyscale helps companies accelerate their cloud compliance process and ace audits by providing:\n\n* security controls that check if you’re implementing the requirements correctly, and\n* a page for each standard where you can track your progress and history.\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News"],"title":"Cyscale Ranked Among Top Ten in AWS B2B SaaS Accelerator","seoTitle":"Cyscale Ranked Among Top Ten in AWS B2B SaaS Accelerator","description":"AWS B2B SaaS Accelerator is a program launched by Amazon Web Services in collaboration with Vestbee that is meant to help support startups in their journey of developing innovations in different industries such as Cybersecurity, AI & Big Data, Financial Services & Insurance, Sustainability and ClimateTech, and others. Cyscale ranked in the top 10 out of hundreds of companies. Our product's key feature includes multi-cloud data security, a cloud compliance platform, CSPM capabilities, contextual visibility, The Security Knowledge Graph.","seoDescription":"AWS B2B SaaS Accelerator is a program launched by Amazon Web Services in collaboration with Vestbee that is meant to help support startups in their journey of developing innovations in different industries such as Cybersecurity, AI & Big Data, Financial Services & Insurance, Sustainability and ClimateTech, and others. Cyscale ranked in the top 10 out of hundreds of companies. Our product's key feature includes multi-cloud data security, a cloud compliance platform, CSPM capabilities, contextual visibility, The Security Knowledge Graph.","date":"2023-07-14T12:54:15.213Z","featuredpost":true,"permalink":"aws-b2b-saas-accelerator-announcement","featuredimage":{"publicURL":"/static/d46779ab11a4772757f1c39ef26135a0/47_blog-cover-aws-accelerator.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/d46779ab11a4772757f1c39ef26135a0/888e2/47_blog-cover-aws-accelerator.webp","srcSet":"/static/d46779ab11a4772757f1c39ef26135a0/913d0/47_blog-cover-aws-accelerator.webp 205w,\n/static/d46779ab11a4772757f1c39ef26135a0/91660/47_blog-cover-aws-accelerator.webp 410w,\n/static/d46779ab11a4772757f1c39ef26135a0/888e2/47_blog-cover-aws-accelerator.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"We’re excited to announce that we’ve been selected for the AWS B2B SaaS Accelerator! We’ve been shortlisted in the top 10 out of hundreds of companies. \n\nAWS B2B SaaS Accelerator is a program launched by Amazon Web Services in collaboration with Vestbee that is meant to help support startups in their journey of developing innovations in different industries such as Cybersecurity, AI & Big Data, Financial Services & Insurance, Sustainability and ClimateTech, and others. \n\nSome notable companies selected for this program are: \n\n[Privasee](https://www.privasee.io/), a SaaS that automates GDPR Compliance for SMEs.  \n\n[Datafy](https://trydatafy.com/), an analytics platform that helps companies grow faster and more profitably through AI-powered insights. \n\n[Gaston](https://gogaston.io/), a multi-awards winning, highly intelligent food personalisation engine focussing on boosting health and wellbeing.  \n\n[Boost.space](https://boost.space/), the new standard in data synchronization, and the first no-code two-way data synchronization tool that enables companies create standardized source of data for their whole dataset. \n\n[Myneral](https://myneral.com/), which helps businesses of any size prove where their products come from, how they are made and how sustainable they are, using the blockchain. \n\n[Bitskout](https://www.bitskout.com/), a software platform where teams can \"hire\" A.I. for their back-offices tasks.  \n\n[Coplug](https://coplug.co.uk/), a location data analytics SaaS business. Their product, Sidm Systems, provides timely, targeted and accurate insights to unlock complex decisions in planning of places, services and infrastructure. \n\n[Givver](https://www.givver.io/), the People Operating System dedicated to changing how SMEs onboard, manage and pay their international Teams. \n\n[Ethora](https://ethora.com/), a \"super app\" engine that allows startups and businesses to create their mobile and web apps in no time. \n\n[Medley](https://www.medley.gg/), the platform to manage and measure online communities. They allow companies and creators to align their community through micro incentivised tasks and understand their users granuarly with real time analytics. \n\n[qaTT](https://qatt.online/), an AI monitoring technology that helps DevOps and the engineering team to detect product issues faster and accurately using AI technology.  \n\n[TestInt](https://testint.ai/), a no-code data augmentation & AI testing platform specialized for computer vision problems.  \n\n[CodeMonk](https://www.codemonk.ai/), an online dashboard for companies to find gaps in their existing tech teams and hire vetted Developers, Data Scientists, Designers, Product Managers, DevOps Engineers and more on a flexible basis for accelerate product development. \n\n \n\nWe believe that Cyscale’s placement among the top 10 companies in the AWS B2B SaaS Accelerator is well-deserved due to our product’s key features: \n\n* [Multi-cloud data security](https://cyscale.com/use-cases/cloud-data-security/),  \n* [Security Knowledge Graph](https://cyscale.com/products/security-knowledge-graph/), \n* [Cloud compliance platform](https://cyscale.com/use-cases/cloud-compliance-and-auditing/), \n* [CSPM capabilities](https://cyscale.com/products/cloud-security-posture-management/), \n* [Contextual visibility](https://cyscale.com/blog/s3-bucket-security/). \n\nWe are incredibly excited to participate in this program, where we have the opportunity to gain invaluable insights from AWS mentors as we strive to help as many companies as possible secure their cloud!\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News","CSPM"],"title":"Secure Your Cloud Stack Now with our New Data Security E-book! ","seoTitle":"Secure Your Cloud Stack Now with our New Data Security E-book! ","description":"Our new e-book on data security contains best practices on how to encrypt and classify data, how to secure your cloud environment and many other recommendations to protect data. Read our comprehensive guide to expand your knowledge.","seoDescription":"Our new e-book on data security contains best practices on how to encrypt and classify data, how to secure your cloud environment and many other recommendations to protect data. Read our comprehensive guide to expand your knowledge.","date":"2023-05-10T12:19:20.367Z","featuredpost":true,"permalink":"data-security-e-book","featuredimage":{"publicURL":"/static/7e91adee2997dc20c6fc24cec964a69f/blog_39-cover-ebook.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/7e91adee2997dc20c6fc24cec964a69f/888e2/blog_39-cover-ebook.webp","srcSet":"/static/7e91adee2997dc20c6fc24cec964a69f/913d0/blog_39-cover-ebook.webp 205w,\n/static/7e91adee2997dc20c6fc24cec964a69f/91660/blog_39-cover-ebook.webp 410w,\n/static/7e91adee2997dc20c6fc24cec964a69f/888e2/blog_39-cover-ebook.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"We have emphasized many times how important data security is, and we have decided to write a comprehensive guide to help you implement the most important best practices! \n\nIn the paper, you will find: \n\n* How to encrypt in motion, in use and at rest data, \n* What data classification is and why you should implement it, \n* An in-depth guide to securing your AWS cloud environment from encryption, data loss prevention, to S3 bucket security, \n* Solutions for these problems through cloud security controls and a data security dashboard. \n\nTo read up-to-date recommendations regarding data security in the cloud and expand your knowledge, download the e-book:\n<div class=\"hs-cta-embed hs-cta-simple-placeholder hs-cta-embed-127064433808\"\n  style=\"max-width:100%; max-height:100%; width:210px;height:42.390625px\">\n  <a href=\"https://cta-service-cms2.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLKcdzdjs3ubIU5XI1ozY9QJ9YF2yD%2BsoZJAk2vNcR0qYhDoYVmmHNu5VA5Avb9E7Sr%2BRbNjqakYxt0DJ%2B1qbaeIfqdLwOEW0Tl%2FYSlNPTCQfjQ%3D&webInteractiveContentId=127064433808&portalId=5413427\" target=\"_blank\" rel=\"noopener\" crossorigin=\"anonymous\">\n    <img alt=\"Download the eBook\" loading=\"lazy\" src=\"https://no-cache.hubspot.com/cta/default/5413427/interactive-127064433808.png\" style=\"height: 100%; width: 100%; object-fit: fill\"\n      onerror=\"this.style.display='none'\" />\n  </a>\n</div\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News","Product","CSPM"],"title":"How to Prevent Alert Fatigue: Announcing the New Alert Features","seoTitle":"How to Prevent Alert Fatigue: Announcing the New Alert Features","description":"Alert fatigue is a phenomenon in which individuals receive an overwhelming amount of alerts and become desensitized to them. To avoid alert fatigue, a sound alert system with no noise is necessary. Knowing how to group alerts and how to manage them is very important. Cyscale provides alerts visualization, alerts grouping, alerts exemption and alerts remediation to ensure that users have a deep understanding of their cloud infrastructure and can easily manage their alerts.","seoDescription":"Alert fatigue is a phenomenon in which individuals receive an overwhelming amount of alerts and become desensitized to them. To avoid alert fatigue, a sound alert system with no noise is necessary. Knowing how to group alerts and how to manage them is very important. Cyscale provides alerts visualization, alerts grouping, alerts exemption and alerts remediation to ensure that users have a deep understanding of their cloud infrastructure and can easily manage their alerts.","date":"2023-03-20T04:55:49.633Z","featuredpost":true,"permalink":"prevent-alert-fatigue","featuredimage":{"publicURL":"/static/2a994aa75bad2e92e8ff052e1df44847/36_blog-cover-image.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/2a994aa75bad2e92e8ff052e1df44847/888e2/36_blog-cover-image.webp","srcSet":"/static/2a994aa75bad2e92e8ff052e1df44847/913d0/36_blog-cover-image.webp 205w,\n/static/2a994aa75bad2e92e8ff052e1df44847/91660/36_blog-cover-image.webp 410w,\n/static/2a994aa75bad2e92e8ff052e1df44847/888e2/36_blog-cover-image.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nAlert fatigue is a phenomenon in which individuals receive an overwhelming amount of alerts and become desensitized to them.  \n\nIf a security team sees hundreds of alerts every day that do not have critical information, they may start to pay less attention to them. Then, if a real cybersecurity event were to happen, they may not catch it in time, since alerts are not considered important anymore. \n\nTo avoid alert fatigue, a sound alert system with no noise is necessary. Knowing how to group alerts and how to manage them is very important. \n\nCyscale is a CSPM that provides solutions for alert fatigue and helps users understand their alerts. In this article, we will explain how. \n\n## Alerts visualization \n\nThe first step to managing alerts efficiently is understanding them. With the following four sections, you get to see how your company is handling the alerts at a glance. \n\n<img src=\"/img/36_blog-1-cards.webp\" alt=\"Alerts visualization cards in the Cyscale platforrm\" title=\"Alerts visualization cards in the Cyscale platforrm\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nThe **Insights** card gives you context on how many alerts your assets have generated, as well as the average time to resolve them. This valuable information shows how efficiently the security team is working through findings. \n\nThe next section, **Summary**, shows how many alerts have a High severity and how many have a Medium severity, as well as other information about your environment. \n\nThe third card, **Trend**, illustrates the evolution of alerts over time. The time component, which is present in the first section as well, is key to fully understanding how well your company is progressing towards securing the cloud infrastructure over time. \n\nFinally, the fourth section, **Open Alerts by Asset Category**, shows the distribution of alerts over the types of assets in the cloud. For example, knowing that your IAM or your storage assets generate the most alerts can help you focus your attention on those areas of your cloud security posture. \n\n## Alerts grouping  \n\nThere are two views for alerts: \n\n1. Grouped by control, and \n2. An ungrouped list of all alerts. \n\n**The first view** makes alerts visualization more manageable by shortening the list and grouping the alerts by control.  \n\n<img src=\"/img/36_blog-2-grouped-by-control.png\" alt=\"Alerts grouped by control in the Cyscale platform\" title=\"Alerts grouped by control in the Cyscale platform\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nThe result of this view is reducing alert fatigue by grouping the triggered alerts under a single item in the list. Each row represents one control, and in the fourth column, the user can see the total number of alerts, with a quick link to the affected assets. \n\n<img src=\"/img/36_blog-gif.gif\" alt=\"Seeing affected assets in the Cyscale platforrm\" title=\"Seeing affected assets in the Cyscale platforrm\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nMoreover, this feature allows users to perform actions on multiple alerts through one click: for example, you can dismiss or acknowledge all alerts triggered by a control using this panel. \n\n**The second view** is a simplified view of the alerts. This is the old version of our Alerts dashboard, where you can search by alert and directly see details such as the severity, the status, or the affected asset.  \n\n<img src=\"/img/36_blog-3-all-alerts.png\" alt=\"All alerts page in the Cyscale platform\" title=\"All alerts page in the Cyscale platform\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n## Alerts exemption \n\nUsing alert exemption, users can reduce the number of alerts and eliminate false positives. Generating an exemption is very easy and can be done straight from the alerts list. The exemptions are highlighted in the compliance reports to ensure visibility and help users understand: \n\n* why they were created, \n* who created them and why,  \n* when they were created. \n\n<img src=\"/img/36_blog-4-create-exemptions.png\" alt=\"Creating exemptions in the Cyscale platform\" title=\"Creating exemptions in the Cyscale platform\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n## Alerts remediation \n\nIt’s never been easier to solve alerts than with the Cyscale platform!  \n\nBy clicking on the control that generated the alerts, a drawer with remediation steps appears. You don’t have to go through documentation and hours of trial and error – we give you the exact measures you have to take to fix your environment! \n\n<img src=\"/img/36_blog-5-remediation-steps.png\" alt=\"Remediation steps in the Cyscale platform\" title=\"Remediation steps in the Cyscale platform\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nWe hope you will enjoy the new features. Stay tuned for another set of improvements that bring more context to alerts! \n\n<!--EndFragment-->\n"}}]}},"pageContext":{"limit":9,"skip":0,"numPages":3,"currentPage":1,"category":"News","seoTitle":"Cyscale - News","seoDescription":"News about Cyscale","categoriesList":["News","CSPM","Product","Compliance","CNAPP","Engineering"]}},"staticQueryHashes":["3765828210","4109069157","632500807","981947644"],"slicesMap":{}}