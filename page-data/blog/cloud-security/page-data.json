{"componentChunkName":"component---src-template-blog-categories-template-js","path":"/blog/cloud-security/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Critical Confluence Authorization Vulnerability Actively Exploited","seoTitle":"Critical Confluence Authorization Vulnerability Actively Exploited","description":"Atlassian has warned that as of November 6th it has observed 'several active exploits' and reports of threat actors using ransomware in association with a critical Improper Authorization Vulnerability in Confluence Data Center and Server.","seoDescription":"Atlassian warns of  active exploits and threat actors using ransomware in critical Improper Authorization Vulnerability in Confluence Data Center and Server.","date":"2023-11-08T11:55:39.247Z","featuredpost":true,"permalink":"critical-authorization-vulnerability-confluence-exploited","featuredimage":{"publicURL":"/static/d806873ee5f93307e67b021fd9e0128e/confluence-criticalvuln-exploit.jpg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/d806873ee5f93307e67b021fd9e0128e/2c0f5/confluence-criticalvuln-exploit.jpg","srcSet":"/static/d806873ee5f93307e67b021fd9e0128e/41be8/confluence-criticalvuln-exploit.jpg 205w,\n/static/d806873ee5f93307e67b021fd9e0128e/c78f7/confluence-criticalvuln-exploit.jpg 410w,\n/static/d806873ee5f93307e67b021fd9e0128e/2c0f5/confluence-criticalvuln-exploit.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/d806873ee5f93307e67b021fd9e0128e/913d0/confluence-criticalvuln-exploit.webp 205w,\n/static/d806873ee5f93307e67b021fd9e0128e/91660/confluence-criticalvuln-exploit.webp 410w,\n/static/d806873ee5f93307e67b021fd9e0128e/888e2/confluence-criticalvuln-exploit.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"Atlassian has warned that as of November 6th it has observed 'several active exploits' and reports of threat actors using ransomware in association with a critical Improper Authorization Vulnerability in Confluence Data Center and Server. \n\nCVE-2023-22518, first published on October 31st, 2023, is a Confluence vulnerability that affects all pre-existing versions of Data Center and Server. It was initially assigned a CVSS score of 9.1, which was increased to 10, the maximum, on November 6th.  \n\nThis is the [second critical vulnerability](https://confluence.atlassian.com/security/cve-2023-22515-privilege-escalation-vulnerability-in-confluence-data-center-and-server-1295682276.html) in Atlassian Data Center and Server discovered in the same month, alongside CVE-2023-22515.   \n\n## Confluence Improper Authorization vulnerability in detail \n\nThis vulnerability occurs due to Improper Authorization. The bug enables the attacker to: \n\n* reset a Confluence instance, and to \n* create a Confluence instance administrator account. \n\nThis means the attacker can either reset the entire instance, causing the company to lose data unless it is backed up, or they can steal the data by creating an administrator account.   \n\n### What you need to do: mitigation of the Confluence Improper Authorization vulnerability \n\nSince all versions prior to the attack are affected, [Atlassian urges users](https://confluence.atlassian.com/security/cve-2023-22518-improper-authorization-vulnerability-in-confluence-data-center-and-server-1311473907.html) to immediately patch to the new versions released:  \n\n* 7.19.16, \n* 8.3.4, \n* 8.4.4, \n* 8.5.3, \n* 8.6.1. \n\nIf patching is not possible straight away, remove the instance from being publicly accessible. This is a temporary measure that allows you to gain time by limiting the attack surface – if your instance is not Internet-facing, attackers cannot reach it as easily. \n\nBesides this, it is recommended to back-up your instance. \n\nIf you cannot patch the instance and remove it from the internet, you can apply the following temporary solutions, which you can also find on [Atlassian’s page](https://confluence.atlassian.com/security/cve-2023-22518-improper-authorization-vulnerability-in-confluence-data-center-and-server-1311473907.html): \n\nBlock access to the following endpoints: \n\n* /json/setup-restore.action \n* /json/setup-restore-local.action \n* /json/setup-restore-progress.action \n\nTo do that, on each node, modify /<confluence-install-dir>/confluence/WEB-INF/web.xml and add the following block of code (just before the </web-app> tag at the end of the file): \n\n```\n\n<security-constraint>\n\t\t<web-resource-collection>\n\t\t\t<url-pattern>/json/setup-restore.action</url-pattern>\n\t\t\t<url-pattern>/json/setup-restore-local.action</url-pattern>\n\t\t\t<url-pattern>/json/setup-restore-progress.action</url-pattern>\n\t\t\t<http-method-omission>*</http-method-omission>\n\t\t</web-resource-collection>\n\t<auth-constraint />\n</security-constraint>\n```\n\nThen, restart your instance.   \n\n### How do you know if you were affected? \n\nIf you cannot login anymore, it could be a sign that your Confluence instance has been compromised. Besides this, look out for: \n\n* requests to /json/setup-restore* in your logs, \n* installed unknown plugins (the malicious plugin web.shell.Plugin was reported, according to Atlassian), \n* corrupted data or encrypted files that were not encrypted before, \n* new and unexpected members of the confluence-administrators group, \n* new and unexpected user accounts. \n\nCyscale customers are already protected, as the [Cyscale cloud security platform](https://cyscale.com/products/cloud-security-posture-management/) surfaces assets affected by the Improper Authorization Vulnerability in Confluence Data Center and Server as long as their vulnerability scanner of choice has been updated."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"High-severity Vulnerabilities Put Kubernetes Secrets at Risk","seoTitle":"Critical NGINX Ingress Vulnerabilities Put Kubernetes Secrets at Risk","description":"Three high-severity security vulnerabilities have been disclosed in the NGINX Ingress controller for Kubernetes, which could put credentials and other secrets at risk of theft by threat actors. ","seoDescription":"Three critical vulnerabilities disclosed in the NGINX Ingress controller for Kubernetes could put credentials and other secrets at risk of theft. ","date":"2023-11-06T15:15:20.627Z","featuredpost":true,"permalink":"critical-vulnerabilities-kubernetes-secrets-risk","featuredimage":{"publicURL":"/static/39ce29032b69e2b79bf9fb939dfe5957/kubernetes-critical-vulns.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/39ce29032b69e2b79bf9fb939dfe5957/2c0f5/kubernetes-critical-vulns.jpg","srcSet":"/static/39ce29032b69e2b79bf9fb939dfe5957/41be8/kubernetes-critical-vulns.jpg 205w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/c78f7/kubernetes-critical-vulns.jpg 410w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/2c0f5/kubernetes-critical-vulns.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/39ce29032b69e2b79bf9fb939dfe5957/913d0/kubernetes-critical-vulns.webp 205w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/91660/kubernetes-critical-vulns.webp 410w,\n/static/39ce29032b69e2b79bf9fb939dfe5957/888e2/kubernetes-critical-vulns.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"Three high-severity security vulnerabilities have been disclosed in the NGINX Ingress controller for Kubernetes, which could put credentials and other secrets at risk of theft by threat actors. \n\n## What are the NGINX Ingress controller vulnerabilities? \n\nOn October 27, 2023, three critical vulnerabilities were disclosed and assigned the following CVE numbers: \n\n* [CVE-2023-5043](https://nvd.nist.gov/vuln/detail/CVE-2023-5043),  \n* [CVE-2023-5044](https://nvd.nist.gov/vuln/detail/CVE-2023-5044), and  \n* [CVE-2022-4886.](https://nvd.nist.gov/vuln/detail/CVE-2022-4886) \n\nAll three vulnerabilities allow an attacker to execute arbitrary command execution and obtain the ingress-NGINX controller credentials. These vulnerabilities have been assigned a CVSS score of 7.6 (the first two) and 8.6 (the third one), ranked HIGH. \n\nTo better understand how the vulnerabilities can be exploited, what the impact is on your cloud infrastructure and how they can be patched, let’s dive deeper: \n\n### What is an NGINX Ingress controller? \n\nThe ingress-NGINX controller is a [specialized load balancer](https://www.nginx.com/resources/glossary/kubernetes-ingress-controller/) for Kubernetes and other containerized environments that accepts incoming traffic and routes it to Kubernetes pods. The NGINX Ingress controller is designed to be a central point of entry into a Kubernetes cluster adding a layer of abstraction to reduce routing complexity.  \n\nTo put it simply, it’s like a traffic policeman that tells all vehicles on a road where they are and are not allowed to go. \n\nAn ingress-NGINX controller is a specific implementation of an Ingress controller that uses the NGINX web server, which is known for its speed and efficiency.   \n\n### The 3 NGINX Ingress controller vulnerabilities in detail \n\n**CVE-2023-5043** \n\nAnnotations are key/value pairs that can be attached to Kubernetes objects in order to add additional information to those objects. \n\nDue to poor input sanitization, the annotation nginx.ingress.kubernetes.io/configuration-snippet can be used to inject command execution. \n\nThe “configuration-snippet” annotation, or metadata, allows users to inject custom configuration code into the NGINX configuration file. \n\n**CVE-2023-5044** \n\nThis vulnerability occurs for the nginx.ingress.kubernetes.io/permanent-redirect annotation. This annotation allows you to establish a permanent HTTP redirect (Return Code 301) by injecting arbitrary code via the annotation. As a result, the controller will redirect traffic to that path. \n\n**CVE-2022-4886** \n\nThis issue can be exploited by someone with create or update permissions on ingress API objects.   \n\nThe field spec.rules\\[].http.paths\\[].path allows you to specify where incoming requests to your applications should be routed based on the path in the URL. Since the input is not correctly sanitized, the attacker can specify an internal file as the path, obtaining the credentials of the controller. Thus, by exploiting the poor sanitization, the attacker gains access to sensitive data. \n\n### Impact of the NGINX Ingress controller vulnerabilities \n\nIngress controllers run with high privileges. By default, having access to the credentials of the ingress controller means you have access to all secrets in the cluster. As you can imagine, the impact of these vulnerabilities left unchecked can create significant risk for your data. So, it’s no surprise that the vulnerabilities described have been assigned such high CVSS scores.  \n\n### Mitigation of the NGINX Ingress controller vulnerabilities \n\nTo protect your cloud environment from these vulnerabilities, follow these steps: \n\n* for CVE-2023-5043 and CVE-2023-5044, update NGINX to version 1.19 and set the --enable-annotation-validation flag, \n* for CVE-2022-4886, change the pathType attribute of the controller to Exact or Prefix. This will allow only paths that start with “/” and contain alphanumeric characters, “-“, “_”, and additional “/”.  \n\n### The impact of NGINX Ingress controller vulnerabilities on cloud environments  \n\nThe next question is, are cloud environments impacted by these vulnerabilities? Yes! Many cloud environments run Kubernetes clusters with NGINX-ingress controllers. For a cloud-native company building software that heavily relies on Kubernetes and employs ingress-controllers, there are significant risks involved. If exploited, these bugs can lead to unauthorized access to sensitive information stored in the cluster. \n\nMoreover, the ingress controller manages incoming traffic, so the disruption of such a critical component of an infrastructure can cause availability issues leading to downtime and possible financial losses. \n\nCyscale customers are already protected, as the [Cyscale cloud security platform](https://cyscale.com/products/cloud-security-posture-management/) surfaces assets affected by the NGINX Ingress controller bugs as long as their vulnerability scanner of choice has been updated."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Understanding serverless computing: how you can use it and how to secure it ","seoTitle":"Understanding serverless computing: how you can use it and how to secure it ","description":"Serverless computing is a collection of services provided by cloud vendors. It allows users to write and execute code in the cloud without setting up the environment and allocating resources such as VMs beforehand. Benefits include a pay-as-you-go model, granular updates and patches, no server management required, and others. In the industry, you can find serverless computing products like AWS Lambda, AWS Fargate, Cloud Run, Cloud Functions, Azure Serverless. Vulnerabilities may appear in serverless computing due to source code flaws, unpatched or outdates libraries or packages, information disclosure in error messages and many others.","seoDescription":"Serverless computing is a collection of services provided by cloud vendors. It allows users to write and execute code in the cloud without setting up the environment and allocating resources such as VMs beforehand. Benefits include a pay-as-you-go model, granular updates and patches, no server management required, and others. In the industry, you can find serverless computing products like AWS Lambda, AWS Fargate, Cloud Run, Cloud Functions, Azure Serverless. Vulnerabilities may appear in serverless computing due to source code flaws, unpatched or outdates libraries or packages, information disclosure in error messages and many others.","date":"2022-11-17T08:55:54.909Z","featuredpost":true,"permalink":"what-is-serverless-computing","featuredimage":{"publicURL":"/static/12acbeec855dfb4da8a6b0a9110f6ed0/27_blog-serverless-computing.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/12acbeec855dfb4da8a6b0a9110f6ed0/888e2/27_blog-serverless-computing.webp","srcSet":"/static/12acbeec855dfb4da8a6b0a9110f6ed0/913d0/27_blog-serverless-computing.webp 205w,\n/static/12acbeec855dfb4da8a6b0a9110f6ed0/91660/27_blog-serverless-computing.webp 410w,\n/static/12acbeec855dfb4da8a6b0a9110f6ed0/888e2/27_blog-serverless-computing.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## What is serverless computing? \n\nServerless computing is a collection of services provided by cloud vendors. It allows users to write and execute code in the cloud without setting up the environment and allocating resources such as VMs beforehand. \n\nBenefits of serverless computing are: \n\n* **A pay-as-you-go model**, allowing code to only run when needed, \n* **No server management required**, since your code is running in the cloud, and you don't have to deal with the environment settings, \n* **Granular updates and patches** that allow developers to make changes at function-level and quickly deploy new versions, \n* **High reliability applications**, since the code runs on the cloud. \n\n## Services offered by cloud vendors \n\nTo further understand what serverless computing has to offer, we must look at services on the market and their features.  \n\n### 1. AWS Lambda and AWS Fargate \n\n**AWS Lambda** is a compute service that allows users, through functions, to run event-driven code without server provisioning or management. AWS Lambda can be used for: \n\n* File processing, \n* Stream processing, \n* Web and mobile applications, \n* IoT backends, and others. \n\nThe event-driven flows help reduce costs for users and add flexibility. Lambda functions are triggered by events, and customers only pay for the time the code is running.  \n\nMoreover, when creating a Lambda function, you can either start writing a function from scratch, or use sample code such as Amazon’s blueprints or the AWS Serverless Application Repository to implement your desired code. \n\n**AWS Fargate** is a compute engine that provides a serverless solution for application deployment by removing the need for infrastructure management. \n\nAmazon Elastic Kubernetes Service (EKS) is a service that allows Kubernetes instances to run both in the cloud and on-premises. EKS, together with AWS Fargate, produce a serverless solution for containers. \n\nFargate can also be used with Amazon Elastic Container Service (ECS), with no additional changes required for your applications. \n\n### 2. Azure Serverless  \n\nMicrosoft Azure offers a collection of serverless compute solutions. Just like AWS Lambda, Azure Serverless enables its users to deploy code without worrying about the underlying infrastructure.  \n\nSome of the Azure compute services are: \n\n* **Serverless Functions.** Just like AWS Lambda, Azure allows users to write event-driven code in their preferred language. Costs are applied only when the code is being executed, \n* **Serverless Kubernetes.** Azure Kubernetes Service (AKS), together with AKS virtual nodes, provide a serverless solution that reduces the infrastructure management workload of Kubernetes clusters. \n* **Serverless Containerized Microservices.** With this solution, applications are deployed in containers without managing the infrastructure,  \n* **Serverless Application Environments.** Using Azure App Service, web, mobile, and API applications are hosted in a fully managed environment.  \n\nAzure also provides low-code or no-code application development with Power Apps. This feature allows developers to construct applications using drag-and-drop functionalities, connectors, and readily-available solutions for common use cases. \n\n### 3. Cloud Run and Cloud Functions by Google Cloud \n\nThese two solutions offered by Google Cloud provide serverless compute services.  \n\n**Cloud Run** is an application development tool that separates infrastructure management from the code by placing applications in containers. Using Cloud Run, microservices can be deployed without specific configurations. It is highly scalable, and it can scale to zero – this means that if a service has no requests, all containers are removed, reducing costs. It supports the following programming languages: Go, Python, Java, Node.js, Ruby, .NET, as well as others. \n\n**Cloud Functions** is a similar service to AWS Lambda and Azure Serverless. \n\n## Possible vulnerabilities of serverless computing \n\n### 1. Lack of source code security \n\nMany cyber attacks are successful due to poor code security.  \n\nAccording to [OWASP Top 10](https://owasp.org/www-project-top-ten/), one of the most common attacks on web applications in 2022 was SQL Injection. Whether an application is hosted in the cloud or not, user input should always be treated very carefully. \n\nTo correctly handle data received from users, you should sanitize it correctly and use prepared statements. \n\n### 2. Outdated or unpatched libraries, packages, and dependencies \n\nAnother element that affects applications' security is the libraries, packages, technologies, and dependencies used.  \n\nIn 2021, a critical vulnerability was discovered. Log4j, a popular Java framework used for logging messages in applications, introduced a massive flaw: it allowed attackers to execute arbitrary code on the host machine. This vulnerability, CVE-2021-44228, commonly known as Log4Shell, [affected around 3 billion devices](https://www.acaglobal.com/insights/log4shell-vulnerability-what-we-know-and-action-steps-take).   \n\nServerless functions in the cloud were not immune to this attack. The functions written in Java that were using Log4j were vulnerable to Log4Shell. \n\nWhile not having to deal with underlying infrastructure management is an advantage of serverless computing, technologies used by developers still have to be used safely. \n\nHow do you protect your code from such vulnerabilities? \n\n* Only use trusted libraries, \n* Apply updates and patches as they appear, \n* Continuously assess your code, \n* Remove any unnecessary dependencies. \n\n### 3. Monitor your cloud infrastructure \n\nThis measure is a given. Log and monitor what your applications do to identify any odd behavior.  \n\nDocument every event that interacts with your code and see how your applications respond.  \n\n### 4. Integrate cryptography into your code \n\n[Encrypt sensitive data](https://cyscale.com/blog/types-of-encryption/) to ensure confidentiality in your applications’ flow. You should encrypt data in transit using TLS/SSL and at rest data using AES. \n\nMoreover, safely store secrets and keys in Hardware Security Modules (HSM) or in your cloud using services such as: \n\n* Azure Key Vault,  \n* AWS Key Management Service (AWS KMS),  \n* Cloud Key Management Service in Google Cloud. \n\nDo not store keys, connection strings, or passwords in the source code or in plain text. \n\n### 5. Too much information is disclosed in error messages. \n\nWe’ve all encountered verbose error messages. \n\nDevelopers should not disclose information about errors or exceptions to the user. Instead, they should be handled in the code, and the message displayed should offer minimal explanations without revealing why the error occurred. \n\n  \n\nWhile writing code in the cloud and quickly deploying it without infrastructure management is tempting, you should be careful.  \n\nImplement the best practices recommended in this article to address serverless computing vulnerabilities and secure your cloud environment. \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["Cloud Security"],"title":"A Word on Cloud Security","seoTitle":"A Word on Cloud Security","description":"Given all this complexity and the pace at which we are trying to deliver our products, it’s no surprise that breaches still happen. However, we can go fast and build secure systems. It’s not a zero-sum game. You probably have people in your organization that are naturally passionate about security. Give them the responsibility, the training, and the tools. You probably don’t need that many people to do security full-time since the tools are getting increasingly powerful.\n","seoDescription":"Given all this complexity and the pace at which we are trying to deliver our products, it’s no surprise that breaches still happen. However, we can go fast and build secure systems. It’s not a zero-sum game. You probably have people in your organization that are naturally passionate about security. Give them the responsibility, the training, and the tools. You probably don’t need that many people to do security full-time since the tools are getting more and more powerful.","date":"2022-10-25T14:41:49.426Z","featuredpost":true,"permalink":"a-word-on-cloud-security","featuredimage":{"publicURL":"/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/microsoftteams-image-3-.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/888e2/microsoftteams-image-3-.webp","srcSet":"/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/913d0/microsoftteams-image-3-.webp 205w,\n/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/91660/microsoftteams-image-3-.webp 410w,\n/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/888e2/microsoftteams-image-3-.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"## Security is Foundational\n\nWhy care about cloud security? Or about security at all? Let’s zoom out even more and talk about the virtues we, as people, often desire for ourselves and look for in others. These include courage, compassion, generosity, temperance, persistence, and friendliness. As Brian Tracy points out in his excellent book, “No Excuses!: The Power of Self-Discipline”, all these virtues depend on and are guaranteed by one of them: **integrity**. Just like this, our software products have multiple requirements including functional (it must solve specific problems) and non-functional (performance, availability, efficiency, etc.). All these depend on the trust our users have in our systems to keep their data safe; they depend on **security**.\n\nIn theory, the most secure software is the one that doesn’t exist. If you have nothing, there is nothing to worry about. In practice, you will probably want to achieve certain things, to deliver certain features within a reasonable timeframe and budget. Luckily for us, the cloud providers offer a sizeable suite of services that might help us. In the era of data-driven, microservices-based, global-scale systems, we end up using some of them for compute (e.g. EC2, AKS, GKE, Lambda, Cloud Run), storage (S3), business intelligence (Redshift, Power BI), integration (Pub/Sub, Kinesis, API Gateway, SQS, SNS, Azure Service Bus), and so on. AWS even offers a service that lets you make use of their (satellite) ground stations. If you are competing with Elon’s Starlink or you are building a weather forecasting system, you might find it useful\n\n## Great Power, Great Responsibility\n\nNaturally, you must understand how to configure each cloud service you end up using and make them work together. One fundamental concept provided by the cloud is the way you manage access. You have control over both the network (so the service is actually reachable or not) and IAM (whether the clients must have identities and sufficient permissions). On one end of the spectrum, you can leave everything open and hope everyone expects that you have it properly set up. On the other end, you can choose a very restrictive configuration that might slow down your team. This is often known as the tradeoff between security and usability (for your dev team in this case). Over the past few years, the industry started shifting more toward security introducing concepts such as zero trust security and SSO (please make use of it whenever possible; also, it’s a shame that some companies still provide SSO only with their enterprise plans).\n\nClassically, you had a number of VMs (on-premises, VPS), installed and configured UFW, set up SSH access, and sent the SSH keys to your colleagues. Now, you can configure public and **private** (sub)networks, connect your cloud networks to your on-premises networks, deploy load balancers, define firewall rules without ever SSH-ing into the VMs, and assign identities and permissions to the VMs (and any other compute service). If previously your team didn’t interact too much with the infrastructure side, **now the infrastructure is part of the application**.\n\n## Network Access\n\nStarting with configuring the network access, here you have multiple options to control it. Perhaps the simplest concept is making the resources public or private. Your VM might have a vulnerable OS version, but if nothing can reach it and it cannot reach the internet, the risk is considerably lower. Not only can you run most compute and database services in a private network, but you can also configure fully managed services to be accessible through the provider's internal network (without traversing the internet) by leveraging services such as [AWS PrivateLink](https://aws.amazon.com/privatelink/) and [Azure Private Link](https://learn.microsoft.com/en-us/azure/private-link/private-link-overview).\n\nFurthermore, you can (have to) configure firewalls. Here the services vary a bit. Google Cloud calls them [VPC firewall rules](https://cloud.google.com/vpc/docs/firewalls). You define them at the VPC level and can optionally choose to which instances they should apply based on tags (they are not equivalent to AWS/Azure tags. In Google Cloud, the equivalent would be the resource labels) or service accounts (almost every resource can have an identity, which in Google Cloud, is given by service accounts). In AWS, you work with security groups that are assigned to virtual machines. Besides allowing traffic (by default everything is denied) from certain IP addresses or CIDRs, you can also choose based on the security group of the source (please make use of this). You can also achieve this in Azure, but you have to combine two types of resources: network security groups (these are the actual firewalls) and application security groups (you can associate these with the network tags from Google Cloud). In fact, here are the sources you can configure for each provider:\n\n* AWS: CIDRs, IP addresses, security groups, prefix lists (if you want to allow traffic coming only from certain AWS services)\n* Azure: CIDRs, IP addresses, application security groups, service tags (e.g. \\`AzureLoadBalancer\\`, \\`Internet\\`)\n* Google Cloud: CIDRs, IP addresses, network tags (defined on each instance), service accounts\n\nOf course, this is not all. You also have network access control lists (NACLs), firewalls specific to each service (especially managed databases from Azure), NAT gateways, VPC peering, VPNs, virtual appliances, traffic splitting, firewalls that you install on the VMs, and a lot more. All these bring considerable complexity and make it extra difficult to configure the optimal **effective network access**.\n\nAdditionally, while there are tools that check the traffic in real-time, these are often dealing with network paths that you defined and are aware of. There might be paths you did not intend to leave open that an attacker might make us for **lateral movement**.\n\n## IAM Access\n\nNot only can every member of your organization have a user (or multiple) with access to certain parts of your infrastructure, but so does almost every compute resource. Just like you provide John with permission to read data from a bucket, so you assign a role to a VM achieving the same access. The difference is that anything that runs on the VM and everyone who can access it (i.e. SSH into it) now can do everything the VM can do.\n\nFundamentally, this mechanism of assigning roles to resources is excellent. You have clear visibility of the principals (users, resources) that can access a given service, you can grant or revoke access at any moment, and you have a meaningful trail of access logs. The alternative is often based on keys/secrets and is almost impossible to trace properly because anyone that has the key can access the resource (it’s easy to lose track of who has the key) (secret scanners help a bit here but are limited to the resources they run on).\n\nWe just have to understand its implications. If attackers manage to break into a VM and if that VM has high (excessive?) permissions, the attackers will not only be able to access our data, but they will also be able to spin up additional instances (crypto mining?) and delete existing resources (service disruption and data loss).\n\nAgain, here it’s important to understand the effective permissions each resource has. There are multiple factors that contribute to the effective permissions such as the role assigned to the resource, permissions inherited from group memberships or from assignments at a higher level (the VM might be an owner at the subscription level in Azure thus having access to everything in that subscription), and policies configured on the target resources such as [resource policies in AWS](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_identity-vs-resource.html) and [access policies for Azure Key Vaults](https://learn.microsoft.com/en-us/azure/key-vault/general/security-features).\n\nAnother important aspect about effective permissions in the context of data access is encryption, especially encryption with customer-managed keys. For example, if you store data on S3 and encrypt it with a key managed by AWS KMS, you must have access to both the S3 bucket/object and the encryption key from KMS. Managing encryption keys deserves an article on its own.\n\n## The Human Factor\n\nEven if you have pristine infrastructure security, you still must provide access to someone (at least two admins so one doesn’t lock himself out by mistake - aka admin redundancy) to maintain the infrastructure and manage access for everyone else. This is an example of a highly privileged user. This in itself is not a major risk. However, if highly privileged users don’t have strong authentication mechanisms in place (MFA, preferably with strong factors), they can become liabilities. We are all subject to social engineering and phishing attacks.\n\nWhen you find out that an attacker managed to gain access to a highly privileged user, after revoking the sessions and rotating the credentials, you will want to find out the impact. For this, you need to know the systems to which the user has access. This can be quite challenging since the permissions are often spread across multiple systems.\n\nFor example, if you have Okta as the identity provider and AWS for the cloud infrastructure, you have to check both systems and link the results in order to determine what a person actually has access to. In Okta you just provide access to an application, but in AWS that application is often an AWS Organization with multiple accounts.\n\n## Ending Notes\n\nGiven all this complexity and the pace at which we are trying to deliver our products, it’s no surprise that breaches still happen. However, we can go fast and build secure systems. It’s not a zero-sum game. You probably have people in your organization that are naturally passionate about security. Give them the responsibility, the training, and the tools. You probably don’t need that many people to do security full-time since the tools are getting increasingly powerful.\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Cloud Data Security For AWS: An In-Depth Guide","seoTitle":"Cloud Data Security For AWS: An In-Depth Guide ","description":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","seoDescription":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","date":"2022-09-29T06:25:58.261Z","featuredpost":true,"permalink":"cloud-security-for-aws","featuredimage":{"publicURL":"/static/8439e84f30635c75021e87142b3bea7b/24_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp","srcSet":"/static/8439e84f30635c75021e87142b3bea7b/913d0/24_blog-cover-photo.webp 205w,\n/static/8439e84f30635c75021e87142b3bea7b/91660/24_blog-cover-photo.webp 410w,\n/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->  \n\nUnderstanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. \n\nIn this article, you will find a comprehensive guide that will help you understand possible misconfigurations in your AWS cloud infrastructure and how to remediate them.  \n\n## Steps to secure your cloud environment \n\n### 1. Data classification \n\n[Classifying your cloud data](https://cyscale.com/blog/data-classification/) can help you easily sort, retrieve, and prioritize it. This is done using a tag (sometimes called a label), which is applied to cloud storage assets. In this way, that data is placed into one or more categories and can be identified more easily. \n\nBenefits of data classification include: \n\n* Risk management, \n* Compliance,  \n* Security. \n\nIn AWS, tags are key-value pairs that add metadata to your data. \n\nThe AWS documentation recommends using a three-tiered approach, with the following tags: \n\n* Unclassified, \n* Official,  \n* Secret. \n\nHowever, users can tailor data classification to their needs and use their own tags. In addition, **tag policies** can be used to standardize their creation and ensure consistency across all assets. \n\nTo accomplish classification using tags in your AWS environment, you have the following options: \n\n* Using the Amazon console, at resource level, where tags can be added either at creation or after, \n* Programmatically, using the Amazon API, AWS CLI, or AWS SDK. \n\nAccording to the AWS documentation, restrictions regarding tags include: \n\n* There cannot be more than 50 tags per resource, \n* Each tag key must be unique for each resource, \n* The maximum key length is 128 Unicode characters in UTF-8, \n* The maximum value length is 256 Unicode characters in UTF-8. \n\n### 2. Encryption \n\nEncryption is the process of altering data in order to hide its content and ensure confidentiality because entities that do not have the decryption key cannot decrypt the data and, therefore, cannot read its content. \n\nThe two types of encryption mechanisms are: \n\n* **Symmetric encryption**, where the encryption and the decryption key are the same, and \n* **Asymmetric encryption**, where the two keys are different; one is called public key and the other private key. \n\nEncryption can be done in all three states of data: \n\n* [At rest,](https://cyscale.com/blog/protecting-data-at-rest/) \n* In transit, \n* In use. \n\nIn this article, we will discuss data encryption in the first two states, but [a more detailed article](https://cyscale.com/blog/types-of-encryption/) regarding encryption also describes encryption in the last state of data. \n\nFor data in transit, AWS provides the following solution: \n\n1. Encrypt the data using SSL/TLS. TLS (Transport Layer Security) and SSL (Secure Sockets Layer) are transport layer protocols that protect the data in transit. TLS is a newer and improved version of SSL. \n2. Perform client-side encryption. This solution requires the user to encrypt the data before uploading it to the cloud, but it is more difficult since the client has to deal with the encryption process, key management, and other services. \n\nFor data at rest, AWS provides encryption for the following services:  \n\n* Amazon EBS,  \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift,  \n* AWS Lambda, and many others. \n\nAWS uses the 256-bit Advanced Encryption Standard (AES-256) encryption algorithm, an industry-recommended standard and one of the strongest algorithms for symmetric encryption. \n\nKey management is also a very important element of data encryption. If your keys are not stored safely, then no matter how strong the encryption algorithm is, a malicious party may be able to read your data. \n\nA few best practices regarding encryption keys are: \n\n* Do not store your keys in the same place as your data or in the source code, \n* Rotate and retire keys regularly to minimize the impact of a breach, \n* Manage key deletion, \n* Use Cryptographically Secure Random Number Generators (CSRNGs) to generate your keys. \n\nAWS KMS (AWS Key Management System) is a comprehensive solution that helps users deal with all the trouble that comes with cryptographic keys. \n\nAWS KMS helps you: \n\n* Create cryptographic keys, \n* Define policies and control how the keys are used, \n* Audit the keys usage to ensure they are used legitimately. \n\nAccording to AWS, this service can be used: \n\n1. Through the AWS Management Console, \n2. Using the AWS KMS APIs. \n\n### 3. Access control \n\nRegulating access control is an essential step to your [cloud data security](https://cyscale.com/blog/cloud-data-security-guide/) program.  \n\nTo manage access control in AWS, you can use policies, which can be assigned at the following levels: \n\n* Users, \n* Groups of users, \n* Roles, \n* Resources. \n\nPolicies define permissions. To correctly implement them, use the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/) to only allow access rights to the necessary users for the minimum amount of time possible.  \n\nLet’s look at an example where a policy is applied to a resource.  \n\nAn AWS S3 bucket is a type of asset used to store object-like data such as files, databases, and other unstructured data. \n\nA bucket policy contains rules based on which access is allowed or denied and is written in JSON.  \n\n```jsonld\n{\n    \"Version\": \"2012-10-17\",\n    \"Id\": \"S3PolicyId1\",\n    \"Statement\": [\n        {\n            \"Sid\": \"IPAllow\",\n            \"Effect\": \"Deny\",\n            \"Principal\": \"*\",\n            \"Action\": \"s3:*\",\n            \"Resource\": [\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET\",\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET/*\"\n            ],\n            \"Condition\": {\n                \"NotIpAddress\": {\n                    \"aws:SourceIp\": \"54.240.143.0/24\"\n                }\n            }\n        }\n    ]\n}\n```\n\n*Policy source – docs.aws.amazon.com* \n\nAnalyzing the image above, we understand that the policy is applied to a bucket resource, the rule for the permission is “Deny”, and the result of the bucket policy is denying access to the objects stored in the specified bucket unless the requests are made with source IPs in the subnet 54.240.143.0/24. \n\n### 4. Data loss prevention \n\nData loss prevention (DLP) is a protection mechanism for sensitive data that ensures that no unintentional or malicious disclosures occur. DLP prevents data breaches by ensuring no confidential data is accidentally leaked, lost, or stolen. \n\n**Amazon Macie** is a data security and privacy service that protects users’ sensitive data using machine learning technologies and pattern matching. \n\nThis tool identifies sensitive data using **sensitive data discovery jobs**, which analyze S3 buckets. Sensitive data discovery jobs use pre-defined or user-defined lists (or a combination of both) to single out confidential data by matching patterns to the lists. \n\nA passport number is an example of sensitive data that Amazon Macie could match. This is because it has a set number of digits, some corresponding to the owner's region or country. \n\nAfter identifying sensitive data, Amazon Macie can: \n\n* use IAM policies to filter traffic to it,  \n* encrypt and decrypt data,  \n* perform logging and monitoring through AWS CloudTrail integration, and others.  \n\n### 5. Availability \n\nAvailability means that users should be able to access their data without disruptions at any point. \n\nA solution for availability in the cloud is **availability zones**. \n\nAn availability zone is a geographical area where groups of data centers are located. These data centers contain replicated data and provide redundancy regarding electrical power, networking, and connectivity. \n\nAn AWS region contains multiple AWS availability zones, all within 100km of each other, which are independent and provide redundancy. \n\nSome AWS regions around the globe are: \n\n* North America,  \n* South America, \n* Europe,  \n* China,  \n* South Africa, and others. \n\nThese regions provide high availability. \n\nAnother solution for availability is DDoS Protection. DDoS (Distributed Denial of Service) attacks are attempts to bring down a service or a resource by sending a large amount of traffic to them using controlled machines. \n\nAWS Shield is the AWS DDoS Protection service that protects applications hosted in the cloud. \n\nAWS Shield has two tiers: \n\n* Standard, \n* Advanced. \n\nBesides the features that come with the Standard plan, which are at network and transport layer, the Advanced tier of AWS Shield provides: \n\n* integration with AWS WAF (Web Application Firewall), \n* real-time visibility into attacks,  \n* additional detection and mitigation of sophisticated DDOS attacks, and others. \n\n## Secure your cloud environment \n\nAfter understanding the security demands required for the cloud, implementing them seems like a daunting task. However, using Cyscale, you can easily check if you’re lacking any of the mentioned implementations and remediate any findings. \n\nCyscale has over 400 controls that cover a large variety of misconfigurations and vulnerabilities and offer support not only for AWS, but for Azure, Google Cloud, Alibaba Cloud as well. \n\n\n\nEnhance your AWS cloud data security with our [Cloud Security Platform](https://cyscale.com/) to automate the contextual analysis of misconfigurations, vulnerabilities, access, and data for an accurate risk assessment. With over 400 controls, we ensure optimal [AWS security compliance](https://cyscale.com/use-cases/aws-cloud-security/).\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"A Guide to Cloud Security Best Practices","seoTitle":"A Guide to Cloud Security Best Practices","description":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","seoDescription":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","date":"2022-09-01T10:59:21.743Z","featuredpost":true,"permalink":"cloud-data-security-guide","featuredimage":{"publicURL":"/static/ede7e98a6093188a6e7edee54d1956fd/21-cover-01-min.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp","srcSet":"/static/ede7e98a6093188a6e7edee54d1956fd/913d0/21-cover-01-min.webp 205w,\n/static/ede7e98a6093188a6e7edee54d1956fd/91660/21-cover-01-min.webp 410w,\n/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"In the ever-evolving landscape of digital security, understanding and implementing a robust **[cloud security strategy](https://cyscale.com/blog/cloud-security-strategy-best-practices-tutorials/)** is crucial. This guide provides insights into best practices that are integral to this strategy.\n\nData security is one of the biggest concerns of cloud-based organizations. When you think about protecting data, you need to make sure you’re providing the following features:\n\n* Confidentiality,\n* Integrity,\n* Availability.\n\nMoreover, these three security principles need to be implemented for all three states of data, which are:\n\n* In motion,\n* In use,\n* At rest.\n\nThis mission may seem daunting. Let’s break it down and understand every step of the process of securing data. In this article, you will find out:\n\n* The type of attacks that threaten your data,\n* Cloud security best practices,\n* Security solutions on the market from cloud service providers,\n* How to identify any gaps in your security policies.\n\n## **How do you ensure confidentiality?**\n\nConfidentiality is a security principle that states that only authorized users should be able to access the data. It should not be visible to unauthorized entities.\n\n### **Encryption**\n\n[Encryption](https://cyscale.com/blog/types-of-encryption/) is the process of scrambling data to obtain unreadable ciphertext. The algorithm uses a key to encrypt it, and if you are not in possession of the decryption key, you cannot reverse it back to its original state.\n\nEncryption solutions for the three states of data are: \n\n* For in motion data: SSL/TLS. They are transport protocols that encrypt data in transit. \n* For in use data: memory encryption, called Secure Encrypted Virtualization (SEV). It requires specialized hardware, and it encrypts RAM memory. \n* [For at rest data:](https://cyscale.com/blog/protecting-data-at-rest/) industry-recommended symmetric algorithms such as AES-256 are used to perform full disk, database, file system, and cloud assets encryption and to safely store data. \n\nUsing these best practices, you can improve your cloud security posture and prevent data breaches or other security incidents.\n\n### **Access control** \n\nA layered approach should be used when securing data in the cloud. This is where a robust **[cloud infrastructure security](https://cyscale.com/blog/cloud-infrastructure-security/)** becomes crucial. This means that encryption of data at rest should only be considered as the last measure of protection if access control rules are bypassed. \n\nYou must secure access to databases, buckets, and other storage assets by restricting it as much as possible. In doing this, you become compliant with the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/). \n\nA few access control best practices for [database protection](https://cyscale.com/blog/best-practices-for-securing-databases/) are:\n\n* Filter inbound and outbound traffic,\n* Secure your database connection,\n* Keep your connection details secret.\n\nFor [buckets that contain sensitive information](https://cyscale.com/blog/common-cloud-misconfigurations-how-to-avoid-them/#storage-access), do not allow public read/write access and use access control lists to define granular rules.\n\nBesides access control, to ensure robust data protection, strong authentication mechanisms should be put in place. Multi-factor authentication (MFA) is a must-have security measure for cloud computing environments.\n\nBy implementing these IAM (Identity and Access Management) best practices, attack surface is reduced and your cloud infrastructure is secured.\n\n### **Data classification**\n\nClassifying data does not protect it on its own. However, this process can help you understand which is the most sensitive data in order to better focus your efforts to secure it.\n\nAWS (Amazon Web Services), Azure, and Google Cloud provide labels or tags for users to implement [data classification](https://cyscale.com/blog/data-classification/). Labels/tags can be predefined by the public cloud vendor or can be user-defined according to the user’s specific needs.\n\n## **How do you ensure integrity?**\n\nEnsuring integrity means that data must not be altered in transit or at rest. Integrity is usually accomplished using hashes and checksums.\n\nThey are computed before the data is used or transferred and then again after. If the two values of hashes/checksums match, then the data was not altered in transit or at rest. Otherwise, that data was tampered with.\n\nLet’s look at public cloud vendors and how they provide data integrity services:\n\n* AWS S3 uses CRC32, CRC32C, SHA-1, and SHA-256 to check the data integrity after uploading/downloading,\n* Google Cloud also uses CRC32C checksums to verify data integrity.\n\n## **How do you ensure availability?**\n\nData availability means that any user should be able at any point to access their data without disruptions.\n\nFor data in the public cloud, vendors provide solutions to replicate and backup it in different data centers and regions.\n\nWe need to look at **availability zones** to understand availability in the cloud.\n\nAvailability zones are groups of data centers in the same region containing replicated data. If a data center fails, the other data center in the availability zone takes the responsibility, providing fault tolerance and increased availability and preventing data loss.\n\nMoreover, public cloud vendors support region pairs. A region is paired with another region at a great distance (for example, at least 300km away for Azure). If a natural disaster, civil unrest, or any other unforeseen events occur, the secondary region becomes the main source of cloud service.\n\nAnother service available in the public cloud that helps ensure availability is **DDOS protection**.\n\nDDOS (Distributed Denial of Service) is an attack designed to crash an application or a service by sending substantial amounts of traffic to it.\n\nA few examples of available DDOS services to secure cloud infrastructure are:\n\n* AWS Shield,\n* Azure DDOS Protection,\n* Google Cloud Armor.\n\n**Implementing our recommendations**\n\nEnsuring [multi-cloud data security](https://cyscale.com/use-cases/cloud-data-security/) is not an easy task. There are many aspects to be considered, and a small mistake can leave a vulnerability in your cloud environment.\n\nCyscale provides powerful dashboards to ensure visibility of your assets, the identities in your cloud, and an overview of your data security.\n\nMoreover, 400+ security controls ensure that your security teams have implemented the cybersecurity principles and best practices. Here are some examples of controls that can be used to ensure data security:\n\n* **In motion data encryption**: *Ensure web app is using the latest version of TLS encryption* for Microsoft Azure\n* **At rest data encryption**: *Ensure VM disks for critical VMs are encrypted with Customer*-Supplied Encryption Keys (CSEK) for Google Cloud\n* **Access control**: *Ensure S3 bucket policy does not grant Allow permission to everyone* for AWS\n* **Data classification**: *Ensure Kubernetes Clusters are configured with Labels* for Google Cloud\n* **DDOS Protection**: *Ensure Anti-DDoS access and security log service is enabled* for Alibaba Cloud\n\nBefore diving into specific controls, it's essential to acknowledge the evolving **[cloud security challenges](https://cyscale.com/blog/cloud-security-challenges/)** that businesses face. With a constantly changing digital landscape, understanding these challenges can help shape your security strategies more effectively."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Best Practices for Securing Databases in the Cloud ","seoTitle":"Best Practices for Securing Databases in the Cloud ","description":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","seoDescription":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","date":"2022-08-26T07:19:11.434Z","featuredpost":true,"permalink":"best-practices-for-securing-databases","featuredimage":{"publicURL":"/static/79c9688bfcbf26210f6ca16250401cb0/20_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp","srcSet":"/static/79c9688bfcbf26210f6ca16250401cb0/913d0/20_blog-cover-photo.webp 205w,\n/static/79c9688bfcbf26210f6ca16250401cb0/91660/20_blog-cover-photo.webp 410w,\n/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nA database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  \n\nWhen we’re discussing databases in the cloud, there are two options for users. They can: \n\n* manage their own database in the cloud, or \n* use a service provided by their cloud vendor. \n\nThe latter is usually the easier choice since the cloud vendor takes care of security features.  \n\nHowever, your database may be vulnerable in both cases if you don’t configure your environment correctly. \n\nIn this article, we will look at best practices for securing databases in the cloud and how to identify any misconfigurations and vulnerabilities that may exist or appear in the future. \n\n## Best practices \n\n### 1. Filter inbound and outbound traffic. \n\nManaging traffic to and from the database is the first layer of database protection. Place databases behind firewalls and restrict the traffic allowed to reach them as much as possible. \n\nYou can implement more granular rules by only allowing a list of known IPs to connect to a database (for example, the range of addresses specific to a known data center), or by filtering traffic based on other criteria. \n\nMoreover, you can apply conditional access for users when administering the database. You can ask for additional security checks like Multi-Factor Authentication to ensure the entities managing the database are legitimate. \n\n### 2. Ensure availability through redundancy \n\nWhen deploying a database in the public cloud, you have the option to ensure availability through redundancy. You can replicate a database in different data centers and even different geographical regions. \n\nIf one data center or region fails, you can rely on a replication of the database located in a different data center to work. \n\n### 3. Encrypt your database \n\nDatabase [encryption](https://cyscale.com/blog/protecting-data-at-rest/) is important for protecting your data at rest.  \n\nEnsure that only authorized entities can see the data you’re storing in the database by [encrypting it ](https://cyscale.com/blog/protecting-data-at-rest/)with a strong, recommended algorithm such as AES-256. Keep your encryption keys safe by storing them separately from the data, use strong generation algorithms and rotate them every 90 days or less. \n\n### 4. Secure your database connection \n\nNot only data at rest is vulnerable. When you're transferring data to and from the database, it is essential to encrypt your traffic.  \n\nThis is called encryption for data in transit and is implemented with the TLS/SSL protocols. \n\n### 5. Keep your connection details secret \n\nDo not disclose database connection strings, keys, certificates, and other secrets that may be used to breach your database. You can use cloud solutions to keep your cryptographic secrets safe: \n\n* [Azure](https://cyscale.com/use-cases/azure-cloud-security/) Key Vault, \n* [AWS ](https://cyscale.com/use-cases/aws-cloud-security/)Key Management Service (AWS KMS), \n* [Google Cloud ](https://cyscale.com/use-cases/gcp-cloud-security/)Secret Manager, \n* dedicated hardware devices such as Hardware Security Modules (HSM), and others. \n\n### 6. Log connection attempts \n\nKeep track of who is trying to connect to your database by logging any authentication attempts. In this way, you can see if: \n\n* someone unauthorized is trying to or is connecting to the database, \n* there is a brute-force attack taking place.  \n\n### 7. Perform regular database backups \n\nDatabases should be backed up regularly, to prevent loss of data, in the case of: \n\n* Data corruption, and \n* Ransomware attacks. \n\nAlthough ransomware attacks are less common in cloud environments at the moment, attackers could in time develop the proper tactics. \n\n![RPO and RTO](/img/20_blog-rpo-and-rto.webp#shadow \"RPO and RTO\")\n\nThe time between the backups is known as RPO (Recovery Point Objective). It is measured as the time that passed between the last backup and the current one. If a disaster appears, the data written in that time is lost. \n\nRTO (Recovery Time Objective) is the time it takes for an application to go back online after a disaster and to restore its data.   \n\nRTO and RPO should be kept in acceptable limits. \n\n \n\nIt is difficult to ensure you’re implementing all the best practices we mentioned in this article. [Cyscale ](https://cyscale.com/)has over 400 controls that can help you secure your entire cloud environment. \n\nHere are some examples of controls that check for any misconfigurations and vulnerabilities regarding your database setup in the public cloud: \n\n* *Ensure encrypted storage is used for VMs that might host a database* for AWS \n* *Ensure no SQL Databases allow ingress 0.0.0.0/0 (ANY IP)* for Microsoft Azure \n* *Ensure that Cloud SQL database instances are configured with automated backups* for Google Cloud \n* *Ensure that Cloud SQL database instances require all incoming connections to use SSL* for Google Cloud \n* *Ensure parameter 'log_connections' is set to 'ON' for PostgreSQL Database* for Alibaba Cloud \n\nAlong with these controls that alert you on any findings, you receive remediation steps to quickly eliminate any vulnerabilities and secure your database in the cloud. \n\n \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Protecting Data at Rest Using Encryption  ","seoTitle":"Protecting Data at Rest Using Encryption  ","description":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.\n\n","seoDescription":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.","date":"2022-08-20T07:06:54.032Z","featuredpost":true,"permalink":"protecting-data-at-rest","featuredimage":{"publicURL":"/static/4c004ae5409e8873ac3b77d3e3668417/19_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp","srcSet":"/static/4c004ae5409e8873ac3b77d3e3668417/913d0/19_blog-cover-photo.webp 205w,\n/static/4c004ae5409e8873ac3b77d3e3668417/91660/19_blog-cover-photo.webp 410w,\n/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nData at rest is data that is not currently used or transmitted between computer systems.  \n\nThis state of data is usually the most sought-for by attackers. Data at rest can be stored in: \n\n* Storage cloud assets such as buckets, \n* Databases, \n* Files, and others. \n\nThe most common method of protecting data at rest is through [encryption](https://cyscale.com/blog/types-of-encryption/). In this article, we will look at ways to perform encryption and understand its importance. \n\n## Why is it important to encrypt data at rest? \n\nThere are three main risks regarding data at rest: \n\n* loss,  \n* leakage,  \n* theft. \n\nIn all three cases, your data at rest will probably end up in somebody’s hands. You can forget your USB drive in a coffee shop, you can accidentally disclose your data to someone else or the public or it can be stolen by a malicious attacker. \n\nFor these reasons, a safeguarding mechanism is encrypting your data. \n\nWith this method, even if someone else gets ahold of your data, they will not be able to read it. \n\n## Client-side and server-side encryption \n\nClient-side encryption is done on a local device with the user's key. \n\nServer-side encryption is implemented in the cloud, and the cloud vendor usually takes care of the key. This method of encryption is easier to use, since the cloud provider takes care of the algorithm, the key management system, and other troubles you may have. \n\nIn this article, we will look at best practices for client-side encryption, as well as solutions offered for server-side encryption.  \n\n## How do you encrypt data at rest? \n\nThere are a few best practices that need to be considered when undergoing the encryption process: \n\n### 1. Use an industry-recommended standard with an appropriate key length. \n\nFor data at rest, symmetric encryption algorithms are usually used. An industry-recommended standard is AES-256 (Advanced Encryption Standard with a key of 256 bits). \n\n### 2. Classify data and decide what to encrypt. \n\nMake sure you don’t leave any sensitive data unencrypted. Use [data classification](https://cyscale.com/blog/data-classification/) to decide what data should be encrypted.  \n\nAlternatively, perform full disk encryption to protect all data, especially in case you lose the hardware. \n\n## Key management \n\nNow that we’ve established how to encrypt data at rest, let’s talk keys.  \n\nIf your key management is poor, no matter how strong and well-done an encryption is, it can become totally useless. \n\nFollow the best practices we’re recommending to ensure textbook key management.  \n\n### 1. Use a random key generation algorithm for your keys.  \n\nMost random number generator algorithms are not truly random; they are called Pseudo-Random Number Generators (PRNGs).  \n\nIf you’re using programmatic functions such as random() or rand() from C++, Java, and other languages, you’re not generating random keys; they use a seed (which always gives the same result), can be predicted, and are not for cryptographic usage. \n\nFor this reason, you need to use tools that utilize Cryptographically Secure Random Number Generators (CSRNGs). \n\nTo generate a random, secure key, you can use: \n\n* [GenerateRandom](https://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateRandom.html), a tool provided by AWS, \n* the [GenerateRandomBytes](https://cloud.google.com/kms/docs/generate-random) API from Google Cloud, \n* [SecureRandom](https://docs.oracle.com/javase/8/docs/api/java/security/SecureRandom.html), a class from Java, and others. \n\n### 2. Store your keys separately from your ciphertext. \n\nDo not store your keys in the same place as encrypted data, and do not hardcode them in the source code. You can use: \n\n* dedicated hardware devices such as Hardware security modules (HSM), \n* key management systems such as Azure Key Vault and AWS KMS, \n* open source KMS such as HashiCorp Vault. \n\n### 3. Rotate the keys. \n\nChange the keys regularly (every 90 days or less). This process involves retiring an encryption key and generating a new one. \n\nMoreover, if a key is compromised, immediately replace it and assess which data is at risk. \n\n### 4. Implement access control for keys \n\nEnsure that access to keys is heavily restricted in the following ways: \n\n* [Implement the Least Privilege Principle.](https://cyscale.com/blog/check-for-least-privilege/) Only the individuals that need the keys should be able to access them. You can also implement time windows when keys can be accessed. \n* Only authorized personnel should be able to access keys. Ensure that, after you’ve granted access rights to people, only they can see and use the keys. \n\n###  5. Manage key deletion \n\nIf a key is permanently deleted, all data encrypted with that key is lost. The key should be appropriately destroyed after all the encrypted data is decrypted and re-encrypted with a new key. \n\nSolutions from cloud vendors for safe key deletion are: \n\n* Soft delete in Azure Key Vault, \n* Key deletion scheduling in AWS. \n\n## Server-side encryption - cloud solutions \n\nAWS, Azure, and Google Cloud provide data at rest encryption and key management solutions. Let's look at the available options and how to make sure you're using them correctly. \n\n### Encryption in AWS \n\nThe following services in AWS support data at rest encryption capabilities: \n\n* Amazon EBS, \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift, \n* AWS Lambda, and many others. \n\nKey management is done using the AWS Key Management Service, which allows users to utilize their own keys or let AWS deal with them. \n\n### Encryption in Azure \n\nIn Microsoft Azure, users have the following options: \n\n* Azure Disk Encryption, for Virtual Machines, \n* Azure Storage and Azure SQL Database, which encrypt all data at rest. \n\nFor key management, Azure provides the following services: \n\n* Azure Key Vault, \n* Vault Managed Hardware Security Model (HSM). \n\n### Encryption in Google Cloud \n\nFor key management, Google Cloud provides the Google Key Management Service. As an additional layer of security, the encryption key, named DEK (Data Encryption Key), is also encrypted using a KEK (Key-encryption key).  \n\n## How do you check for encryption misconfigurations? \n\nAs we’ve seen, there are many best practices to be considered, and therefore there is room for mistakes. \n\nYou can quickly [check for misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/) regarding data at rest encryption in the cloud using Cyscale’s controls. Here are a few examples of controls that check if you’re implementing the best practices described in this article: \n\n* *Ensure all S3 buckets employ encryption-at rest* for AWS \n* *Ensure storage for critical data are encrypted with Customer Managed Key* for Microsoft Azure, \n* *Ensure EBS encryption by default is enabled* for AWS, \n* *Ensure CloudTrail logs are encrypted at rest* for AWS. \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"5 Hybrid Cloud Best Practices ","seoTitle":"5 Hybrid Cloud Best Practices ","description":"A Hybrid Cloud infrastructure contains at least two different environments, which can be on-premises, in the public cloud and in a private cloud. The advantages of a hybrid cloud are improved performance, higher flexibility, increased scalability, and others. Containerized applications in Docker and Kubernetes become portable with this infrastructure. Implement the Least Privilege Principle, use antiviruses and firewalls, monitor your environment, perform audits and backup data to keep a secure hybrid cloud.","seoDescription":"A Hybrid Cloud infrastructure contains at least two different environments, which can be on-premises, in the public cloud and in a private cloud. The advantages of a hybrid cloud are improved performance, higher flexibility, increased scalability, and others. Containerized applications in Docker and Kubernetes become portable with this infrastructure. Implement the Least Privilege Principle, use antiviruses and firewalls, monitor your environment, perform audits and backup data to keep a secure hybrid cloud.","date":"2022-07-29T05:32:05.559Z","featuredpost":true,"permalink":"hybrid-cloud-best-practices","featuredimage":{"publicURL":"/static/dd9fa6fe457aea015d622ef44f1b225a/blog_15-hybrid-cloud-best-practices.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/dd9fa6fe457aea015d622ef44f1b225a/888e2/blog_15-hybrid-cloud-best-practices.webp","srcSet":"/static/dd9fa6fe457aea015d622ef44f1b225a/913d0/blog_15-hybrid-cloud-best-practices.webp 205w,\n/static/dd9fa6fe457aea015d622ef44f1b225a/91660/blog_15-hybrid-cloud-best-practices.webp 410w,\n/static/dd9fa6fe457aea015d622ef44f1b225a/888e2/blog_15-hybrid-cloud-best-practices.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## What does Hybrid Cloud mean? \n\nA Hybrid Cloud infrastructure contains at least two different environments, which can be: \n\n* on-premises computing,  \n* a public cloud service, and  \n* a private cloud. \n\nLet’s look at an example where all three components are interconnected and are used to achieve a company’s business goals: \n\n* the on-premises computers act as web servers,  \n* the public cloud vendor, such as [AWS](https://cyscale.com/use-cases/aws-cloud-security/), [Google Cloud](https://cyscale.com/use-cases/gcp-cloud-security/), or [Azure](https://cyscale.com/use-cases/azure-cloud-security/), hosts a different application integrated with the company’s website, \n* the private cloud contains the users’ database. \n\nAccording to [Statista](https://www.statista.com/topics/7914/hybrid-cloud/), around 80% of enterprises follow a hybrid [cloud strategy](https://cyscale.com/blog/cloud-security-strategy-best-practices-tutorials/) in 2022. \n\n## Advantages and disadvantages of using a hybrid cloud scheme\n\n### Advantages \n\n#### Improved performance \n\nKeeping your resources in different solutions and working under a distributed system can help you increase performance. If you efficiently distribute workloads, you can significantly decrease latency and become more efficient. \n\n#### Higher flexibility \n\nHaving so many technologies integrated into your workflow can help you with flexibility. For example, you can choose where each type of data is stored. \n\nMoreover, by hosting your applications in the cloud using technologies like Docker or Kubernetes, they become **portable** and can be moved across environments. \n\n#### Increased scalability \n\nCompared to on-premises systems, hybrid cloud is more scalable because of its cloud component. \n\nYou can quickly scale up and acquire more resources in the cloud without having to purchase any equipment. \n\n### Disadvantages \n\n#### Increased complexity \n\nDue to increased complexity, it is harder to secure and manage your application’s resources and workloads. Working with at least three different environments (on-premises, private and public cloud) can increase the chance of making mistakes in terms of security (and not only). \n\n#### Higher costs \n\nOne of the public cloud's most significant advantages is that it is usually the cheapest alternative to keeping up servers on-premises. However, hybrid cloud architecture uses both, increasing costs. \n\n## Hybrid Cloud Best Practices \n\nWe’ve composed a list of best practices to tick off when constructing and assessing your hybrid cloud infrastructure. Some of these may be applicable to companies that use cloud environments (and not hybrid ones) as well. \n\n#### 1. Have a robust cloud security posture, secure your on-premises servers, and ensure endpoint security. \n\nIn order to secure an infrastructure that uses hybrid cloud, besides managing your [cloud security posture](https://cyscale.com/blog/improve-cloud-security-posture/), you need to ensure your devices are secured. On-premises devices should: \n\n* be updated regularly, \n* be protected by antiviruses and firewalls. \n\n#### 2. Implement the Least Privilege Principle. \n\nThe Least Privilege Principle states that no user should be given more permissions than required. This practice helps minimize the risk of data breaches or accidental misconfigurations. \n\nMake sure you implement this principle across all platforms and devices.  \n\nTo do this, restrict access to the lowest privilege every user needs and eliminate all root and administrator accounts that are not strictly necessary. \n\n#### 3. Monitor your environment. \n\nMonitoring is essential to detecting any misconfigurations or malicious actions in your company.  \n\nKeep logs of everything that happens in your infrastructure and use targeted alerts to help you respond quickly to the most important events. \n\n#### 4. Perform regular audits and comply with international standards. \n\nIt is important to be compliant with international standards and acquire their accreditations. In this way, you ensure that you: \n\n* manage customer data safely, \n* have a good reputation since you show that you recognize the importance of information security, \n* avoid fines and other financial consequences. \n\nTo achieve compliance, you must implement proper data handling in both on-premises and cloud environments. \n\nInternational standards that define rules and regulations that apply to the hybrid cloud are: \n\n* [PCI-DSS,](https://cyscale.com/blog/pci-dss-compliance-in-cloud/) \n* HIPAA, \n* SOC 2, \n* ISO 27001, and others. \n\n#### 5. Perform backups \n\nSince the on-premises infrastructure is a part of the hybrid cloud, it is essential to perform regular backups.  \n\nPublic cloud vendors provide backup services for your cloud assets. Some solutions are: \n\n* Azure Backup, \n* AWS Backup, \n* Actifio Go, for Google Cloud. \n\nTo back up your on-premises devices, establish a disaster recovery strategy and store backups separately from on-premises equipment. \n\n## How can Cyscale improve your hybrid cloud infrastructure? \n\nUse Cyscale’s policy engine to create policies for your entire infrastructure and effortlessly follow the best practices described in this article. \n\nThe policies you establish can be used for both on-premises and public cloud environments. \n\nMoreover, for your public cloud infrastructure, you can achieve robust security when using Cyscale, by: \n\n* becoming [compliant with international standards](https://cyscale.com/use-cases/cloud-compliance-and-auditing/) with less effort and time, \n* checking your cloud’s configurations and eliminating any vulnerabilities using over 500 controls and policies available across the most important cloud vendors,  \n* receiving targeted alerts that let you locate critical misconfigurations in no time, \n* receiving remediation steps to fix findings. \n\n<!--EndFragment-->"}}]}},"pageContext":{"limit":9,"skip":0,"numPages":2,"currentPage":1,"category":"Cloud Security","seoTitle":"Cyscale - Cloud Security","seoDescription":"News about Cyscale Cloud Security","categoriesList":["Cloud Security","Compliance","News","Product","CSPM","CNAPP","Misconfigurations","IAM"]}},"staticQueryHashes":["220583031","4109069157","632500807","981947644"],"slicesMap":{}}