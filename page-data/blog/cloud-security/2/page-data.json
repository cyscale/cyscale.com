{"componentChunkName":"component---src-template-blog-categories-template-js","path":"/blog/cloud-security/2/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Securing Your Cloud: Essential Tips for Your Business","seoTitle":"Securing Your Cloud: Essential Tips for Your Business","description":"In today's digital landscape, cloud computing has become essential for organizations looking to streamline their operations and enhance their business agility. As the adoption of cloud-native infrastructure continues to grow, so does the need for effective cloud security measures. \n\nThis article will look at a high-level overview of the steps to establish a security plan: performing a risk assessment, conducting an incident response plan, monitoring and evaluating how that plan is working, and making efforts to become compliant with international standards.","seoDescription":"In today's digital landscape, cloud computing has become essential for organizations looking to streamline their operations and enhance their business agility. As the adoption of cloud-native infrastructure continues to grow, so does the need for effective cloud security measures.   This article will look at a high-level overview of the steps to establish a security plan. ","date":"2023-05-18T10:05:42.486Z","featuredpost":true,"permalink":"essential-tips-cloud-security","featuredimage":{"publicURL":"/static/95f19b01b90128761574d03c80bd3223/microsoftteams-image-5-.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/95f19b01b90128761574d03c80bd3223/888e2/microsoftteams-image-5-.webp","srcSet":"/static/95f19b01b90128761574d03c80bd3223/913d0/microsoftteams-image-5-.webp 205w,\n/static/95f19b01b90128761574d03c80bd3223/91660/microsoftteams-image-5-.webp 410w,\n/static/95f19b01b90128761574d03c80bd3223/888e2/microsoftteams-image-5-.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"C﻿loud computing has become crucial for businesses seeking to streamline their operations and boost their company agility in the current digital landscape. Effective cloud security solutions are becoming necessary as cloud-native infrastructure adoption grows.\n\nT﻿his article will look at a high-level overview of the steps needed to establish a security plan.\n\n## 1﻿. Risk assessment\n\nA﻿ successful security plan for cloud security must begin with a thorough risk assessment. The assessment should identify the following:\n\n* a﻿ny potential threats to the company's systems,\n* v﻿ulnerabilities, and\n* r﻿isks associated with the cloud environment.\n\nT﻿he assessment should take into consideration the type of data stored in the cloud, the level of access granted to different users, and the efforts conducted to mitigate risks.\n\n## 2. Compliance frameworks \n\nAnother important component of a successful security plan is compliance frameworks. Compliance requirements can vary by industry and location, and businesses must ensure they follow relevant regulations and standards.  \n\nWell-known and accredited standards include: \n\n* GDPR,  \n* [ISO 27001](https://cyscale.com/blog/new-iso27001-2022-version/),  \n* PCI-DSS, \n* HIPAA, \n* DORA, \n* [SOC 2](https://cyscale.com/blog/soc-2-compliance-in-cloud/), and others. \n\nCompliance frameworks provide guidelines and best practices for securing data and systems in the cloud environment.  \n\nEstablish which standard fits your business. For example, [PCI-DSS](https://cyscale.com/blog/pci-dss-compliance-in-cloud/) (Payment Card Industry Data Security Standard) is a framework related to information security that regulates credit and debit card transactions, while [HIPAA](https://cyscale.com/blog/hipaa-compliance-in-cloud/) (The Health Insurance Portability and Accountability Act of 1996) is a federal law that defines rules regarding medical records and PHI. \n\n## 3. Incident response planning \n\nIncident response planning is also critical to a successful cloud security plan. An incident response plan outlines the steps to be taken in the event of a security breach or other incident. Some of the steps are: \n\n### 1﻿. Determine what caused the incident.\n\nF﻿inding the incident's cause is the first step in incident response. This could entail reviewing security rules and procedures, looking over employees interviews, and reviewing system logs.\n\n### 2﻿. Contain the incident\n\nT﻿he response team should take actions to contain the event after the incident's cause has been found. some actions include:\n\n* i﻿solating affected systems,\n* b﻿locking access to sensitive data, and\n* d﻿isabling compromised user accounts.\n\nT﻿his goal is to prevent the incident from spreading and causing further damage.\n\n### 3﻿. Notify affected parties\n\nT﻿he event must be reported to the affected parties as soon as possible. This may include:\n\n* c﻿ustomers,\n* e﻿mployees,\n* p﻿artners, and\n* r﻿egulatory bodies.\n\nT﻿he notification should contain:\n\n* i﻿nformation about the incident,\n* w﻿hat steps are being take to address it,\n* h﻿ow the incident can affect the stakeholders.\n\nT﻿he response team should also answer any questions that may arise, as well as provide ongoing updates as needed.\n\n### 4﻿. Conduct a root cause analysis\n\nT﻿he response team should carry out a root cause analysis to determine the incident's primary cause after it has been contained. This will aid in avoiding future similar incidents.\n\n### 5. Implement remediation measures\n\nThis may involve: \n\n* updating security policies and procedures,  \n* enhancing security controls, and  \n* providing additional employee training.  \n\nThe goal is to reduce the likelihood of future incidents and protect the organization's assets and reputation. \n\n## 4. Monitor and evaluate your plan \n\nAfter going through the previous stages and ensuring that your company has implemented the necessary best practices, you must monitor the security plan and ensure it works accordingly.  \n\nMoreover, the threat landscape constantly evolves, and businesses must remain vigilant to new threats and vulnerabilities. Therefore, even if you have a good security strategy, remain adaptive and ensure ongoing defense against new threats.  \n\nBusinesses may safeguard their sensitive information and assets, reduce the risk of security events, and ensure the continuity of company operations by adopting a proactive and strategic approach to cloud security.\n\nUpgrade your [cloud security strategy](https://cyscale.com/blog/cloud-security-strategy-best-practices-tutorials/) with our [Cloud Security Platform](https://cyscale.com/), a powerful tool offering comprehensive cloud inventory, advanced risk detection, multi-cloud support, and streamlined compliance processes to strengthen your business's cloud security posture."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Understanding serverless computing: how you can use it and how to secure it ","seoTitle":"Understanding serverless computing: how you can use it and how to secure it ","description":"Serverless computing is a collection of services provided by cloud vendors. It allows users to write and execute code in the cloud without setting up the environment and allocating resources such as VMs beforehand. Benefits include a pay-as-you-go model, granular updates and patches, no server management required, and others. In the industry, you can find serverless computing products like AWS Lambda, AWS Fargate, Cloud Run, Cloud Functions, Azure Serverless. Vulnerabilities may appear in serverless computing due to source code flaws, unpatched or outdates libraries or packages, information disclosure in error messages and many others.","seoDescription":"Serverless computing is a collection of services provided by cloud vendors. It allows users to write and execute code in the cloud without setting up the environment and allocating resources such as VMs beforehand. Benefits include a pay-as-you-go model, granular updates and patches, no server management required, and others. In the industry, you can find serverless computing products like AWS Lambda, AWS Fargate, Cloud Run, Cloud Functions, Azure Serverless. Vulnerabilities may appear in serverless computing due to source code flaws, unpatched or outdates libraries or packages, information disclosure in error messages and many others.","date":"2022-11-17T08:55:54.909Z","featuredpost":true,"permalink":"what-is-serverless-computing","featuredimage":{"publicURL":"/static/12acbeec855dfb4da8a6b0a9110f6ed0/27_blog-serverless-computing.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/12acbeec855dfb4da8a6b0a9110f6ed0/888e2/27_blog-serverless-computing.webp","srcSet":"/static/12acbeec855dfb4da8a6b0a9110f6ed0/913d0/27_blog-serverless-computing.webp 205w,\n/static/12acbeec855dfb4da8a6b0a9110f6ed0/91660/27_blog-serverless-computing.webp 410w,\n/static/12acbeec855dfb4da8a6b0a9110f6ed0/888e2/27_blog-serverless-computing.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## What is serverless computing? \n\nServerless computing is a collection of services provided by cloud vendors. It allows users to write and execute code in the cloud without setting up the environment and allocating resources such as VMs beforehand. \n\nBenefits of serverless computing are: \n\n* **A pay-as-you-go model**, allowing code to only run when needed, \n* **No server management required**, since your code is running in the cloud, and you don't have to deal with the environment settings, \n* **Granular updates and patches** that allow developers to make changes at function-level and quickly deploy new versions, \n* **High reliability applications**, since the code runs on the cloud. \n\n## Services offered by cloud vendors \n\nTo further understand what serverless computing has to offer, we must look at services on the market and their features.  \n\n### 1. AWS Lambda and AWS Fargate \n\n**AWS Lambda** is a compute service that allows users, through functions, to run event-driven code without server provisioning or management. AWS Lambda can be used for: \n\n* File processing, \n* Stream processing, \n* Web and mobile applications, \n* IoT backends, and others. \n\nThe event-driven flows help reduce costs for users and add flexibility. Lambda functions are triggered by events, and customers only pay for the time the code is running.  \n\nMoreover, when creating a Lambda function, you can either start writing a function from scratch, or use sample code such as Amazon’s blueprints or the AWS Serverless Application Repository to implement your desired code. \n\n**AWS Fargate** is a compute engine that provides a serverless solution for application deployment by removing the need for infrastructure management. \n\nAmazon Elastic Kubernetes Service (EKS) is a service that allows Kubernetes instances to run both in the cloud and on-premises. EKS, together with AWS Fargate, produce a serverless solution for containers. \n\nFargate can also be used with Amazon Elastic Container Service (ECS), with no additional changes required for your applications. \n\n### 2. Azure Serverless  \n\nMicrosoft Azure offers a collection of serverless compute solutions. Just like AWS Lambda, Azure Serverless enables its users to deploy code without worrying about the underlying infrastructure.  \n\nSome of the Azure compute services are: \n\n* **Serverless Functions.** Just like AWS Lambda, Azure allows users to write event-driven code in their preferred language. Costs are applied only when the code is being executed, \n* **Serverless Kubernetes.** Azure Kubernetes Service (AKS), together with AKS virtual nodes, provide a serverless solution that reduces the infrastructure management workload of Kubernetes clusters. \n* **Serverless Containerized Microservices.** With this solution, applications are deployed in containers without managing the infrastructure,  \n* **Serverless Application Environments.** Using Azure App Service, web, mobile, and API applications are hosted in a fully managed environment.  \n\nAzure also provides low-code or no-code application development with Power Apps. This feature allows developers to construct applications using drag-and-drop functionalities, connectors, and readily-available solutions for common use cases. \n\n### 3. Cloud Run and Cloud Functions by Google Cloud \n\nThese two solutions offered by Google Cloud provide serverless compute services.  \n\n**Cloud Run** is an application development tool that separates infrastructure management from the code by placing applications in containers. Using Cloud Run, microservices can be deployed without specific configurations. It is highly scalable, and it can scale to zero – this means that if a service has no requests, all containers are removed, reducing costs. It supports the following programming languages: Go, Python, Java, Node.js, Ruby, .NET, as well as others. \n\n**Cloud Functions** is a similar service to AWS Lambda and Azure Serverless. \n\n## Possible vulnerabilities of serverless computing \n\n### 1. Lack of source code security \n\nMany cyber attacks are successful due to poor code security.  \n\nAccording to [OWASP Top 10](https://owasp.org/www-project-top-ten/), one of the most common attacks on web applications in 2022 was SQL Injection. Whether an application is hosted in the cloud or not, user input should always be treated very carefully. \n\nTo correctly handle data received from users, you should sanitize it correctly and use prepared statements. \n\n### 2. Outdated or unpatched libraries, packages, and dependencies \n\nAnother element that affects applications' security is the libraries, packages, technologies, and dependencies used.  \n\nIn 2021, a critical vulnerability was discovered. Log4j, a popular Java framework used for logging messages in applications, introduced a massive flaw: it allowed attackers to execute arbitrary code on the host machine. This vulnerability, CVE-2021-44228, commonly known as Log4Shell, [affected around 3 billion devices](https://www.acaglobal.com/insights/log4shell-vulnerability-what-we-know-and-action-steps-take).   \n\nServerless functions in the cloud were not immune to this attack. The functions written in Java that were using Log4j were vulnerable to Log4Shell. \n\nWhile not having to deal with underlying infrastructure management is an advantage of serverless computing, technologies used by developers still have to be used safely. \n\nHow do you protect your code from such vulnerabilities? \n\n* Only use trusted libraries, \n* Apply updates and patches as they appear, \n* Continuously assess your code, \n* Remove any unnecessary dependencies. \n\n### 3. Monitor your cloud infrastructure \n\nThis measure is a given. Log and monitor what your applications do to identify any odd behavior.  \n\nDocument every event that interacts with your code and see how your applications respond.  \n\n### 4. Integrate cryptography into your code \n\n[Encrypt sensitive data](https://cyscale.com/blog/types-of-encryption/) to ensure confidentiality in your applications’ flow. You should encrypt data in transit using TLS/SSL and at rest data using AES. \n\nMoreover, safely store secrets and keys in Hardware Security Modules (HSM) or in your cloud using services such as: \n\n* Azure Key Vault,  \n* AWS Key Management Service (AWS KMS),  \n* Cloud Key Management Service in Google Cloud. \n\nDo not store keys, connection strings, or passwords in the source code or in plain text. \n\n### 5. Too much information is disclosed in error messages. \n\nWe’ve all encountered verbose error messages. \n\nDevelopers should not disclose information about errors or exceptions to the user. Instead, they should be handled in the code, and the message displayed should offer minimal explanations without revealing why the error occurred. \n\n  \n\nWhile writing code in the cloud and quickly deploying it without infrastructure management is tempting, you should be careful.  \n\nImplement the best practices recommended in this article to address serverless computing vulnerabilities and secure your cloud environment. \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["Cloud Security"],"title":"A Word on Cloud Security","seoTitle":"A Word on Cloud Security","description":"Given all this complexity and the pace at which we are trying to deliver our products, it’s no surprise that breaches still happen. However, we can go fast and build secure systems. It’s not a zero-sum game. You probably have people in your organization that are naturally passionate about security. Give them the responsibility, the training, and the tools. You probably don’t need that many people to do security full-time since the tools are getting increasingly powerful.\n","seoDescription":"Given all this complexity and the pace at which we are trying to deliver our products, it’s no surprise that breaches still happen. However, we can go fast and build secure systems. It’s not a zero-sum game. You probably have people in your organization that are naturally passionate about security. Give them the responsibility, the training, and the tools. You probably don’t need that many people to do security full-time since the tools are getting more and more powerful.","date":"2022-10-25T14:41:49.426Z","featuredpost":true,"permalink":"a-word-on-cloud-security","featuredimage":{"publicURL":"/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/microsoftteams-image-3-.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/888e2/microsoftteams-image-3-.webp","srcSet":"/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/913d0/microsoftteams-image-3-.webp 205w,\n/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/91660/microsoftteams-image-3-.webp 410w,\n/static/e7d0b79299e2f1d5a1d08d2a9f3629a9/888e2/microsoftteams-image-3-.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"## Security is Foundational\n\nWhy care about cloud security? Or about security at all? Let’s zoom out even more and talk about the virtues we, as people, often desire for ourselves and look for in others. These include courage, compassion, generosity, temperance, persistence, and friendliness. As Brian Tracy points out in his excellent book, “No Excuses!: The Power of Self-Discipline”, all these virtues depend on and are guaranteed by one of them: **integrity**. Just like this, our software products have multiple requirements including functional (it must solve specific problems) and non-functional (performance, availability, efficiency, etc.). All these depend on the trust our users have in our systems to keep their data safe; they depend on **security**.\n\nIn theory, the most secure software is the one that doesn’t exist. If you have nothing, there is nothing to worry about. In practice, you will probably want to achieve certain things, to deliver certain features within a reasonable timeframe and budget. Luckily for us, the cloud providers offer a sizeable suite of services that might help us. In the era of data-driven, microservices-based, global-scale systems, we end up using some of them for compute (e.g. EC2, AKS, GKE, Lambda, Cloud Run), storage (S3), business intelligence (Redshift, Power BI), integration (Pub/Sub, Kinesis, API Gateway, SQS, SNS, Azure Service Bus), and so on. AWS even offers a service that lets you make use of their (satellite) ground stations. If you are competing with Elon’s Starlink or you are building a weather forecasting system, you might find it useful\n\n## Great Power, Great Responsibility\n\nNaturally, you must understand how to configure each cloud service you end up using and make them work together. One fundamental concept provided by the cloud is the way you manage access. You have control over both the network (so the service is actually reachable or not) and IAM (whether the clients must have identities and sufficient permissions). On one end of the spectrum, you can leave everything open and hope everyone expects that you have it properly set up. On the other end, you can choose a very restrictive configuration that might slow down your team. This is often known as the tradeoff between security and usability (for your dev team in this case). Over the past few years, the industry started shifting more toward security introducing concepts such as zero trust security and SSO (please make use of it whenever possible; also, it’s a shame that some companies still provide SSO only with their enterprise plans).\n\nClassically, you had a number of VMs (on-premises, VPS), installed and configured UFW, set up SSH access, and sent the SSH keys to your colleagues. Now, you can configure public and **private** (sub)networks, connect your cloud networks to your on-premises networks, deploy load balancers, define firewall rules without ever SSH-ing into the VMs, and assign identities and permissions to the VMs (and any other compute service). If previously your team didn’t interact too much with the infrastructure side, **now the infrastructure is part of the application**.\n\n## Network Access\n\nStarting with configuring the network access, here you have multiple options to control it. Perhaps the simplest concept is making the resources public or private. Your VM might have a vulnerable OS version, but if nothing can reach it and it cannot reach the internet, the risk is considerably lower. Not only can you run most compute and database services in a private network, but you can also configure fully managed services to be accessible through the provider's internal network (without traversing the internet) by leveraging services such as [AWS PrivateLink](https://aws.amazon.com/privatelink/) and [Azure Private Link](https://learn.microsoft.com/en-us/azure/private-link/private-link-overview).\n\nFurthermore, you can (have to) configure firewalls. Here the services vary a bit. Google Cloud calls them [VPC firewall rules](https://cloud.google.com/vpc/docs/firewalls). You define them at the VPC level and can optionally choose to which instances they should apply based on tags (they are not equivalent to AWS/Azure tags. In Google Cloud, the equivalent would be the resource labels) or service accounts (almost every resource can have an identity, which in Google Cloud, is given by service accounts). In AWS, you work with security groups that are assigned to virtual machines. Besides allowing traffic (by default everything is denied) from certain IP addresses or CIDRs, you can also choose based on the security group of the source (please make use of this). You can also achieve this in Azure, but you have to combine two types of resources: network security groups (these are the actual firewalls) and application security groups (you can associate these with the network tags from Google Cloud). In fact, here are the sources you can configure for each provider:\n\n* AWS: CIDRs, IP addresses, security groups, prefix lists (if you want to allow traffic coming only from certain AWS services)\n* Azure: CIDRs, IP addresses, application security groups, service tags (e.g. \\`AzureLoadBalancer\\`, \\`Internet\\`)\n* Google Cloud: CIDRs, IP addresses, network tags (defined on each instance), service accounts\n\nOf course, this is not all. You also have network access control lists (NACLs), firewalls specific to each service (especially managed databases from Azure), NAT gateways, VPC peering, VPNs, virtual appliances, traffic splitting, firewalls that you install on the VMs, and a lot more. All these bring considerable complexity and make it extra difficult to configure the optimal **effective network access**.\n\nAdditionally, while there are tools that check the traffic in real-time, these are often dealing with network paths that you defined and are aware of. There might be paths you did not intend to leave open that an attacker might make us for **lateral movement**.\n\n## IAM Access\n\nNot only can every member of your organization have a user (or multiple) with access to certain parts of your infrastructure, but so does almost every compute resource. Just like you provide John with permission to read data from a bucket, so you assign a role to a VM achieving the same access. The difference is that anything that runs on the VM and everyone who can access it (i.e. SSH into it) now can do everything the VM can do.\n\nFundamentally, this mechanism of assigning roles to resources is excellent. You have clear visibility of the principals (users, resources) that can access a given service, you can grant or revoke access at any moment, and you have a meaningful trail of access logs. The alternative is often based on keys/secrets and is almost impossible to trace properly because anyone that has the key can access the resource (it’s easy to lose track of who has the key) (secret scanners help a bit here but are limited to the resources they run on).\n\nWe just have to understand its implications. If attackers manage to break into a VM and if that VM has high (excessive?) permissions, the attackers will not only be able to access our data, but they will also be able to spin up additional instances (crypto mining?) and delete existing resources (service disruption and data loss).\n\nAgain, here it’s important to understand the effective permissions each resource has. There are multiple factors that contribute to the effective permissions such as the role assigned to the resource, permissions inherited from group memberships or from assignments at a higher level (the VM might be an owner at the subscription level in Azure thus having access to everything in that subscription), and policies configured on the target resources such as [resource policies in AWS](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_identity-vs-resource.html) and [access policies for Azure Key Vaults](https://learn.microsoft.com/en-us/azure/key-vault/general/security-features).\n\nAnother important aspect about effective permissions in the context of data access is encryption, especially encryption with customer-managed keys. For example, if you store data on S3 and encrypt it with a key managed by AWS KMS, you must have access to both the S3 bucket/object and the encryption key from KMS. Managing encryption keys deserves an article on its own.\n\n## The Human Factor\n\nEven if you have pristine infrastructure security, you still must provide access to someone (at least two admins so one doesn’t lock himself out by mistake - aka admin redundancy) to maintain the infrastructure and manage access for everyone else. This is an example of a highly privileged user. This in itself is not a major risk. However, if highly privileged users don’t have strong authentication mechanisms in place (MFA, preferably with strong factors), they can become liabilities. We are all subject to social engineering and phishing attacks.\n\nWhen you find out that an attacker managed to gain access to a highly privileged user, after revoking the sessions and rotating the credentials, you will want to find out the impact. For this, you need to know the systems to which the user has access. This can be quite challenging since the permissions are often spread across multiple systems.\n\nFor example, if you have Okta as the identity provider and AWS for the cloud infrastructure, you have to check both systems and link the results in order to determine what a person actually has access to. In Okta you just provide access to an application, but in AWS that application is often an AWS Organization with multiple accounts.\n\n## Ending Notes\n\nGiven all this complexity and the pace at which we are trying to deliver our products, it’s no surprise that breaches still happen. However, we can go fast and build secure systems. It’s not a zero-sum game. You probably have people in your organization that are naturally passionate about security. Give them the responsibility, the training, and the tools. You probably don’t need that many people to do security full-time since the tools are getting increasingly powerful.\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Cloud Data Security For AWS: An In-Depth Guide","seoTitle":"Cloud Data Security For AWS: An In-Depth Guide ","description":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","seoDescription":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","date":"2022-09-29T06:25:58.261Z","featuredpost":true,"permalink":"cloud-security-for-aws","featuredimage":{"publicURL":"/static/8439e84f30635c75021e87142b3bea7b/24_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp","srcSet":"/static/8439e84f30635c75021e87142b3bea7b/913d0/24_blog-cover-photo.webp 205w,\n/static/8439e84f30635c75021e87142b3bea7b/91660/24_blog-cover-photo.webp 410w,\n/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->  \n\nUnderstanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. \n\nIn this article, you will find a comprehensive guide that will help you understand possible misconfigurations in your AWS cloud infrastructure and how to remediate them.  \n\n## Steps to secure your cloud environment \n\n### 1. Data classification \n\n[Classifying your cloud data](https://cyscale.com/blog/data-classification/) can help you easily sort, retrieve, and prioritize it. This is done using a tag (sometimes called a label), which is applied to cloud storage assets. In this way, that data is placed into one or more categories and can be identified more easily. \n\nBenefits of data classification include: \n\n* Risk management, \n* Compliance,  \n* Security. \n\nIn AWS, tags are key-value pairs that add metadata to your data. \n\nThe AWS documentation recommends using a three-tiered approach, with the following tags: \n\n* Unclassified, \n* Official,  \n* Secret. \n\nHowever, users can tailor data classification to their needs and use their own tags. In addition, **tag policies** can be used to standardize their creation and ensure consistency across all assets. \n\nTo accomplish classification using tags in your AWS environment, you have the following options: \n\n* Using the Amazon console, at resource level, where tags can be added either at creation or after, \n* Programmatically, using the Amazon API, AWS CLI, or AWS SDK. \n\nAccording to the AWS documentation, restrictions regarding tags include: \n\n* There cannot be more than 50 tags per resource, \n* Each tag key must be unique for each resource, \n* The maximum key length is 128 Unicode characters in UTF-8, \n* The maximum value length is 256 Unicode characters in UTF-8. \n\n### 2. Encryption \n\nEncryption is the process of altering data in order to hide its content and ensure confidentiality because entities that do not have the decryption key cannot decrypt the data and, therefore, cannot read its content. \n\nThe two types of encryption mechanisms are: \n\n* **Symmetric encryption**, where the encryption and the decryption key are the same, and \n* **Asymmetric encryption**, where the two keys are different; one is called public key and the other private key. \n\nEncryption can be done in all three states of data: \n\n* [At rest,](https://cyscale.com/blog/protecting-data-at-rest/) \n* In transit, \n* In use. \n\nIn this article, we will discuss data encryption in the first two states, but [a more detailed article](https://cyscale.com/blog/types-of-encryption/) regarding encryption also describes encryption in the last state of data. \n\nFor data in transit, AWS provides the following solution: \n\n1. Encrypt the data using SSL/TLS. TLS (Transport Layer Security) and SSL (Secure Sockets Layer) are transport layer protocols that protect the data in transit. TLS is a newer and improved version of SSL. \n2. Perform client-side encryption. This solution requires the user to encrypt the data before uploading it to the cloud, but it is more difficult since the client has to deal with the encryption process, key management, and other services. \n\nFor data at rest, AWS provides encryption for the following services:  \n\n* Amazon EBS,  \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift,  \n* AWS Lambda, and many others. \n\nAWS uses the 256-bit Advanced Encryption Standard (AES-256) encryption algorithm, an industry-recommended standard and one of the strongest algorithms for symmetric encryption. \n\nKey management is also a very important element of data encryption. If your keys are not stored safely, then no matter how strong the encryption algorithm is, a malicious party may be able to read your data. \n\nA few best practices regarding encryption keys are: \n\n* Do not store your keys in the same place as your data or in the source code, \n* Rotate and retire keys regularly to minimize the impact of a breach, \n* Manage key deletion, \n* Use Cryptographically Secure Random Number Generators (CSRNGs) to generate your keys. \n\nAWS KMS (AWS Key Management System) is a comprehensive solution that helps users deal with all the trouble that comes with cryptographic keys. \n\nAWS KMS helps you: \n\n* Create cryptographic keys, \n* Define policies and control how the keys are used, \n* Audit the keys usage to ensure they are used legitimately. \n\nAccording to AWS, this service can be used: \n\n1. Through the AWS Management Console, \n2. Using the AWS KMS APIs. \n\n### 3. Access control \n\nRegulating access control is an essential step to your [cloud data security](https://cyscale.com/blog/cloud-data-security-guide/) program.  \n\nTo manage access control in AWS, you can use policies, which can be assigned at the following levels: \n\n* Users, \n* Groups of users, \n* Roles, \n* Resources. \n\nPolicies define permissions. To correctly implement them, use the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/) to only allow access rights to the necessary users for the minimum amount of time possible.  \n\nLet’s look at an example where a policy is applied to a resource.  \n\nAn AWS S3 bucket is a type of asset used to store object-like data such as files, databases, and other unstructured data. \n\nA bucket policy contains rules based on which access is allowed or denied and is written in JSON.  \n\n```jsonld\n{\n    \"Version\": \"2012-10-17\",\n    \"Id\": \"S3PolicyId1\",\n    \"Statement\": [\n        {\n            \"Sid\": \"IPAllow\",\n            \"Effect\": \"Deny\",\n            \"Principal\": \"*\",\n            \"Action\": \"s3:*\",\n            \"Resource\": [\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET\",\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET/*\"\n            ],\n            \"Condition\": {\n                \"NotIpAddress\": {\n                    \"aws:SourceIp\": \"54.240.143.0/24\"\n                }\n            }\n        }\n    ]\n}\n```\n\n*Policy source – docs.aws.amazon.com* \n\nAnalyzing the image above, we understand that the policy is applied to a bucket resource, the rule for the permission is “Deny”, and the result of the bucket policy is denying access to the objects stored in the specified bucket unless the requests are made with source IPs in the subnet 54.240.143.0/24. \n\n### 4. Data loss prevention \n\nData loss prevention (DLP) is a protection mechanism for sensitive data that ensures that no unintentional or malicious disclosures occur. DLP prevents data breaches by ensuring no confidential data is accidentally leaked, lost, or stolen. \n\n**Amazon Macie** is a data security and privacy service that protects users’ sensitive data using machine learning technologies and pattern matching. \n\nThis tool identifies sensitive data using **sensitive data discovery jobs**, which analyze S3 buckets. Sensitive data discovery jobs use pre-defined or user-defined lists (or a combination of both) to single out confidential data by matching patterns to the lists. \n\nA passport number is an example of sensitive data that Amazon Macie could match. This is because it has a set number of digits, some corresponding to the owner's region or country. \n\nAfter identifying sensitive data, Amazon Macie can: \n\n* use IAM policies to filter traffic to it,  \n* encrypt and decrypt data,  \n* perform logging and monitoring through AWS CloudTrail integration, and others.  \n\n### 5. Availability \n\nAvailability means that users should be able to access their data without disruptions at any point. \n\nA solution for availability in the cloud is **availability zones**. \n\nAn availability zone is a geographical area where groups of data centers are located. These data centers contain replicated data and provide redundancy regarding electrical power, networking, and connectivity. \n\nAn AWS region contains multiple AWS availability zones, all within 100km of each other, which are independent and provide redundancy. \n\nSome AWS regions around the globe are: \n\n* North America,  \n* South America, \n* Europe,  \n* China,  \n* South Africa, and others. \n\nThese regions provide high availability. \n\nAnother solution for availability is DDoS Protection. DDoS (Distributed Denial of Service) attacks are attempts to bring down a service or a resource by sending a large amount of traffic to them using controlled machines. \n\nAWS Shield is the AWS DDoS Protection service that protects applications hosted in the cloud. \n\nAWS Shield has two tiers: \n\n* Standard, \n* Advanced. \n\nBesides the features that come with the Standard plan, which are at network and transport layer, the Advanced tier of AWS Shield provides: \n\n* integration with AWS WAF (Web Application Firewall), \n* real-time visibility into attacks,  \n* additional detection and mitigation of sophisticated DDOS attacks, and others. \n\n## Secure your cloud environment \n\nAfter understanding the security demands required for the cloud, implementing them seems like a daunting task. However, using Cyscale, you can easily check if you’re lacking any of the mentioned implementations and remediate any findings. \n\nCyscale has over 400 controls that cover a large variety of misconfigurations and vulnerabilities and offer support not only for AWS, but for Azure, Google Cloud, Alibaba Cloud as well. \n\n\n\nEnhance your AWS cloud data security with our [Cloud Security Platform](https://cyscale.com/) to automate the contextual analysis of misconfigurations, vulnerabilities, access, and data for an accurate risk assessment. With over 400 controls, we ensure optimal [AWS security compliance](https://cyscale.com/use-cases/aws-cloud-security/).\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"A Guide to Cloud Security Best Practices","seoTitle":"A Guide to Cloud Security Best Practices","description":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","seoDescription":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","date":"2022-09-01T10:59:21.743Z","featuredpost":true,"permalink":"cloud-data-security-guide","featuredimage":{"publicURL":"/static/ede7e98a6093188a6e7edee54d1956fd/21-cover-01-min.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp","srcSet":"/static/ede7e98a6093188a6e7edee54d1956fd/913d0/21-cover-01-min.webp 205w,\n/static/ede7e98a6093188a6e7edee54d1956fd/91660/21-cover-01-min.webp 410w,\n/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"In the ever-evolving landscape of digital security, understanding and implementing a robust **[cloud security strategy](https://cyscale.com/blog/cloud-security-strategy-best-practices-tutorials/)** is crucial. This guide provides insights into best practices that are integral to this strategy.\n\nData security is one of the biggest concerns of cloud-based organizations. When you think about protecting data, you need to make sure you’re providing the following features:\n\n* Confidentiality,\n* Integrity,\n* Availability.\n\nMoreover, these three security principles need to be implemented for all three states of data, which are:\n\n* In motion,\n* In use,\n* At rest.\n\nThis mission may seem daunting. Let’s break it down and understand every step of the process of securing data. In this article, you will find out:\n\n* The type of attacks that threaten your data,\n* Cloud security best practices,\n* Security solutions on the market from cloud service providers,\n* How to identify any gaps in your security policies.\n\n## **How do you ensure confidentiality?**\n\nConfidentiality is a security principle that states that only authorized users should be able to access the data. It should not be visible to unauthorized entities.\n\n### **Encryption**\n\n[Encryption](https://cyscale.com/blog/types-of-encryption/) is the process of scrambling data to obtain unreadable ciphertext. The algorithm uses a key to encrypt it, and if you are not in possession of the decryption key, you cannot reverse it back to its original state.\n\nEncryption solutions for the three states of data are: \n\n* For in motion data: SSL/TLS. They are transport protocols that encrypt data in transit. \n* For in use data: memory encryption, called Secure Encrypted Virtualization (SEV). It requires specialized hardware, and it encrypts RAM memory. \n* [For at rest data:](https://cyscale.com/blog/protecting-data-at-rest/) industry-recommended symmetric algorithms such as AES-256 are used to perform full disk, database, file system, and cloud assets encryption and to safely store data. \n\nUsing these best practices, you can improve your cloud security posture and prevent data breaches or other security incidents.\n\n### **Access control** \n\nA layered approach should be used when securing data in the cloud. This is where a robust **[cloud infrastructure security](https://cyscale.com/blog/cloud-infrastructure-security/)** becomes crucial. This means that encryption of data at rest should only be considered as the last measure of protection if access control rules are bypassed. \n\nYou must secure access to databases, buckets, and other storage assets by restricting it as much as possible. In doing this, you become compliant with the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/). \n\nA few access control best practices for [database protection](https://cyscale.com/blog/best-practices-for-securing-databases/) are:\n\n* Filter inbound and outbound traffic,\n* Secure your database connection,\n* Keep your connection details secret.\n\nFor [buckets that contain sensitive information](https://cyscale.com/blog/common-cloud-misconfigurations-how-to-avoid-them/#storage-access), do not allow public read/write access and use access control lists to define granular rules.\n\nBesides access control, to ensure robust data protection, strong authentication mechanisms should be put in place. Multi-factor authentication (MFA) is a must-have security measure for cloud computing environments.\n\nBy implementing these IAM (Identity and Access Management) best practices, attack surface is reduced and your cloud infrastructure is secured.\n\n### **Data classification**\n\nClassifying data does not protect it on its own. However, this process can help you understand which is the most sensitive data in order to better focus your efforts to secure it.\n\nAWS (Amazon Web Services), Azure, and Google Cloud provide labels or tags for users to implement [data classification](https://cyscale.com/blog/data-classification/). Labels/tags can be predefined by the public cloud vendor or can be user-defined according to the user’s specific needs.\n\n## **How do you ensure integrity?**\n\nEnsuring integrity means that data must not be altered in transit or at rest. Integrity is usually accomplished using hashes and checksums.\n\nThey are computed before the data is used or transferred and then again after. If the two values of hashes/checksums match, then the data was not altered in transit or at rest. Otherwise, that data was tampered with.\n\nLet’s look at public cloud vendors and how they provide data integrity services:\n\n* AWS S3 uses CRC32, CRC32C, SHA-1, and SHA-256 to check the data integrity after uploading/downloading,\n* Google Cloud also uses CRC32C checksums to verify data integrity.\n\n## **How do you ensure availability?**\n\nData availability means that any user should be able at any point to access their data without disruptions.\n\nFor data in the public cloud, vendors provide solutions to replicate and backup it in different data centers and regions.\n\nWe need to look at **availability zones** to understand availability in the cloud.\n\nAvailability zones are groups of data centers in the same region containing replicated data. If a data center fails, the other data center in the availability zone takes the responsibility, providing fault tolerance and increased availability and preventing data loss.\n\nMoreover, public cloud vendors support region pairs. A region is paired with another region at a great distance (for example, at least 300km away for Azure). If a natural disaster, civil unrest, or any other unforeseen events occur, the secondary region becomes the main source of cloud service.\n\nAnother service available in the public cloud that helps ensure availability is **DDOS protection**.\n\nDDOS (Distributed Denial of Service) is an attack designed to crash an application or a service by sending substantial amounts of traffic to it.\n\nA few examples of available DDOS services to secure cloud infrastructure are:\n\n* AWS Shield,\n* Azure DDOS Protection,\n* Google Cloud Armor.\n\n**Implementing our recommendations**\n\nEnsuring [multi-cloud data security](https://cyscale.com/use-cases/cloud-data-security/) is not an easy task. There are many aspects to be considered, and a small mistake can leave a vulnerability in your cloud environment.\n\nCyscale provides powerful dashboards to ensure visibility of your assets, the identities in your cloud, and an overview of your data security.\n\nMoreover, 400+ security controls ensure that your security teams have implemented the cybersecurity principles and best practices. Here are some examples of controls that can be used to ensure data security:\n\n* **In motion data encryption**: *Ensure web app is using the latest version of TLS encryption* for Microsoft Azure\n* **At rest data encryption**: *Ensure VM disks for critical VMs are encrypted with Customer*-Supplied Encryption Keys (CSEK) for Google Cloud\n* **Access control**: *Ensure S3 bucket policy does not grant Allow permission to everyone* for AWS\n* **Data classification**: *Ensure Kubernetes Clusters are configured with Labels* for Google Cloud\n* **DDOS Protection**: *Ensure Anti-DDoS access and security log service is enabled* for Alibaba Cloud\n\nBefore diving into specific controls, it's essential to acknowledge the evolving **[cloud security challenges](https://cyscale.com/blog/cloud-security-challenges/)** that businesses face. With a constantly changing digital landscape, understanding these challenges can help shape your security strategies more effectively."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Best Practices for Securing Databases in the Cloud ","seoTitle":"Best Practices for Securing Databases in the Cloud ","description":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","seoDescription":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","date":"2022-08-26T07:19:11.434Z","featuredpost":true,"permalink":"best-practices-for-securing-databases","featuredimage":{"publicURL":"/static/79c9688bfcbf26210f6ca16250401cb0/20_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp","srcSet":"/static/79c9688bfcbf26210f6ca16250401cb0/913d0/20_blog-cover-photo.webp 205w,\n/static/79c9688bfcbf26210f6ca16250401cb0/91660/20_blog-cover-photo.webp 410w,\n/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nA database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  \n\nWhen we’re discussing databases in the cloud, there are two options for users. They can: \n\n* manage their own database in the cloud, or \n* use a service provided by their cloud vendor. \n\nThe latter is usually the easier choice since the cloud vendor takes care of security features.  \n\nHowever, your database may be vulnerable in both cases if you don’t configure your environment correctly. \n\nIn this article, we will look at best practices for securing databases in the cloud and how to identify any misconfigurations and vulnerabilities that may exist or appear in the future. \n\n## Best practices \n\n### 1. Filter inbound and outbound traffic. \n\nManaging traffic to and from the database is the first layer of database protection. Place databases behind firewalls and restrict the traffic allowed to reach them as much as possible. \n\nYou can implement more granular rules by only allowing a list of known IPs to connect to a database (for example, the range of addresses specific to a known data center), or by filtering traffic based on other criteria. \n\nMoreover, you can apply conditional access for users when administering the database. You can ask for additional security checks like Multi-Factor Authentication to ensure the entities managing the database are legitimate. \n\n### 2. Ensure availability through redundancy \n\nWhen deploying a database in the public cloud, you have the option to ensure availability through redundancy. You can replicate a database in different data centers and even different geographical regions. \n\nIf one data center or region fails, you can rely on a replication of the database located in a different data center to work. \n\n### 3. Encrypt your database \n\nDatabase [encryption](https://cyscale.com/blog/protecting-data-at-rest/) is important for protecting your data at rest.  \n\nEnsure that only authorized entities can see the data you’re storing in the database by [encrypting it ](https://cyscale.com/blog/protecting-data-at-rest/)with a strong, recommended algorithm such as AES-256. Keep your encryption keys safe by storing them separately from the data, use strong generation algorithms and rotate them every 90 days or less. \n\n### 4. Secure your database connection \n\nNot only data at rest is vulnerable. When you're transferring data to and from the database, it is essential to encrypt your traffic.  \n\nThis is called encryption for data in transit and is implemented with the TLS/SSL protocols. \n\n### 5. Keep your connection details secret \n\nDo not disclose database connection strings, keys, certificates, and other secrets that may be used to breach your database. You can use cloud solutions to keep your cryptographic secrets safe: \n\n* [Azure](https://cyscale.com/use-cases/azure-cloud-security/) Key Vault, \n* [AWS ](https://cyscale.com/use-cases/aws-cloud-security/)Key Management Service (AWS KMS), \n* [Google Cloud ](https://cyscale.com/use-cases/gcp-cloud-security/)Secret Manager, \n* dedicated hardware devices such as Hardware Security Modules (HSM), and others. \n\n### 6. Log connection attempts \n\nKeep track of who is trying to connect to your database by logging any authentication attempts. In this way, you can see if: \n\n* someone unauthorized is trying to or is connecting to the database, \n* there is a brute-force attack taking place.  \n\n### 7. Perform regular database backups \n\nDatabases should be backed up regularly, to prevent loss of data, in the case of: \n\n* Data corruption, and \n* Ransomware attacks. \n\nAlthough ransomware attacks are less common in cloud environments at the moment, attackers could in time develop the proper tactics. \n\n![RPO and RTO](/img/20_blog-rpo-and-rto.webp#shadow \"RPO and RTO\")\n\nThe time between the backups is known as RPO (Recovery Point Objective). It is measured as the time that passed between the last backup and the current one. If a disaster appears, the data written in that time is lost. \n\nRTO (Recovery Time Objective) is the time it takes for an application to go back online after a disaster and to restore its data.   \n\nRTO and RPO should be kept in acceptable limits. \n\n \n\nIt is difficult to ensure you’re implementing all the best practices we mentioned in this article. [Cyscale ](https://cyscale.com/)has over 400 controls that can help you secure your entire cloud environment. \n\nHere are some examples of controls that check for any misconfigurations and vulnerabilities regarding your database setup in the public cloud: \n\n* *Ensure encrypted storage is used for VMs that might host a database* for AWS \n* *Ensure no SQL Databases allow ingress 0.0.0.0/0 (ANY IP)* for Microsoft Azure \n* *Ensure that Cloud SQL database instances are configured with automated backups* for Google Cloud \n* *Ensure that Cloud SQL database instances require all incoming connections to use SSL* for Google Cloud \n* *Ensure parameter 'log_connections' is set to 'ON' for PostgreSQL Database* for Alibaba Cloud \n\nAlong with these controls that alert you on any findings, you receive remediation steps to quickly eliminate any vulnerabilities and secure your database in the cloud. \n\n \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"Protecting Data at Rest Using Encryption  ","seoTitle":"Protecting Data at Rest Using Encryption  ","description":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.\n\n","seoDescription":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.","date":"2022-08-20T07:06:54.032Z","featuredpost":true,"permalink":"protecting-data-at-rest","featuredimage":{"publicURL":"/static/4c004ae5409e8873ac3b77d3e3668417/19_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp","srcSet":"/static/4c004ae5409e8873ac3b77d3e3668417/913d0/19_blog-cover-photo.webp 205w,\n/static/4c004ae5409e8873ac3b77d3e3668417/91660/19_blog-cover-photo.webp 410w,\n/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nData at rest is data that is not currently used or transmitted between computer systems.  \n\nThis state of data is usually the most sought-for by attackers. Data at rest can be stored in: \n\n* Storage cloud assets such as buckets, \n* Databases, \n* Files, and others. \n\nThe most common method of protecting data at rest is through [encryption](https://cyscale.com/blog/types-of-encryption/). In this article, we will look at ways to perform encryption and understand its importance. \n\n## Why is it important to encrypt data at rest? \n\nThere are three main risks regarding data at rest: \n\n* loss,  \n* leakage,  \n* theft. \n\nIn all three cases, your data at rest will probably end up in somebody’s hands. You can forget your USB drive in a coffee shop, you can accidentally disclose your data to someone else or the public or it can be stolen by a malicious attacker. \n\nFor these reasons, a safeguarding mechanism is encrypting your data. \n\nWith this method, even if someone else gets ahold of your data, they will not be able to read it. \n\n## Client-side and server-side encryption \n\nClient-side encryption is done on a local device with the user's key. \n\nServer-side encryption is implemented in the cloud, and the cloud vendor usually takes care of the key. This method of encryption is easier to use, since the cloud provider takes care of the algorithm, the key management system, and other troubles you may have. \n\nIn this article, we will look at best practices for client-side encryption, as well as solutions offered for server-side encryption.  \n\n## How do you encrypt data at rest? \n\nThere are a few best practices that need to be considered when undergoing the encryption process: \n\n### 1. Use an industry-recommended standard with an appropriate key length. \n\nFor data at rest, symmetric encryption algorithms are usually used. An industry-recommended standard is AES-256 (Advanced Encryption Standard with a key of 256 bits). \n\n### 2. Classify data and decide what to encrypt. \n\nMake sure you don’t leave any sensitive data unencrypted. Use [data classification](https://cyscale.com/blog/data-classification/) to decide what data should be encrypted.  \n\nAlternatively, perform full disk encryption to protect all data, especially in case you lose the hardware. \n\n## Key management \n\nNow that we’ve established how to encrypt data at rest, let’s talk keys.  \n\nIf your key management is poor, no matter how strong and well-done an encryption is, it can become totally useless. \n\nFollow the best practices we’re recommending to ensure textbook key management.  \n\n### 1. Use a random key generation algorithm for your keys.  \n\nMost random number generator algorithms are not truly random; they are called Pseudo-Random Number Generators (PRNGs).  \n\nIf you’re using programmatic functions such as random() or rand() from C++, Java, and other languages, you’re not generating random keys; they use a seed (which always gives the same result), can be predicted, and are not for cryptographic usage. \n\nFor this reason, you need to use tools that utilize Cryptographically Secure Random Number Generators (CSRNGs). \n\nTo generate a random, secure key, you can use: \n\n* [GenerateRandom](https://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateRandom.html), a tool provided by AWS, \n* the [GenerateRandomBytes](https://cloud.google.com/kms/docs/generate-random) API from Google Cloud, \n* [SecureRandom](https://docs.oracle.com/javase/8/docs/api/java/security/SecureRandom.html), a class from Java, and others. \n\n### 2. Store your keys separately from your ciphertext. \n\nDo not store your keys in the same place as encrypted data, and do not hardcode them in the source code. You can use: \n\n* dedicated hardware devices such as Hardware security modules (HSM), \n* key management systems such as Azure Key Vault and AWS KMS, \n* open source KMS such as HashiCorp Vault. \n\n### 3. Rotate the keys. \n\nChange the keys regularly (every 90 days or less). This process involves retiring an encryption key and generating a new one. \n\nMoreover, if a key is compromised, immediately replace it and assess which data is at risk. \n\n### 4. Implement access control for keys \n\nEnsure that access to keys is heavily restricted in the following ways: \n\n* [Implement the Least Privilege Principle.](https://cyscale.com/blog/check-for-least-privilege/) Only the individuals that need the keys should be able to access them. You can also implement time windows when keys can be accessed. \n* Only authorized personnel should be able to access keys. Ensure that, after you’ve granted access rights to people, only they can see and use the keys. \n\n###  5. Manage key deletion \n\nIf a key is permanently deleted, all data encrypted with that key is lost. The key should be appropriately destroyed after all the encrypted data is decrypted and re-encrypted with a new key. \n\nSolutions from cloud vendors for safe key deletion are: \n\n* Soft delete in Azure Key Vault, \n* Key deletion scheduling in AWS. \n\n## Server-side encryption - cloud solutions \n\nAWS, Azure, and Google Cloud provide data at rest encryption and key management solutions. Let's look at the available options and how to make sure you're using them correctly. \n\n### Encryption in AWS \n\nThe following services in AWS support data at rest encryption capabilities: \n\n* Amazon EBS, \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift, \n* AWS Lambda, and many others. \n\nKey management is done using the AWS Key Management Service, which allows users to utilize their own keys or let AWS deal with them. \n\n### Encryption in Azure \n\nIn Microsoft Azure, users have the following options: \n\n* Azure Disk Encryption, for Virtual Machines, \n* Azure Storage and Azure SQL Database, which encrypt all data at rest. \n\nFor key management, Azure provides the following services: \n\n* Azure Key Vault, \n* Vault Managed Hardware Security Model (HSM). \n\n### Encryption in Google Cloud \n\nFor key management, Google Cloud provides the Google Key Management Service. As an additional layer of security, the encryption key, named DEK (Data Encryption Key), is also encrypted using a KEK (Key-encryption key).  \n\n## How do you check for encryption misconfigurations? \n\nAs we’ve seen, there are many best practices to be considered, and therefore there is room for mistakes. \n\nYou can quickly [check for misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/) regarding data at rest encryption in the cloud using Cyscale’s controls. Here are a few examples of controls that check if you’re implementing the best practices described in this article: \n\n* *Ensure all S3 buckets employ encryption-at rest* for AWS \n* *Ensure storage for critical data are encrypted with Customer Managed Key* for Microsoft Azure, \n* *Ensure EBS encryption by default is enabled* for AWS, \n* *Ensure CloudTrail logs are encrypted at rest* for AWS. \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"5 Hybrid Cloud Best Practices ","seoTitle":"5 Hybrid Cloud Best Practices ","description":"A Hybrid Cloud infrastructure contains at least two different environments, which can be on-premises, in the public cloud and in a private cloud. The advantages of a hybrid cloud are improved performance, higher flexibility, increased scalability, and others. Containerized applications in Docker and Kubernetes become portable with this infrastructure. Implement the Least Privilege Principle, use antiviruses and firewalls, monitor your environment, perform audits and backup data to keep a secure hybrid cloud.","seoDescription":"A Hybrid Cloud infrastructure contains at least two different environments, which can be on-premises, in the public cloud and in a private cloud. The advantages of a hybrid cloud are improved performance, higher flexibility, increased scalability, and others. Containerized applications in Docker and Kubernetes become portable with this infrastructure. Implement the Least Privilege Principle, use antiviruses and firewalls, monitor your environment, perform audits and backup data to keep a secure hybrid cloud.","date":"2022-07-29T05:32:05.559Z","featuredpost":true,"permalink":"hybrid-cloud-best-practices","featuredimage":{"publicURL":"/static/dd9fa6fe457aea015d622ef44f1b225a/blog_15-hybrid-cloud-best-practices.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/dd9fa6fe457aea015d622ef44f1b225a/888e2/blog_15-hybrid-cloud-best-practices.webp","srcSet":"/static/dd9fa6fe457aea015d622ef44f1b225a/913d0/blog_15-hybrid-cloud-best-practices.webp 205w,\n/static/dd9fa6fe457aea015d622ef44f1b225a/91660/blog_15-hybrid-cloud-best-practices.webp 410w,\n/static/dd9fa6fe457aea015d622ef44f1b225a/888e2/blog_15-hybrid-cloud-best-practices.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## What does Hybrid Cloud mean? \n\nA Hybrid Cloud infrastructure contains at least two different environments, which can be: \n\n* on-premises computing,  \n* a public cloud service, and  \n* a private cloud. \n\nLet’s look at an example where all three components are interconnected and are used to achieve a company’s business goals: \n\n* the on-premises computers act as web servers,  \n* the public cloud vendor, such as [AWS](https://cyscale.com/use-cases/aws-cloud-security/), [Google Cloud](https://cyscale.com/use-cases/gcp-cloud-security/), or [Azure](https://cyscale.com/use-cases/azure-cloud-security/), hosts a different application integrated with the company’s website, \n* the private cloud contains the users’ database. \n\nAccording to [Statista](https://www.statista.com/topics/7914/hybrid-cloud/), around 80% of enterprises follow a hybrid [cloud strategy](https://cyscale.com/blog/cloud-security-strategy-best-practices-tutorials/) in 2022. \n\n## Advantages and disadvantages of using a hybrid cloud scheme\n\n### Advantages \n\n#### Improved performance \n\nKeeping your resources in different solutions and working under a distributed system can help you increase performance. If you efficiently distribute workloads, you can significantly decrease latency and become more efficient. \n\n#### Higher flexibility \n\nHaving so many technologies integrated into your workflow can help you with flexibility. For example, you can choose where each type of data is stored. \n\nMoreover, by hosting your applications in the cloud using technologies like Docker or Kubernetes, they become **portable** and can be moved across environments. \n\n#### Increased scalability \n\nCompared to on-premises systems, hybrid cloud is more scalable because of its cloud component. \n\nYou can quickly scale up and acquire more resources in the cloud without having to purchase any equipment. \n\n### Disadvantages \n\n#### Increased complexity \n\nDue to increased complexity, it is harder to secure and manage your application’s resources and workloads. Working with at least three different environments (on-premises, private and public cloud) can increase the chance of making mistakes in terms of security (and not only). \n\n#### Higher costs \n\nOne of the public cloud's most significant advantages is that it is usually the cheapest alternative to keeping up servers on-premises. However, hybrid cloud architecture uses both, increasing costs. \n\n## Hybrid Cloud Best Practices \n\nWe’ve composed a list of best practices to tick off when constructing and assessing your hybrid cloud infrastructure. Some of these may be applicable to companies that use cloud environments (and not hybrid ones) as well. \n\n#### 1. Have a robust cloud security posture, secure your on-premises servers, and ensure endpoint security. \n\nIn order to secure an infrastructure that uses hybrid cloud, besides managing your [cloud security posture](https://cyscale.com/blog/improve-cloud-security-posture/), you need to ensure your devices are secured. On-premises devices should: \n\n* be updated regularly, \n* be protected by antiviruses and firewalls. \n\n#### 2. Implement the Least Privilege Principle. \n\nThe Least Privilege Principle states that no user should be given more permissions than required. This practice helps minimize the risk of data breaches or accidental misconfigurations. \n\nMake sure you implement this principle across all platforms and devices.  \n\nTo do this, restrict access to the lowest privilege every user needs and eliminate all root and administrator accounts that are not strictly necessary. \n\n#### 3. Monitor your environment. \n\nMonitoring is essential to detecting any misconfigurations or malicious actions in your company.  \n\nKeep logs of everything that happens in your infrastructure and use targeted alerts to help you respond quickly to the most important events. \n\n#### 4. Perform regular audits and comply with international standards. \n\nIt is important to be compliant with international standards and acquire their accreditations. In this way, you ensure that you: \n\n* manage customer data safely, \n* have a good reputation since you show that you recognize the importance of information security, \n* avoid fines and other financial consequences. \n\nTo achieve compliance, you must implement proper data handling in both on-premises and cloud environments. \n\nInternational standards that define rules and regulations that apply to the hybrid cloud are: \n\n* [PCI-DSS,](https://cyscale.com/blog/pci-dss-compliance-in-cloud/) \n* HIPAA, \n* SOC 2, \n* ISO 27001, and others. \n\n#### 5. Perform backups \n\nSince the on-premises infrastructure is a part of the hybrid cloud, it is essential to perform regular backups.  \n\nPublic cloud vendors provide backup services for your cloud assets. Some solutions are: \n\n* Azure Backup, \n* AWS Backup, \n* Actifio Go, for Google Cloud. \n\nTo back up your on-premises devices, establish a disaster recovery strategy and store backups separately from on-premises equipment. \n\n## How can Cyscale improve your hybrid cloud infrastructure? \n\nUse Cyscale’s policy engine to create policies for your entire infrastructure and effortlessly follow the best practices described in this article. \n\nThe policies you establish can be used for both on-premises and public cloud environments. \n\nMoreover, for your public cloud infrastructure, you can achieve robust security when using Cyscale, by: \n\n* becoming [compliant with international standards](https://cyscale.com/use-cases/cloud-compliance-and-auditing/) with less effort and time, \n* checking your cloud’s configurations and eliminating any vulnerabilities using over 500 controls and policies available across the most important cloud vendors,  \n* receiving targeted alerts that let you locate critical misconfigurations in no time, \n* receiving remediation steps to fix findings. \n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Cloud Security"],"title":"What Is Data Classification And Why Is It Important?","seoTitle":"What Is Data Classification And Why Is It Important?","description":"Data classification is a way of grouping data to ensure easy sorting, retrieval, and prioritization. The data is divided into categories, and a label, or a tag, is applied to make it easily searchable. Three types of data classification are content-based, context-based and user-based. The benefits of data classification are: risk management, compliance with international standards, security through confidentiality, integrity, availability. Use Cyscale to easily filter assets using their tags and labels.\n\n","seoDescription":"Data classification is a way of grouping data to ensure easy sorting, retrieval, and prioritization. The data is divided into categories, and a label, or a tag, is applied to make it easily searchable. Three types of data classification are content-based, context-based and user-based. The benefits of data classification are: risk management, compliance with international standards, security through confidentiality, integrity, availability. Use Cyscale to easily filter assets using their tags and labels.","date":"2022-07-21T09:32:21.283Z","featuredpost":true,"permalink":"data-classification","featuredimage":{"publicURL":"/static/a2d7192e5cdb371b52a02a98d30eebe3/blog_14-data-classification.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/a2d7192e5cdb371b52a02a98d30eebe3/888e2/blog_14-data-classification.webp","srcSet":"/static/a2d7192e5cdb371b52a02a98d30eebe3/913d0/blog_14-data-classification.webp 205w,\n/static/a2d7192e5cdb371b52a02a98d30eebe3/91660/blog_14-data-classification.webp 410w,\n/static/a2d7192e5cdb371b52a02a98d30eebe3/888e2/blog_14-data-classification.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## What is data classification? \n\nData classification is a way of grouping data to ensure easy sorting, retrieval, and prioritization. \n\nThe data is divided into categories, and a label, or a tag, is applied to make it easily searchable.  \n\n<br/>\n\nThe three commonly used types of data classification are: \n\n* **Content-based**, which is done solely based on the information involved, \n* **Context-based**, which takes into account the location of the data, the owner, the application it is used in, and others, \n* **User-based**, which requires users to label data based on internal rules. \n\n</br>\n\nIn this article, we will understand how valuable data classification is for a company using cloud services, as well as how [AWS](https://cyscale.com/use-cases/aws-cloud-security/), [Azure](https://cyscale.com/use-cases/azure-cloud-security/), and [Google Cloud](https://cyscale.com/use-cases/gcp-cloud-security/) handle the process of labeling/tagging assets. \n\n## Benefits of data classification \n\n#### 1. Risk management \n\nAccording to [AWS](https://docs.aws.amazon.com/whitepapers/latest/data-classification/data-classification-overview.html), data classification is a foundational step in cybersecurity risk management. The reason behind this is that applying labels to data and establishing security requirements such as: \n\n* the level of confidentiality,  \n* the need for integrity checking,  \n* the sensitivity of data, \n\ncan help your company manage risks efficiently. \n\n#### 2. Compliance \n\nWhen implementing compliance with [international standards](https://cyscale.com/use-cases/cloud-compliance-and-auditing/), you must know what type of data your company is managing and storing.  \n\nData classification should be done correctly to understand which of the data you're storing is confidential/sensitive. You cannot comply with recognized frameworks unless you correctly handle confidential data (and you cannot do this unless you know which data is confidential). \n\nLet’s look at a **scenario** – if you’re storing customer [PII](https://cyscale.com/blog/protecting-pii-in-the-cloud/), but you are not aware of the criticality of that data, you may not even think of protecting it, for example, by encrypting it. \n\nTherefore, your company may not be compliant with standards like: \n\n* SOC 2,  \n* [PCI-DSS](https://cyscale.com/blog/pci-dss-compliance-in-cloud/),  \n* GDPR, and others. \n\n#### 3. Security \n\nOrganizing data into categories and using labels can help you maintain: \n\n* **confidentiality**, because you will turn your focus to the most sensitive data, \n* **integrity**, because you can mark the need for integrity as high for some data using labels, \n* **availability**, which can be explicitly ensured for data that needs to be highly available and is labeled as such. \n\n<br/>\n\nMuch of the data that used to be saved on-premises is now saved and processed in the cloud, in databases, assets of type storage, and others.  \n\nTherefore, data classification should be used in the cloud. Let’s look at what the cloud industry offers to help you easily and accurately classify your data. \n\n## Data classification – an industry overview \n\nWe will look at the top 3 cloud vendors – AWS, Microsoft Azure, and Google Cloud – to see how data classification is implemented and the different types of tags that can be applied depending on the cloud service selected. \n\n#### 1. Amazon Web Services \n\nIn the AWS documentation, a three-tiered classification is recommended, with the following tag names: \n\n* Unclassified, \n* Official, \n* Secret and above. \n\nMoreover, AWS presents the following three labels used by NIST (National Institute of Standards and Technology), a United States government agency, and recommends them: \n\n* Low,  \n* Moderate, \n* High, \n\nwhich classify the impact a potential data breach would cause on that data.  \n\nHowever, these tags are recommendations and users can implement their own tags. Later in this article, you will find best practices on how to implement labeling for your cloud environment. \n\nWhen you create a resource in AWS, you can add tags (key-value pairs) to the resource to associate it to labels used in data classification. \n\n#### 2. Google Cloud Platform\n\nFor data classification in Google Cloud, we can find both labels and tags, which are two different things.  \n\nA label is described as a key-value pair that you can create using the Resource Manager API and the Google Cloud console. These can be used to separate resources in terms of billing, to add information about resource state, and so on. \n\nTags, however, are the tools that allow Google Cloud customers to classify data and establish rules based on their classification. \n\nThe difference between labels and tags in Google Cloud is that labels are simply metadata added to resources, while tags categorize assets and can be used when defining policies and rules (for example, who is allowed to access a certain asset) in your Google Cloud environment. \n\n#### 3. Microsoft Azure \n\nIn Microsoft Azure, we can use the Microsoft Purview service to ensure data labeling of cloud assets.  \n\nMicrosoft Purview is a solution offered by Microsoft that brings together your cloud, on-premises, and SaaS data and helps you manage it through different solutions: \n\n* Data Map, \n* Data Catalog,  \n* Data Sharing, \n* Data Estate Insights, and others. \n\nAn important aspect is that Data Map powers most of the solutions offered by Microsoft Purview and is a paid service. \n\nIn terms of data classification, there are a few services that can help you manage your cloud resources: \n\n* the Microsoft Purview Data Catalog uses sensitivity labels that can be added to cloud assets. \n* the Microsoft Purview Information Protection service, which has the following features: data classification, trainable classifiers, sensitive information types, \n* the Azure Information Protection unified labeling client, a downloadable client that also provides sensitivity labels.  \n\nMicrosoft Azure suggests that you apply tags that contain additional information about resources (do not include any PII or sensitive data in the tags) to: \n\n* add context to your resources and understand them better,  \n* be able to use complex filters. \n\nAzure also suggests a “Data classification” tag to describe the sensitivity of data stored or processed by a resource. If an organization does not have their own labels defined, they may use the following values supplied by Microsoft: \n\n* Non-business, \n* Public, \n* General, \n* Confidential, \n* Highly confidential. \n\nMoreover, Azure recommends that you also use a formal data classification process. In the next section, we will explain best practices to keep in mind when classifying your resources. \n\n## How do you implement data classification? \n\nAn important rule to follow when implementing data classification is that the entire organization should use the same classification tags/labels. Using a policy or a procedure for this process that regulates: \n\n* the classification process as a whole, \n* the tags’ names, and others \n\nis essential to ensuring consistent data classification. \n\nIn Cyscale, you can find the out-of-the-box “Data Management” policy, which contains the “Data Classification” procedure to guide you in this process. Moreover, you can create your own custom policy with any specific rules you want to add. \n\n<br/>\n\nConsidering the benefits of data classification, implement this feature for your cloud environment. Use a company-level classification policy and add tags to your cloud assets to enable easy sorting, retrieval, and prioritization.  \n\nIn [Cyscale](https://cyscale.com/), you can use this feature to:  \n\n* easily filter assets based on tags,  \n* highlight any irregularities regarding your most sensitive assets, and  \n* prioritize remediation for the most urgent findings.  \n\n<!--EndFragment-->\n"}}]}},"pageContext":{"limit":9,"skip":9,"numPages":3,"currentPage":2,"category":"Cloud Security","seoTitle":"Cyscale - Cloud Security","seoDescription":"News about Cyscale Cloud Security","categoriesList":["Cloud Security","Compliance","News","Product","IAM","CSPM","CNAPP","Misconfigurations"],"categorySlug":"cloud-security"}},"staticQueryHashes":["220583031","4109069157","632500807","981947644"],"slicesMap":{}}