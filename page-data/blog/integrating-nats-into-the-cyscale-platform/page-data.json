{"componentChunkName":"component---src-template-blog-template-js","path":"/blog/integrating-nats-into-the-cyscale-platform/","result":{"pageContext":{"alldata":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["Engineering"],"title":"Integrating NATS Into the Cyscale Platform","seoTitle":null,"description":"Some concepts and techniques we leveraged to switch to a cloud-native message broker.","seoDescription":null,"date":"2021-12-22T10:11:16.968Z","featuredpost":true,"permalink":"integrating-nats-into-the-cyscale-platform","featuredimage":{"publicURL":"/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/nats-horizontal-color.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/55207/nats-horizontal-color.png","srcSet":"/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/ac644/nats-horizontal-color.png 205w,\n/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/7329d/nats-horizontal-color.png 410w,\n/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/55207/nats-horizontal-color.png 820w,\n/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/b1090/nats-horizontal-color.png 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/913d0/nats-horizontal-color.webp 205w,\n/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/85995/nats-horizontal-color.webp 410w,\n/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/02dc4/nats-horizontal-color.webp 820w,\n/static/f6d3c0d1c6563c2d1bdbbb31e7a2ac98/62a3a/nats-horizontal-color.webp 1640w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":461}}}},"rawMarkdownBody":"\n<!--StartFragment-->\n\n## Backstory\n\nCyscale helps you secure your cloud infrastructure. To achieve this, the platform must be able to read (sync) the cloud resources, perform assessments against a set of controls (security and architecture guidelines and best practices), send notifications, generate reports, perform scheduled tasks, and so on. Given the highly distributed and segregated nature of the platform, we chose a microservices architecture on top of Kubernetes. Also, by design, these processes are mostly asynchronous, happening in the background as a result of a certain event or trigger.\n\nBesides direct HTTP communication (REST mostly for the account/user management and GraphQL for everything cloud-related), we make heavy use of message-based communication.\n\nUp until recently, Redis served as our backbone for sending messages. We used Redis Lists to simulate queues (e.g., for sending emails) and Redis Pub/Sub for, well, implementing the publish-subscribe pattern (e.g., for triggering the synchronization of the cloud resources). We knew since the beginning that Redis will not serve as the messaging middleware forever, but we started with it since it was already there for caching and tasks (through [Go Celery](https://github.com/gocelery/gocelery)).\n\nDue to a mix of accumulated technical debt and a desire for simplicity, we decided to invest in integrating a purpose-built technology for handling messages. After a good amount of research covering topics such as operational simplicity, community, and documentation, we decided to go with [NATS](https://nats.io/). As a side note, we continue to love Redis and there are plenty of well-established companies using it as their messaging middleware with great success.\n\nThe rest of the article will cover the main steps we took to integrate NATS into our platform such as understanding the NATS ecosystem, deploying the relevant tools on our Kubernetes cluster using Helm - this will form the main part since this is where we faced the most challenges, and, of course, sending and consuming messages.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\n**The NATS Ecosystem**\n\n![The NATS ecosystem encompassing the core NATS server, JetStream, the NATS clients and CLI, and the NATS resources for Kubernetes](/img/cyscale-nats.png 'The NATS ecosystem')\n\n### Core NATS\n\nAt its core, **the NATS server** is a **publish/subscribe** message broker. It offers **at most once delivery** and works based on **subjects**. These can have a hierarchical structure such as `sync.aws` and `sync.gcp`. Services concerned with messages related to syncing operations for AWS will only subscribe to `sync.aws` while other services might listen for all sync-related messages on `sync.*` (which covers both subjects) or even `sync.>` (which will also cover `sync.aws.ec2` - a separate subject).\n\nAnother feature that provides us with great value is called **queue groups**. This helps us horizontally scale our consumers while making sure that only one instance of a service receives a certain message. If you have experience with Kafka, it resembles consumer groups. What’s nice about queue groups is that they are automatically created when consumers subscribe to a subject and provide the queue group parameter (a simple string that, just like subjects, can have a hierarchical structure). For example, we use the name of the service (e.g. notifier) as the queue group.\n\nWhile the core functionality is great and simple, plain old pub/sub with at most once delivery will not cover all use cases. Subscribers might be under heavy load or even down, there might be a network partition or we might even want to keep messages and follow an approach based on event sourcing (you can find more examples in the [NATS docs](https://docs.nats.io/using-nats/developer/develop_jetstream)). In other words, as soon as we need **temporal decoupling** between publishers and subscribers, we need **persistence**, which for NATS is provided by JetStream.\n\n### JetStream\n\nJetStream adds the concept of **streams** on top of the core NATS subjects. Basically, if you want your messages to be persisted, you can enable JetStream on the NATS server and create a stream that will actually store the messages sent to a subject (or multiple subjects - this is mostly to optimize resource utilization; for example, we have one stream called sync that stores all messages sent to any sync subject - i.e. sync.>).\n\nIf your system takes full advantage of JetStream, at most once delivery transforms into **at least once** and even **exactly once** by leveraging [message deduplication](https://docs.nats.io/using-nats/developer/develop_jetstream/model_deep_dive#message-deduplication) (NATS will discard a message if another message with the same publisher-provided ID exists in the stream over a window of a certain time - 2 minutes by default).\n\nOne confusion we had at the beginning was whether we actually had to do anything to take advantage of JetStream besides enabling it. Again, bringing the simplicity up front, publishers will not require any modification unless you are looking for exactly-once delivery (you will have to add the message ID). They still send messages on a certain subject and, behind the scenes, JetStream will persist them in the configured stream.\n\nOn the other hand, **you do have to create the actual streams** (we will talk about this below) and **adjust the subscribers to use the JetStream API** (part of the client NATS library). Note that you can still use the core NATS API, but your subscribers will not receive messages sent before they started listening (even though they are stored in the stream). The reason behind this is that JetStream actually creates consumers that handle the delivery of messages for each subscriber. You will have to manually create the consumer when using the CLI, but the client libraries will handle this automatically when subscribing to a subject through the JetStream API.\n\nHaving the messages persisted also enables us to take different approaches based on what we want to achieve. We might still follow a pub/sub approach for certain subscribers (these are known as **push consumers**) (e.g. we use this approach for generating user-requested reports) or we might want to have more control over how messages are retrieved in which case we will use a **pull consumer**. This enables us to batch messages (e.g. we do this for sending notifications). Here is how we handle the messages in our notifier service:\n\n```typescript\nexport type MessageHandler = (data: NotificationDto[]) => Promise<void>;\n\nexport const handleNotificationMessages = async (handler: MessageHandler) => {\n    try {\n        const nc = await getNatsClient();\n\n        if (!process.env.NOTIFICATIONS_SUBJECT) {\n            throw Error('NOTIFICATIONS_SUBJECT not set');\n        }\n\n        const jc = JSONCodec<NotificationDto>();\n\n        const psub = await nc.jetstream().pullSubscribe(process.env.NOTIFICATIONS_SUBJECT, {\n            queue: 'notifier',\n            config: { durable_name: 'notifier' }\n        });\n\n        const done = (async () => {\n            let notifications: NotificationDto[] = [];\n            for await (const m of psub) {\n                try {\n                    notifications.push(jc.decode(m.data));\n                    m.ack(); // Wait to gather all messages from the current batch\n                    if (m.info.pending === 0) {\n                        await handler(notifications);\n                        logger.info(`Processing ${notifications.length} messages`);\n                        notifications = [];\n                    }\n                } catch (error) {\n                    logger.error(error);\n                }\n            }\n        })();\n\n        setInterval(() => {\n            psub.pull({ batch: 30, expires: 1000 });\n        }, 1000 * 30);\n\n        logger.info(`Listening for messages on ${process.env.NOTIFICATIONS_SUBJECT}`);\n\n        await done;\n        await psub.destroy();\n    } catch (e) {\n        logger.error(`Failed to initiate message listening ${e}`);\n    }\n};\n```\n\n(yes, most of our services are actually written in Go, hence the naming of some variables)\n\nAnother dilemma we faced was regarding **stream creation**. Who/what is responsible for creating the streams? One option is using the client libraries which expose a method to **idempotently** create streams. While this can work just fine, we didn’t want our services to bother with the technical details of NATS. Also, streams felt more like being part of the infrastructure than part of the actual services. So we continued our research and found [NACK](https://github.com/nats-io/nack) which we cover below.\n\nAs a side note regarding persistence/streaming with NATS, the precursor of JetStream is called STAN, which is now deprecated. We are mentioning this because there are still plenty of tutorials that focus on STAN, but JetStream is the way forward.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\n## NATS on Kubernetes with Helm\n\nBeing part of the CNCF, we can expect NATS to have first-class support for Kubernetes. And it does.\n\nSince the entire Cyscale platform is specified as a Helm chart we just needed to add the [NATS](https://github.com/nats-io/k8s/tree/main/helm/charts/nats) subchart as a dependency and configure the values. You can check the [values file](https://github.com/nats-io/k8s/blob/main/helm/charts/nats/values.yaml) from the chart repo for reference. One small detail that cost us a few hours was how we were specifying the values for NATS. If you look at [the documentation](https://docs.nats.io/running-a-nats-service/introduction/running/nats-kubernetes/helm-charts#jetstream), you will notice the `nats` object. However, since we are deploying NATS as a subchart, we will need an additional parent `nats` object to instruct Helm to pass the values down to the nats subchart. Here are our values for NATS on the dev cluster:\n\n```yaml\nnats:\n  nats:\n    image: nats:alpine\n    resources:\n      requests:\n        cpu: 100m\n        memory: 100Mi\n      limits:\n        cpu: 200m\n        memory: 200Mi\n    jetstream:\n      enabled: true\n      memStorage:\n        enabled: true\n        size: 80Mi\n      fileStorage:\n        enabled: true\n        size: 1Gi\n        storageDirectory: /data/\n        storageClassName: default\n```\n\n(notice the two `nats`)\n\nBesides the actual NATS server (which is a container running in the NATS pod along with the monitoring and config reloader containers), we also have a **NATS Box** pod (comes with the NATS Helm chart) that helps us with testing and administrative tasks - basically its a **preconfigured NATS CLI**. We access it using the command `kubectl exec -it <nats-box-container> -- /bin/sh -l`. The other alternative would have been to install the NATS CLI on our machines and port forward the NATS server from the cluster.\n\n### Creating the Streams with NACK\n\nBesides NATS, we also added the [NACK subchart](https://github.com/nats-io/k8s/tree/main/helm/charts/nack) which requires the NACK **CRDs** (install using `kubectl apply -f <https://raw.githubusercontent.com/nats-io/nack/v0.6.0/deploy/crds.yml>`). That’s because it enables us to treat JetStream streams as Kubernetes resources deployed as part of the rest of the platform.\n\nInstead of having our services handle the stream creation or manually creating them from the NATS box, we specify them declaratively as follows (`templates/nats-streams.yaml`):\n\n```yaml\n# See https://github.com/nats-io/nack/blob/main/deploy/crds.yml for more properties\n{{- range .Values.nack.streams }}\napiVersion: jetstream.nats.io/v1beta2\nkind: Stream\nmetadata:\n  name: {{ .name | quote }}\nspec:\n  name: {{ .name }}\n  subjects: {{ .subjects }}\n  storage: {{ .storage | quote | default \"file\" }}\n  retention: {{ .retention | quote | default \"limits\" }}\n---\n{{- end }}\n```\n\nWe also declare the streams as a list in the values file (notice the `range`).\n\nOnce these are deployed, you can inspect the streams just like any other k8s resource using `kubectl get streams`. One issue we faced was that the streams were not actually created in JetStream (`nats stream ls` from the nats box) even though the k8s resources existed. We simply manually deleted them from the cluster (`kubectl delete streams.jetstream.nats.io --all`) and re-deployed the helm chart.\n\nThere is another alternative we considered - the [jetstream Terraform provider](https://registry.terraform.io/providers/nats-io/jetstream/latest/docs). While we do use Terraform to declare our infrastructure on top of which the Kubernetes cluster is running, we chose NACK because it fit our abstraction layers best and because the terraform provider, running locally or in our pipelines, has to somehow reach the NATS server. In our case, the NATS server is not exposed outside of the cluster (again, port-forwarding is an option).\n\n### Ending Notes\n\nWhile there are more subjects to cover such as [authentication](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro) and [authorization](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/authorization), clustering (and [super-clusters](https://docs.nats.io/running-a-nats-service/configuration/gateways)), and multi-tenancy using [accounts](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/accounts), we hope this article helps you better understand how NATS works and how to deploy it. This is our way of giving back to a growing community and expressing our appreciation for getting to work with such great technologies.\n\n<!--EndFragment-->\n"},"suggestions":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"MAS TRM Compliance in the Cloud","seoTitle":"MAS TRM Compliance in the Cloud","description":"The Monetary Authority of Singapore (MAS) Technology Risk Management (TRM) Guidelines is a set of principles and best practices destined for financial institutions, meant to regulate risk management and assessment, access control, incident management, software application development, and others. In this article, we look at requirements that affect the cloud, such as IT resilience, access control, cryptography, data and infrastructure security, cyber security operations, and cyber security assessment.","seoDescription":"The Monetary Authority of Singapore (MAS) Technology Risk Management (TRM) Guidelines is a set of principles and best practices destined for financial institutions, meant to regulate risk management and assessment, access control, incident management, software application development, and others. In this article, we look at requirements that affect the cloud, such as IT resilience, access control, cryptography, data and infrastructure security, cyber security operations, and cyber security assessment.","date":"2023-01-31T09:47:07.869Z","featuredpost":true,"permalink":"mas-trm-compliance-in-cloud","featuredimage":{"publicURL":"/static/ee0114aebe1c57ddb6213af1a22b8a7f/33_blog-cover-image-mas-trm.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/ee0114aebe1c57ddb6213af1a22b8a7f/d6cae/33_blog-cover-image-mas-trm.png","srcSet":"/static/ee0114aebe1c57ddb6213af1a22b8a7f/ac644/33_blog-cover-image-mas-trm.png 205w,\n/static/ee0114aebe1c57ddb6213af1a22b8a7f/89b47/33_blog-cover-image-mas-trm.png 410w,\n/static/ee0114aebe1c57ddb6213af1a22b8a7f/d6cae/33_blog-cover-image-mas-trm.png 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/ee0114aebe1c57ddb6213af1a22b8a7f/913d0/33_blog-cover-image-mas-trm.webp 205w,\n/static/ee0114aebe1c57ddb6213af1a22b8a7f/91660/33_blog-cover-image-mas-trm.webp 410w,\n/static/ee0114aebe1c57ddb6213af1a22b8a7f/888e2/33_blog-cover-image-mas-trm.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nThe Monetary Authority of Singapore (MAS) Technology Risk Management (TRM) Guidelines is a set of principles and best practices destined for financial institutions, meant to regulate various aspects of technology such as: \n\n* Risk management and assessment,  \n* Access control, \n* Incident management,  \n* Software application development, and many others. \n\nMAS TRM Guidelines contains the following 13 sections: \n\n1. Technology Risk Governance and Oversight \n2. Technology Risk Management Framework \n3. IT Project Management and Security-by-Design \n4. Software Application Development and Management \n5. IT Service Management \n6. IT Resilience \n7. Access Control \n8. Cryptography \n9. Data and Infrastructure Security \n10. Cyber Security Operations \n11. Cyber Security Assessment \n12. Online Financial Services \n13. IT Audit \n\nThese sections contain subsections that describe in detail the best practices that should be followed for each area covered by that section.  \n\nIt is important to note that MAS TRM Guidelines does not contain any specific controls, and it is up to the organization to create and tailor controls to fulfill each section's recommendations. \n\nIn this article, we will look in detail at the sections that may apply for cloud environments and understand the requirements. \n\n## IT Resilience  \n\nThis section describes the importance of: \n\n* Availability,  \n* Recoverability, \n* Disaster recovery, \n* Backups,  \n* Data centre resilience. \n\n**Availability** ensures users can access data without interruption. High availability is an essential feature, and having disruptions of even a few minutes per week can cost organizations a lot. \n\n**Recoverability** is the ability of an organization to quickly restore its systems after an incident. **Disaster recovery** is an aspect of recoverability that specifically refers to the way systems and data are restored after a disaster.  \n\n**System backup** is the process of storing copies of data in different data centers. Backup goes hand-in-hand with **data center resilience**, enforcing that data backups should be stored in data centers that are in different regions. In this way, if a natural disaster or civil unrest occurs, the destructions of all backups may be avoided by storing them apart.  \n\n## Access control \n\nThe following section in MAS TRM Guidelines is access control. It is a component of IAM (Identity and Access Management) that describes what users can access and how. Parts of this section include: \n\n* User access management, \n* Privileged access management. \n\n**User access management** refers to what resource can each user access. [The principles of least privilege](https://cyscale.com/blog/check-for-least-privilege/) and segregation of duties are recommended best practices. \n\n**Privileged Access Management (PAM)**, on the other hand, is an essential aspect of access control that strictly regulates the access of authorized users to privileged resources. Moreover, the access granted can be restricted: the user may only access important resources for a limited amount of time or perform only a small set of actions, according to their needs. \n\n## Cryptography \n\n[Cryptography](https://cyscale.com/blog/types-of-encryption/) protects the confidentiality, integrity, and authenticity of mostly at-rest and in-transit data.  \n\nIn MAS TRM Guidelines, two aspects of cryptography are considered: \n\n* Cryptographic Algorithm and Protocol, \n* Cryptographic Key Management. \n\n**Cryptographic Algorithm and Protocol** refers to the usage of industry-recommended cryptographic algorithms, such as: \n\n* SSL/TLS (Transport Layer Security) and SSL (Secure Sockets Layer) for in transit data encryption, and  \n* AES (Advanced Encryption Standard) for [at rest data](https://cyscale.com/blog/protecting-data-at-rest/) encryption. \n\n**Key management** is also an important aspect of cryptography; if the key is not generated, stored, transmitted, or destroyed safely, it may compromise the encryption. Best practices that we recommend include: \n\n* generating the keys randomly,  \n* rotating them regularly,  \n* storing them separately from ciphertext. \n\n## Data and Infrastructure Security \n\nThis section refers to the following concepts: \n\n* Data Security, \n* Network Security, \n* System security, \n* Virtualization security. \n\nTo ensure **data security**, data should be protected in all its states: at rest, in transit, and in use. Unauthorized access, modification, copying, or destruction of data should be avoided by: \n\n* Encrypting data when possible, \n* Disabling public access to assets that should not be publicly accessible, \n* Restricting access through strict policies, and others. \n\nTo implement **network security**, firewalls, intrusion detection systems (IDSs), network access control lists (ACLs), and other network devices or protection mechanisms should be used. \n\nTo ensure a strong **system security**, recommendations from MAS TRM Guidelines include both software and hardware components in their best practices: \n\n* using anti-virus programs for endpoint protection,  \n* defining procedures to check if security measures are effective and up to date, \n* using a white-list approach, which means that only authorized software should be trusted, and others. \n\nLastly, best practices suggested by MAS TRM Guidelines in the context of virtualization security are: \n\n* Implement a strong access control to administrative privileges that may affect the hypervisor or the operating system of a virtual machine (VM),  \n* Ensure the images used for VMs are secure, and others. \n\n## Cyber Security Operations \n\nThe “**Cyber Event Monitoring and Detection**” component refers to continuous logging and monitoring of cloud processes to identify suspicious behavior and anomalies, as well as procedures that should be implemented to efficiently react to findings. \n\n## Cyber Security Assessment \n\nThe last section that can be applied to cloud environments is \"Cyber Security Assessment\", more specifically, **Vulnerability assessment**.  \n\nTo identify vulnerabilities in the cloud, regular vulnerability assessments should be conducted.  \n\n## Achieving MAS TRM Compliance in the Cloud \n\nMAS TRM Guidelines is a comprehensive compliance standard that specifies best practices for financial institutions. We've looked at aspects that affect cloud environments. \n\nCyscale provides a dedicated page for standards and compliance laws, that can be used to track progress in the compliance process and ensure that you’re ready for audits. MAS TRM Guidelines is one of the compliance frameworks that can be found here. \n\nIn the image below, you can see that, for the standard, there have been 276 controls checked, which are available across four cloud vendors (Microsoft Azure, AWS, GCP Cloud, Alibaba Cloud). \n\nLet’s look at examples of controls for some of the key components we've described in this article to see how Cyscale checks cloud configurations and helps you understand which requirements you’re fulfilling and which not. \n\n### IT Resilience \n\n* Availability: *Ensure databases have deletion protection enabled.* \n* Backups: *Ensure soft delete is enabled for Azure Storage.* \n\n### Access control \n\n* User access management: *Ensure IAM policies that allow full \"\\*:\\*\" administrative privileges are not created.* \n* Privileged access management: *Ensure a log metric filter and alarm exist for usage of \"root\" account.* \n\n### Cryptography \n\n* Cryptographic Algorithm and Protocol: *Ensure web app is using the latest version of TLS encryption.* \n* Cryptographic Key Management: *Ensure Azure Key Vaults are used to store secrets.* \n\n### Data and Infrastructure Security \n\n* Data security: *Ensure databases are encrypted.* \n* Network security: *Ensure firewall rule does not allow all traffic on port 80.* \n* System Security: *Ensure Kubernetes Engine uses HTTP load balancing ID.* \n* Virtualization security: *Ensure AMIs Are Private.* This control limits data exposure by disabling public access to AMIs (Amazon Machine Images). \n\n### Cyber Security Operations \n\n* Cyber Event Monitoring and Detection: *Ensure CloudTrail is enabled in all regions.* \n\n### Cyber Security Assessment \n\n* Vulnerability assessment: *Ensure AWS Inspector is configured for EC2 Instances.* \n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News"],"title":"Announcing the New Whitepaper: The In-Depth Guide to Cloud Compliance in 2023","seoTitle":"Announcing the New Whitepaper: The In-Depth Guide to Cloud Compliance in 2023","description":"Along with the new year come new resolutions. Do you want to take that big step and become compliant with an international standard in 2023?  \n\nWe’ve created a detailed whitepaper to help you understand why compliance is so important, what standards exist on the market and who they are destined for, and how to achieve compliance in the cloud.\nIn our in-depth guide, you will read about ISO 27001, SOC 2, PCI-DSS, GDPR, and HIPAA.\n","seoDescription":"Along with the new year come new resolutions. Do you want to take that big step and become compliant with an international standard in 2023?    We’ve created a detailed whitepaper to help you understand why compliance is so important, what standards exist on the market and who they are destined for, and how to achieve compliance in the cloud. In our in-depth guide, you will read about ISO 27001, SOC 2, PCI-DSS, GDPR, and HIPAA.","date":"2023-01-26T06:48:45.952Z","featuredpost":true,"permalink":"whitepaper-cloud-compliance-in-2023","featuredimage":{"publicURL":"/static/c38c164d3bde9f6eafa520cefc33d41f/31_blog-cover-image-02.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/c38c164d3bde9f6eafa520cefc33d41f/d6cae/31_blog-cover-image-02.png","srcSet":"/static/c38c164d3bde9f6eafa520cefc33d41f/ac644/31_blog-cover-image-02.png 205w,\n/static/c38c164d3bde9f6eafa520cefc33d41f/89b47/31_blog-cover-image-02.png 410w,\n/static/c38c164d3bde9f6eafa520cefc33d41f/d6cae/31_blog-cover-image-02.png 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/c38c164d3bde9f6eafa520cefc33d41f/913d0/31_blog-cover-image-02.webp 205w,\n/static/c38c164d3bde9f6eafa520cefc33d41f/91660/31_blog-cover-image-02.webp 410w,\n/static/c38c164d3bde9f6eafa520cefc33d41f/888e2/31_blog-cover-image-02.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nAlong with the new year come new resolutions. Do you want to take that big step and become compliant with an international standard in 2023?  \n\nWe’ve created [a detailed whitepaper](https://cyscale.com/whitepaper/the-complete-guide-to-cloud-compliance/) to help you answer the following questions: \n\n* Why is compliance important? \n* What standards exist on the market, and who are they destined for? \n* How do you achieve compliance in the cloud? \n\nIn our in-depth guide, you will read about the following: \n\n* ISO 27001,  \n* SOC 2, \n* PCI-DSS, \n* GDPR, \n* HIPAA. \n\nWe look in detail at the cloud-specific controls required by them, we understand how audits work and how long they last, and we also take into consideration the consequences of failing to meet compliance conditions in the case of each standard. \n\nCyscale has the cloud-focused features you need to achieve compliance with as little effort as possible, providing: \n\n* A comprehensive standards page where you can group all of the standards you want to adhere to and also track your progress, \n* A policies page where you can choose from our out-of-the-box policies or create your own (we offer flexibility on how you use the feature), \n* Compliance scores, alerts, and trends to bring visibility to your cloud environment and compliance progress. \n\n[Download the whitepaper ](https://cyscale.com/whitepaper/the-complete-guide-to-cloud-compliance/)to read more and let us be your compliance partner in 2023! \n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"NIST Compliance in the Cloud","seoTitle":"NIST Compliance in the Cloud","description":"NIST (The National Institute of Standards and Technology) is a compliance standard that develops best practices and security standards for government organizations or contractors. There are three NIST frameworks available: NIST Cybersecurity Framework, NIST 800-53, NIST 800-171. Cyscale can help you ease the process of becoming NIST compliant. Using our Standards page, you can track your progress and speed up the process in terms of your cloud-specific needs. ","seoDescription":"NIST (The National Institute of Standards and Technology) is a compliance standard that develops best practices and security standards for government organizations or contractors. There are three NIST frameworks available: NIST Cybersecurity Framework, NIST 800-53, NIST 800-171. Cyscale can help you ease the process of becoming NIST compliant. Using our Standards page, you can track your progress and speed up the process in terms of your cloud-specific needs. ","date":"2023-01-11T09:15:32.900Z","featuredpost":true,"permalink":"nist-compliance-in-the-cloud","featuredimage":{"publicURL":"/static/cd1d1dd59a75ec79b1c30404b792ffe7/32_blog-cover.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/cd1d1dd59a75ec79b1c30404b792ffe7/d6cae/32_blog-cover.png","srcSet":"/static/cd1d1dd59a75ec79b1c30404b792ffe7/ac644/32_blog-cover.png 205w,\n/static/cd1d1dd59a75ec79b1c30404b792ffe7/89b47/32_blog-cover.png 410w,\n/static/cd1d1dd59a75ec79b1c30404b792ffe7/d6cae/32_blog-cover.png 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/cd1d1dd59a75ec79b1c30404b792ffe7/913d0/32_blog-cover.webp 205w,\n/static/cd1d1dd59a75ec79b1c30404b792ffe7/91660/32_blog-cover.webp 410w,\n/static/cd1d1dd59a75ec79b1c30404b792ffe7/888e2/32_blog-cover.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nThe National Institute of Standards and Technology (NIST) is a non-regulatory US government agency that develops best practices and security standards for government organizations or contractors.  \n\nNIST compliance is mandatory for government contractors handling government data. Still, companies outside this range also choose to become NIST compliant due to the excellent reputation and benefits of the standard. \n\nThree NIST frameworks can be used when establishing NIST compliance: \n\n* NIST Cybersecurity Framework, \n* NIST 800-53, \n* NIST 800-171. \n\nLet’s look at them in detail to understand the differences. \n\n## NIST Cybersecurity Framework \n\nThe NIST Cybersecurity Framework (CSF) gathers best practices and standards to help companies build a robust cybersecurity program and manage risk.  \n\nThe framework contains 5 core functions, which contain 23 categories, which in turn are divided into 108 subcategories formulated as outcomes. Organizations can formulate their own controls or use the suggested ones corresponding to NIST SP 800-53.  \n\nThe core functions are: \n\n* Identify, \n* Protect, \n* Detect, \n* Respond, \n* Recovery. \n\nThe **Identify** function focuses on the company’s efforts to assess and understand: \n\n* Risk, \n* The business environment,  \n* Assets, \n* The supply chain, and others. \n\nIdentify is the first step to securing your cloud environment; having a good grasp of your assets and their relations can provide you the visibility you need to secure them and fix misconfigurations properly. \n\nThe **Protect** function introduces requirements regarding: \n\n* [identity management](https://cyscale.com/blog/iam-services-in-aws-azure-gcp/),  \n* access control,  \n* data security, and others. \n\nWe can translate to the cloud this function’s scope through the following examples: \n\n* Assets [encryption](https://cyscale.com/blog/types-of-encryption/), \n* Strong [IAM policies](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/), \n* Compliance with the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/), and others. \n\nThe third function in the NIST Cybersecurity Framework, **Detect**, refers to the logging and monitoring of processes and events. Suspicious behavior and anomalies can be identified through careful examination of logs. \n\nThe **Respond** function involves incident management and incident response and ensures that the impact of a cybersecurity incident is minimized. \n\nThe last step to ensuring NIST CSF compliance is **Recovery**. Availability is crucial, and incidents that keep systems down can be catastrophic. To fulfill this function in the cloud, one of the solutions is to replicate and back up data in different data centers and regions to safeguard data and maintain high availability in the case of incidents. \n\n## NIST 800-53 \n\nThe NIST Special Publication (SP) 800-53 is a comprehensive framework designed for governmental agencies that implement information security systems, except for those related to national security, where they can be used to complement the national security systems guidelines. \n\nSP 800-53 has over 1000 security controls, categorized into the following 20 control families: \n\n1. Access control, \n2. Awareness and training, \n3. Audit and accountability, \n4. Assessment, authorization, and monitoring, \n5. Configuration management, \n6. Contingency planning, \n7. Identification and authentication, \n8. Incident response, \n9. Maintenance, \n10. Media protection, \n11. Physical and environmental protection, \n12. Planning, \n13. Program management, \n14. Personnel security, \n15. [PII](https://cyscale.com/blog/protecting-pii-in-the-cloud/) processing and transparency, \n16. Risk assessment, \n17. System and services acquisition, \n18. System and communications protection, \n19. System and information integrity, \n20. Supply chain risk management. \n\nFor this framework, the following steps are recommended: \n\n1. **Analyze.** This stage involves understanding what data the company stores and the risk associated with it, as well as possible threats. \n2. **Tailor controls.** This process involves inspecting all of the controls and establishing how each of them applies to your company, as well as adjusting them to fit your company's needs.  \n3. **Assess.** A continuous analysis of the efficacy is an essential process. \n\nFor example, the first control family described in NIST SP 800-53, “Access control”, can be comprised of several cloud-specific requirements, such as: \n\n* Assigning permissions in the cloud at group level with well-defined rules, \n* Using role-based access control (RBAC) and complying with the Least Privilege Principle, \n* Enabling [multi-factor authentication (MFA)](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/#MFA) for all users, and others. \n\n## NIST 800-171 \n\nThe NIST SP 800-171 is a framework designed for non-federal companies that work with federal agencies. This framework is intended to protect controlled unclassified information (CUI). \n\nCUI is information related to the government that is unclassified, but sensitive. For example, [PII](https://cyscale.com/blog/protecting-pii-in-the-cloud/) and [PHI](https://cyscale.com/blog/hipaa-compliance-in-cloud/) may fall under this category. \n\nThis framework contains 14 out of the 20 categories listed for NIST 800-53 and is less complex than SP 800-53. Many of the 110 controls are best practices and are easier to understand, compared to the 1000 controls existent in NIST SP 800-53. \n\n## Here’s how we can help \n\nChoosing which framework is suitable for you and becoming compliant is not an easy task.  \n\nCyscale can help you ease the process of becoming NIST compliant. Using our Standards page, you can track your progress and speed up the process in terms of your cloud-specific needs. \n\n<img src=\"/img/32_blog-standards.png\" alt=\"The NIST Standard in Cyscale\" title=\"The NIST Standard in Cyscale\" class=\"\" style=\"width:auto;height:auto;\"/>\n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News","Product"],"title":"Introducing the New Data Security Dashboard!","seoTitle":"Introducing the New Data Security Dashboard!","description":"We have released a new, powerful Data Security Dashboard to provide visibility in the cloud. The Dashboard displays information about encryption, the management of cryptographic keys, publicly accessible storage assets such as VMs, databases, buckets, and others, databases and misconfigurations related to them, containers such as blobs and buckets that may vulnerable, and others. These DSPM (Data Security Posture Management) capabilities enable users to detect attack paths for data storage assets and quickly mitigate them.   ","seoDescription":"We have released a new, powerful Data Security Dashboard to provide visibility in the cloud. The Dashboard displays information about encryption, the management of cryptographic keys, publicly accessible storage assets such as VMs, databases, buckets, and others, databases and misconfigurations related to them, containers such as blobs and buckets that may vulnerable, and others. These DSPM (Data Security Posture Management) capabilities enable users to detect attack paths for data storage assets and quickly mitigate them.   ","date":"2022-12-15T09:34:35.185Z","featuredpost":true,"permalink":"data-security-dashboard","featuredimage":{"publicURL":"/static/d4bc24dc38f86db99f4b9bec779de02b/blog_30-cover-2.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/d4bc24dc38f86db99f4b9bec779de02b/23056/blog_30-cover-2.jpg","srcSet":"/static/d4bc24dc38f86db99f4b9bec779de02b/41be8/blog_30-cover-2.jpg 205w,\n/static/d4bc24dc38f86db99f4b9bec779de02b/c78f7/blog_30-cover-2.jpg 410w,\n/static/d4bc24dc38f86db99f4b9bec779de02b/23056/blog_30-cover-2.jpg 820w,\n/static/d4bc24dc38f86db99f4b9bec779de02b/13bb8/blog_30-cover-2.jpg 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/d4bc24dc38f86db99f4b9bec779de02b/913d0/blog_30-cover-2.webp 205w,\n/static/d4bc24dc38f86db99f4b9bec779de02b/91660/blog_30-cover-2.webp 410w,\n/static/d4bc24dc38f86db99f4b9bec779de02b/02dc4/blog_30-cover-2.webp 820w,\n/static/d4bc24dc38f86db99f4b9bec779de02b/94e00/blog_30-cover-2.webp 1640w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":461}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nWe have released a new, powerful Data Security Dashboard to provide the visibility you need for your cloud. The Dashboard displays information about: \n\n* Encryption, \n* The management of cryptographic keys, \n* Publicly accessible storage assets such as VMs, databases, [buckets](https://cyscale.com/blog/s3-bucket-security/), and others, \n* Databases and misconfigurations related to them, \n* Containers such as blobs and buckets that may vulnerable, and others. \n\nThese DSPM (Data Security Posture Management) capabilities enable users to detect attack paths for data storage assets and quickly mitigate them.  \n\nThe first section of the dashboard shows us the percentage of storage assets that are:  \n\n* unencrypted,  \n* encrypted with provider-managed-key, and  \n* encrypted with CMK (Customer Managed Key).  \n\n<img src=\"/img/32_blog-progress-card.png\" alt=\"Progress card for encryption status\" title=\"Progress card for encryption status\" class=\"\" style=\"width:autorem;height:autorem;\"/>\n\nThis card is a good indicator of progress, and, by clicking on each section of the status bar, we see which assets fit in each of those states. Using this feature, you are at a click away from finding out which of your storage cloud assets are unencrypted. \n\nThe next section contains the Publicly Accessible card, which provides visibility over a multitude of assets, as you can see in the image below. When you click on each element, you see a list of affected assets, along with the associated risk. \n\n<img src=\"/img/32_blog-second-image.png\" alt=\"Publicly accessible cloud assets\" title=\"Publicly accessible cloud assets\" class=\"\" style=\"width:autorem;height:autorem;\"/>\n\nLet’s look at this feature in more detail to understand how this helps secure your cloud infrastructure. \n\nThe “**Readable Object Containers**” and “**Writable Object Containers**” refer to storage assets such as [buckets](https://cyscale.com/blog/s3-bucket-security/) and blobs. Object containers should not be publicly accessible unless it is necessary, since individuals could then read or overwrite possibly sensitive data without having to perform any kind of authentication or authorization. \n\nThe next item in this section highlights **database instances that have public IP addresses**. Databases should be configured with private IP addresses to reduce attack surface and increase security. \n\nThe last items in this list are publicly accessible: \n\n* **queues**,  \n* **encryption keys**, and  \n* **disks**.  \n\n[Cloud queues](https://cyscale.com/blog/cloud-queues-security-best-practices/) act like buffers to prevent data loss when services are too busy and cannot process incoming messages, and therefore should not be publicly accessible to prevent data leakage or data tampering. The control regarding encryption keys checks for attached policies that may allow public access to the key. The other control ensures there are no disks attached to VMs reachable from the internet. \n\nThe next card on the Data Security Dashboard provides an overview of the [encryption keys](https://cyscale.com/blog/protecting-data-at-rest/) used in your cloud infrastructure. Cryptographic key management is a very important but sometimes overlooked aspect of the encryption process.  \n\n<img src=\"/img/32_blog-encryption-keys.png\" alt=\"Cryptographic key management in Cyscale\" title=\"Cryptographic key management in Cyscale\" class=\"\" style=\"width:autorem;height:autorem;\"/>\n\nCyscale checks if the encryption keys are stored on a vulnerable VM or if they have a permissive access policy to identify possible attack paths. Moreover, important information is highlighted, such as: \n\n* keys that are in use and are scheduled for deletion, \n* keys that haven’t been rotated in a long time, and \n* keys that will expire soon. \n\nThe next two sections in this dashboard focus on object containers, such as buckets or blobs, and on [databases](https://cyscale.com/blog/best-practices-for-securing-databases/). Here, you can see some of the categories of vulnerabilities Cyscale has identified and checked your cloud environment against.  \n\nThe first card presents the state of your object containers. \n\n<img src=\"/img/32_blog-publicly-accessible-assets.png\" alt=\"Object containers with issues\" title=\"Object containers with issues\" class=\"\" style=\"width:autorem;height:autorem;\"/>\n\nUsing this feature, we identify attack paths that may compromise your cloud assets and help you solve them. \n\nFor example, a common attack is exploiting VMs that have open management ports. If you have a VM that has permissions on a bucket, and that VM is compromised, your bucket may be compromised as well.  \n\nUsing the [Cyscale Knowledge Graph](https://cyscale.com/blog/security-knowledge-graph-integrations/), you can see that the VM named \"sql-instance\" has an instance profile that gives it full access to the bucket on the far right, and the VM also has port 22 (SSH) open. The VM is thus connected to the internet and therefore puts the data stored in the bucket at risk. \n\n<img src=\"/img/cyscale-article-image-14-min.png\" alt=\"Cyscale Knowledge Graph highlighting an attack path\" title=\"Cyscale Knowledge Graph\" class=\"\" style=\"width:autorem;height:autorem;\"/>\n\nOther critical issues highlighted for object containers include: \n\n* Enabling public access to storage assets, \n* Having an overly-permissive access policy,  \n* Not enabling versioning, and others. \n\nClicking on “Object containers with public access”, we get a list of misconfigured assets as well as details like: \n\n* Connectors, which represents the cloud or identity provider account, \n* Tags,  \n* Risks. \n\n<img src=\"/img/blog_32-second-to-last.png\" alt=\"List of misconfigured assets\" title=\"List of misconfigured assets\" class=\"\" style=\"width:autorem;height:autorem;\"/>\n\nMoving on to the databases card, using controls, Cyscale checks for the following misconfigurations: \n\n* **Databases with public IP addresses,** \n* **Databases with outdated engine versions,** \n* **Databases without deletion protection,** \n* **Databases with no encryption,** \n* **Databases with no/old TLS.** \n\n<img src=\"/img/blog_32-databases-last.png\" alt=\"Databases with issues in Cyscale\" title=\"Databases with issues in Cyscale\" class=\"\" style=\"width:autorem;height:autorem;\"/>\n\nUse the multitude of features present in the Cyscale Data Security Dashboard to eliminate data exposure through [data storage misconfigurations](https://cyscale.com/whitepaper/cloud-storage-misconfigurations/). Check out our product in the [playground](https://cyscale.com/playground/) or [schedule a demo with us](https://cyscale.com/request-demo) to start your cloud security journey! \n\n<!--EndFragment-->"}}],"whitepaperCover":{"data":{"whitepaperCover":{"childImageSharp":{"gatsbyImageData":{"layout":"fixed","images":{"fallback":{"src":"/static/cdbd5693af50ac8bf55f2d978315946c/4c8e8/whitepaper-cover-blog.png","srcSet":"/static/cdbd5693af50ac8bf55f2d978315946c/4c8e8/whitepaper-cover-blog.png 111w","sizes":"111px"},"sources":[{"srcSet":"/static/cdbd5693af50ac8bf55f2d978315946c/891d3/whitepaper-cover-blog.webp 111w","type":"image/webp","sizes":"111px"}]},"width":111,"height":162}}}}}}},"staticQueryHashes":["2757132133","3765828210","4109069157","54043548"]}