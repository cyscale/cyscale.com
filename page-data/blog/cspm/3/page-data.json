{"componentChunkName":"component---src-template-blog-categories-template-js","path":"/blog/cspm/3/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Cloud Queues Security Best Practices","seoTitle":"Cloud Queues Security Best Practices","description":"A queue is a data structure that allows you to store and retrieve data in efficiently. A message queue, in the context of the cloud, is a service used to temporarily store data before it is processed. Solutions offered by cloud vendors are: Amazon SQS, Azure Queue Storage and Cloud Tasks in Google Cloud. Best Practices for queues security are: encrypt the data that arrives, log every action, restrict access to queue management and ensure access control, configure a dead-letter queue, use private endpoints for your queues and configure a long retention period.","seoDescription":"A queue is a data structure that allows you to store and retrieve data in efficiently. A message queue, in the context of the cloud, is a service used to temporarily store data before it is processed. Solutions offered by cloud vendors are: Amazon SQS, Azure Queue Storage and Cloud Tasks in Google Cloud. Best Practices for queues security are: encrypt the data that arrives, log every action, restrict access to queue management and ensure access control, configure a dead-letter queue, use private endpoints for your queues and configure a long retention period.","date":"2022-10-07T06:51:22.269Z","featuredpost":true,"permalink":"cloud-queues-security-best-practices","featuredimage":{"publicURL":"/static/3e43f46e5da4cc8c0e95be4faaff9949/25_blog-queue-security-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/3e43f46e5da4cc8c0e95be4faaff9949/888e2/25_blog-queue-security-cover-photo.webp","srcSet":"/static/3e43f46e5da4cc8c0e95be4faaff9949/913d0/25_blog-queue-security-cover-photo.webp 205w,\n/static/3e43f46e5da4cc8c0e95be4faaff9949/91660/25_blog-queue-security-cover-photo.webp 410w,\n/static/3e43f46e5da4cc8c0e95be4faaff9949/888e2/25_blog-queue-security-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## What is a queue? \n\nA queue is a data structure that allows you to store and retrieve data in an efficient manner. A message queue, in the context of the cloud, is a service used to temporarily store data before it is processed.  \n\nA message queue's role is to act like a buffer; if a service is too busy processing data and would otherwise drop traffic, then that traffic is added to a queue for temporary storage. \n\nA message queue usually works based on the FIFO mechanism. FIFO (First In, First Out) allows easy retrieval of messages based on their order of arrival to ensure a smooth process. That means the messages are extracted from the queue in the order they arrive. \n\n## Cloud vendors and queues \n\nLet’s look at solutions offered by cloud vendors and understand how to secure queues used in the cloud infrastructure. \n\n### 1. Amazon Simple Queue Service (Amazon SQS) \n\nThis solution helps you manage distributed systems and asynchronous tasks by storing messages in a buffer and waiting until the system is ready to process them. A few of the benefits offered by Amazon through this service are: \n\n* Security, \n* Durability, \n* Availability,  \n* Scalability, and others. \n\n### 2. Azure Queue Storage \n\nAzure Queue Storage helps you store large volumes of messages that can be accessed using authenticated HTTP or HTTPS requests. This type of storage offered by Microsoft Azure is useful in managing asynchronous tasks and ensuring no data loss occurs. \n\n### 3. Cloud Tasks in Google Cloud \n\nCloud Tasks is a slightly different service than we've discussed so far; Google Cloud allows users to store asynchronous tasks in queues and easily manage them.  \n\nThis type of queue can be used as a task scheduling system since you can set a time when a task should be executed. \n\nHowever, even though the queues in Cloud Tasks are designed for tasks, message passing is a use case of the queues.  \n\nAnother solution, very similar to Cloud Tasks, is Pub/Sub. Pub/Sub is a message queueing system that functions on a predefined set of rules, where there is a set of Subscribers, who all receive the queued messages from the Publisher when an event occurs. \n\n## Queues in the Cloud - Best Practices \n\nWhen thinking about [data security in the cloud](https://cyscale.com/blog/cloud-data-security-guide/), we think of secure storage and assets protection. For this reason, it is very easy to overlook where your sensitive data might end up; and queues are one place. \n\n**Don’t leave queues out of your data security program**; secure every state of data and ensure that you don’t have any vulnerabilities in your cloud infrastructure.  \n\nLet’s look at best practices for securing queues in the cloud. \n\n### 1. Encrypt the data that arrives in queues. \n\n[Encryption](https://cyscale.com/blog/types-of-encryption/) is critical in data security; it ensures that your traffic is confidential. \n\nWhether you implement client-side encryption (which means encrypting the data before sending it) or server-side encryption (where the cloud vendor deals with the encryption process), you need to ensure you don't have information in plain text. \n\nBesides these options, you can also make sure that, after leaving the queue, your data is stored encrypted. For example, AWS S3 assets allow users to set default encryption for data that arrives, so new objects are always stored encrypted.  \n\n### 2. Log actions that affect queues. \n\nKeep details of requests made to the queue; whether they are successful or failed, ensure you keep track of what happens to queues. Important signals that can help you identify any irregularities in your queues' configuration are:  \n\n* Authentication attempts,  \n* Latency, \n* Queue depth (the number of messages waiting to be processed), \n* Request and response sizes, and others. \n\nWhy are these parameters important? For example, if your cloud infrastructure is under a DDoS attack, you can quickly identify that by looking at requests and their size; such attacks usually send either very large volumes of data often or big requests that are meant to slow down your system. \n\n### 3. Restrict access to queue management and ensure access control \n\nImplement [the Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/) and only allow a small group of users to change queue configurations. Following [recommendations offered by Google](https://cloud.google.com/tasks/docs/secure-queue-configuration), deploy specific roles like Queue Administrator and assign them only to users who require those roles. \n\nBesides management, you should also have in place good access control rules. For example, IAM (Identity and Access Management) policies that restrict unnecessary access should be implemented and applied to queues. \n\n### 4. Configure a dead-letter queue \n\nA dead-letter queue (DLQ) is a type of queue designed for messages that, for various reasons, cannot be stored in the queue and processed correctly. Some of the reasons why messages may end up in DLQs are: \n\n* The application in which the queue is used has logical errors, \n* The message length limit was exceeded, \n* The queue is full, and others. \n\nDead-letter queues are useful for debugging what went wrong with the messages’ processing. For example, using a DLQ, you can look at rejected messages and then redirect them to your main queues. \n\n### 5. Use private endpoints for your queues \n\nAlthough most cloud providers enable you to have storage assets (and queues) open to the internet, it is the safest to use private endpoints. \n\nThis can be done using a Private Link, which creates a private connection between the services in the cloud and the queue.  \n\nThis way, traffic does not unnecessarily reach the public internet, and a layer of security is added. \n\n### 6. Configure a good retention period \n\nThe retention period refers to how long messages are stored in the queue before they are deleted. **A longer retention period** is recommended to provide flexibility in your environment and allow some time between the moment a message is received and when it is processed. \n\nFor example, Amazon SQS lets you configure a retention period between 1 minute and 14 days. \n\n## Protect your data using Cyscale \n\nAfter understanding best practices regarding queue security, it’s time to ensure you’re implementing them.  \n\nYou can easily do this using Cyscale! We help you check if you have vulnerabilities in your cloud environment and quickly solve any findings to solidify [your cloud security posture](https://cyscale.com/blog/improve-cloud-security-posture/).  \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Cloud Data Security For AWS: An In-Depth Guide","seoTitle":"Cloud Data Security For AWS: An In-Depth Guide ","description":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","seoDescription":"Understanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. To secure your cloud environment, you need to perform: data classification using labels, encryption, access control through policies. You also need to use DLP mechanisms to identify sensitive data and store it redundantly using availability zones. Secure your AWS environment using Cyscale!","date":"2022-09-29T06:25:58.261Z","featuredpost":true,"permalink":"cloud-security-for-aws","featuredimage":{"publicURL":"/static/8439e84f30635c75021e87142b3bea7b/24_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp","srcSet":"/static/8439e84f30635c75021e87142b3bea7b/913d0/24_blog-cover-photo.webp 205w,\n/static/8439e84f30635c75021e87142b3bea7b/91660/24_blog-cover-photo.webp 410w,\n/static/8439e84f30635c75021e87142b3bea7b/888e2/24_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->  \n\nUnderstanding and managing all your assets and services in the cloud are demanding tasks. It is easy to overlook even the smallest configuration and introduce a vulnerability in your cloud infrastructure. \n\nIn this article, you will find a comprehensive guide that will help you understand possible misconfigurations in your AWS cloud infrastructure and how to remediate them.  \n\n## Steps to secure your cloud environment \n\n### 1. Data classification \n\n[Classifying your cloud data](https://cyscale.com/blog/data-classification/) can help you easily sort, retrieve, and prioritize it. This is done using a tag (sometimes called a label), which is applied to cloud storage assets. In this way, that data is placed into one or more categories and can be identified more easily. \n\nBenefits of data classification include: \n\n* Risk management, \n* Compliance,  \n* Security. \n\nIn AWS, tags are key-value pairs that add metadata to your data. \n\nThe AWS documentation recommends using a three-tiered approach, with the following tags: \n\n* Unclassified, \n* Official,  \n* Secret. \n\nHowever, users can tailor data classification to their needs and use their own tags. In addition, **tag policies** can be used to standardize their creation and ensure consistency across all assets. \n\nTo accomplish classification using tags in your AWS environment, you have the following options: \n\n* Using the Amazon console, at resource level, where tags can be added either at creation or after, \n* Programmatically, using the Amazon API, AWS CLI, or AWS SDK. \n\nAccording to the AWS documentation, restrictions regarding tags include: \n\n* There cannot be more than 50 tags per resource, \n* Each tag key must be unique for each resource, \n* The maximum key length is 128 Unicode characters in UTF-8, \n* The maximum value length is 256 Unicode characters in UTF-8. \n\n### 2. Encryption \n\nEncryption is the process of altering data in order to hide its content and ensure confidentiality because entities that do not have the decryption key cannot decrypt the data and, therefore, cannot read its content. \n\nThe two types of encryption mechanisms are: \n\n* **Symmetric encryption**, where the encryption and the decryption key are the same, and \n* **Asymmetric encryption**, where the two keys are different; one is called public key and the other private key. \n\nEncryption can be done in all three states of data: \n\n* [At rest,](https://cyscale.com/blog/protecting-data-at-rest/) \n* In transit, \n* In use. \n\nIn this article, we will discuss data encryption in the first two states, but [a more detailed article](https://cyscale.com/blog/types-of-encryption/) regarding encryption also describes encryption in the last state of data. \n\nFor data in transit, AWS provides the following solution: \n\n1. Encrypt the data using SSL/TLS. TLS (Transport Layer Security) and SSL (Secure Sockets Layer) are transport layer protocols that protect the data in transit. TLS is a newer and improved version of SSL. \n2. Perform client-side encryption. This solution requires the user to encrypt the data before uploading it to the cloud, but it is more difficult since the client has to deal with the encryption process, key management, and other services. \n\nFor data at rest, AWS provides encryption for the following services:  \n\n* Amazon EBS,  \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift,  \n* AWS Lambda, and many others. \n\nAWS uses the 256-bit Advanced Encryption Standard (AES-256) encryption algorithm, an industry-recommended standard and one of the strongest algorithms for symmetric encryption. \n\nKey management is also a very important element of data encryption. If your keys are not stored safely, then no matter how strong the encryption algorithm is, a malicious party may be able to read your data. \n\nA few best practices regarding encryption keys are: \n\n* Do not store your keys in the same place as your data or in the source code, \n* Rotate and retire keys regularly to minimize the impact of a breach, \n* Manage key deletion, \n* Use Cryptographically Secure Random Number Generators (CSRNGs) to generate your keys. \n\nAWS KMS (AWS Key Management System) is a comprehensive solution that helps users deal with all the trouble that comes with cryptographic keys. \n\nAWS KMS helps you: \n\n* Create cryptographic keys, \n* Define policies and control how the keys are used, \n* Audit the keys usage to ensure they are used legitimately. \n\nAccording to AWS, this service can be used: \n\n1. Through the AWS Management Console, \n2. Using the AWS KMS APIs. \n\n### 3. Access control \n\nRegulating access control is an essential step to your [cloud data security](https://cyscale.com/blog/cloud-data-security-guide/) program.  \n\nTo manage access control in AWS, you can use policies, which can be assigned at the following levels: \n\n* Users, \n* Groups of users, \n* Roles, \n* Resources. \n\nPolicies define permissions. To correctly implement them, use the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/) to only allow access rights to the necessary users for the minimum amount of time possible.  \n\nLet’s look at an example where a policy is applied to a resource.  \n\nAn AWS S3 bucket is a type of asset used to store object-like data such as files, databases, and other unstructured data. \n\nA bucket policy contains rules based on which access is allowed or denied and is written in JSON.  \n\n```jsonld\n{\n    \"Version\": \"2012-10-17\",\n    \"Id\": \"S3PolicyId1\",\n    \"Statement\": [\n        {\n            \"Sid\": \"IPAllow\",\n            \"Effect\": \"Deny\",\n            \"Principal\": \"*\",\n            \"Action\": \"s3:*\",\n            \"Resource\": [\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET\",\n                \"arn:aws:s3:::DOC-EXAMPLE-BUCKET/*\"\n            ],\n            \"Condition\": {\n                \"NotIpAddress\": {\n                    \"aws:SourceIp\": \"54.240.143.0/24\"\n                }\n            }\n        }\n    ]\n}\n```\n\n*Policy source – docs.aws.amazon.com* \n\nAnalyzing the image above, we understand that the policy is applied to a bucket resource, the rule for the permission is “Deny”, and the result of the bucket policy is denying access to the objects stored in the specified bucket unless the requests are made with source IPs in the subnet 54.240.143.0/24. \n\n### 4. Data loss prevention \n\nData loss prevention (DLP) is a protection mechanism for sensitive data that ensures that no unintentional or malicious disclosures occur. DLP prevents data breaches by ensuring no confidential data is accidentally leaked, lost, or stolen. \n\n**Amazon Macie** is a data security and privacy service that protects users’ sensitive data using machine learning technologies and pattern matching. \n\nThis tool identifies sensitive data using **sensitive data discovery jobs**, which analyze S3 buckets. Sensitive data discovery jobs use pre-defined or user-defined lists (or a combination of both) to single out confidential data by matching patterns to the lists. \n\nA passport number is an example of sensitive data that Amazon Macie could match. This is because it has a set number of digits, some corresponding to the owner's region or country. \n\nAfter identifying sensitive data, Amazon Macie can: \n\n* use IAM policies to filter traffic to it,  \n* encrypt and decrypt data,  \n* perform logging and monitoring through AWS CloudTrail integration, and others.  \n\n### 5. Availability \n\nAvailability means that users should be able to access their data without disruptions at any point. \n\nA solution for availability in the cloud is **availability zones**. \n\nAn availability zone is a geographical area where groups of data centers are located. These data centers contain replicated data and provide redundancy regarding electrical power, networking, and connectivity. \n\nAn AWS region contains multiple AWS availability zones, all within 100km of each other, which are independent and provide redundancy. \n\nSome AWS regions around the globe are: \n\n* North America,  \n* South America, \n* Europe,  \n* China,  \n* South Africa, and others. \n\nThese regions provide high availability. \n\nAnother solution for availability is DDoS Protection. DDoS (Distributed Denial of Service) attacks are attempts to bring down a service or a resource by sending a large amount of traffic to them using controlled machines. \n\nAWS Shield is the AWS DDoS Protection service that protects applications hosted in the cloud. \n\nAWS Shield has two tiers: \n\n* Standard, \n* Advanced. \n\nBesides the features that come with the Standard plan, which are at network and transport layer, the Advanced tier of AWS Shield provides: \n\n* integration with AWS WAF (Web Application Firewall), \n* real-time visibility into attacks,  \n* additional detection and mitigation of sophisticated DDOS attacks, and others. \n\n## Secure your cloud environment \n\nAfter understanding the security demands required for the cloud, implementing them seems like a daunting task. However, using Cyscale, you can easily check if you’re lacking any of the mentioned implementations and remediate any findings. \n\nCyscale has over 400 controls that cover a large variety of misconfigurations and vulnerabilities and offer support not only for AWS, but for Azure, Google Cloud, Alibaba Cloud as well. \n\n\n\nEnhance your AWS cloud data security with our [Cloud Security Platform](https://cyscale.com/) to automate the contextual analysis of misconfigurations, vulnerabilities, access, and data for an accurate risk assessment. With over 400 controls, we ensure optimal [AWS security compliance](https://cyscale.com/use-cases/aws-cloud-security/).\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Understanding S3 Bucket Security – A Contextual Approach","seoTitle":"Understanding S3 Bucket Security – A Contextual Approach","description":"An Amazon S3 bucket is a storage cloud asset that acts as a container for data stored in the public cloud. Buckets are object storage services and are similar to folders; this type of storage is flexible and scalable and is ideal for large files and unstructured data. To secure a bucket, restrict public access to it, perform at rest and in transit encryption, log user actions, and perform regular backups.","seoDescription":"An Amazon S3 bucket is a storage cloud asset that acts as a container for data stored in the public cloud. Buckets are object storage services and are similar to folders; this type of storage is flexible and scalable and is ideal for large files and unstructured data. To secure a bucket, restrict public access to it, perform at rest and in transit encryption, log user actions, and perform regular backups.","date":"2022-09-16T08:07:20.546Z","featuredpost":true,"permalink":"s3-bucket-security","featuredimage":{"publicURL":"/static/de7396bc58775c924174c3c9f2467bbe/23_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/de7396bc58775c924174c3c9f2467bbe/888e2/23_blog-cover-photo.webp","srcSet":"/static/de7396bc58775c924174c3c9f2467bbe/913d0/23_blog-cover-photo.webp 205w,\n/static/de7396bc58775c924174c3c9f2467bbe/91660/23_blog-cover-photo.webp 410w,\n/static/de7396bc58775c924174c3c9f2467bbe/888e2/23_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->  \n\nIn 2017, 4 million records with customer information, login credentials, and source code were made publicly available due to 2 unsecured AWS S3 storage buckets owned by Time Warner Cable. \n\nThe consequences of this attack were disastrous, and this event showed the entire cloud industry how important security is. \n\n\n\nIn this article, we will learn more about Amazon S3 buckets, misconfigurations and vulnerabilities, and how to secure them.\n\n## What is an Amazon S3 bucket?  \n\nAn Amazon S3 bucket is a storage cloud asset that acts as a container for data stored in the public cloud. Buckets are object storage services and are similar to folders; this type of storage is flexible and scalable and is ideal for large files and unstructured data. \n\n## Common S3 Bucket Misconfigurations \n\n### 1. Public access to a bucket is allowed. \n\nSometimes, Amazon S3 buckets are required to be publicly accessible. For example, this use case occurs when the owner intends to make data accessible to the internet.  \n\nHowever, breaches occur when a bucket that has sensitive information such [as PII (Personal Identifiable Information)](https://cyscale.com/blog/protecting-pii-in-the-cloud/) allows: \n\n* Public “READ” access, \n* Public “WRITE” access.  \n\nYou can grant and deny access to a bucket using **access lists** and **bucket policies**.  \n\nAn access control list (ACL) is a set of rules that limit access to buckets through permissions. It defines an account's access level over a bucket (for example, READ or WRITE).  \n\nA bucket policy also contains rules based on which access is allowed or denied, but it is a more modern solution because it can enable more complex filtering. It is a JSON-based access policy language. \n\nAmazon recommends that you no longer use ACLs beside special cases, in which you need to filter access to objects individually.  \n\n### 2. No at rest encryption is performed. \n\n[Data at rest](https://cyscale.com/blog/protecting-data-at-rest/) should always be encrypted to ensure confidentiality and improve your cloud data security.  \n\nPerforming encryption on the objects inside a bucket ensures that, even if a malicious entity gains access to your data, they cannot read it.  \n\nAWS provides multiple encryption options to protect data at rest. For example, you can enable default encryption and set it, so it automatically encrypts any new objects added to the bucket.  \n\nEncryption should be done using industry-recommended algorithms and strong cryptographic keys. A strong encryption algorithm is AES-256 (Advanced Encryption Standard with a key of 256 bits). \n\n### 3. In transit encryption is not enabled. \n\nBesides the data that is already stored, you should also encrypt the data that travels to and from the S3 bucket.  \n\nThis step prevents eavesdropping attacks. It is not enough to store your data encrypted. Your efforts are wasted if it travels in plain text and attackers can read it. \n\nData in motion can be encrypted using SSL/TLS. TLS (Transport Layer Security) and SSL (Secure Sockets Layer) are transport layer protocols that protect the data in transit. TLS is a newer and improved version of SSL. \n\nAnother solution for in motion encryption is preparing the data that is to be transported by encrypting it on the client-side. \n\n### 4. Logging is disabled. \n\nLogging an S3 bucket is an essential step in securing your data. With logging, you can record actions taken by users, keep log files for compliance purposes and understand what roles have permission to access data inside a bucket. \n\nThere are two solutions for AWS bucket logging: \n\n* Server access logging, and \n* AWS CloudTrail. \n\nWith server access logging, you obtain detailed records regarding requests that are made to a bucket. \n\nAWS CloudTrail is a comprehensive service that tracks user activity and API calls. It can be used to keep a record of who sends requests to a bucket.  \n\nIt is important to keep in mind that AWS CloudTrail does not log failed authentication attempts through incorrect credentials. However, it does track requests made by anonymous or unauthorized users. \n\n### 5. No regular backups are performed \n\nAttackers may not only try to steal your sensitive data, but they can also delete it. Therefore, ensuring regular and consistent backups is essential to configuring your buckets and providing availability. \n\nUsing AWS Backup, you can perform S3 bucket backups. Amazon supports the following types of backups: \n\n* **Continuous backups**, which allow data restoration from any moment in the last 35 days, \n* **Periodic backups**, which can be performed every 1 hour, 12 hours, or less often. \n\nAn important feature of AWS Backup is that [tags](https://cyscale.com/blog/data-classification/), access control lists, and other metadata are also saved along with your data. \n\nAn additional layer of security can be added by using the MFA delete feature in AWS. This option requires a successful MFA before allowing a user to delete an object or bucket. \n\nMoreover, you can keep multiple versions of an object inside a bucket. This process is called versioning and can be used to recover objects from accidental deletion. \n\n## Do you have a complete cloud security program? \n\nIn this article, we’ve discussed many possible misconfigurations, along with best practices. However, in order to fully understand your public cloud infrastructure and find vulnerabilities, you need to have good visibility over your cloud environment.  \n\nUsing a new feature in Cyscale, the bucket graph, you can put in context all of your knowledge and grasp a better understanding of your infrastructure. \n\nBelow, you can see an example of a bucket graph. \n\n![Bucket Graph in Cyscale](/img/23_blog-graph-bucket.webp#shadow \"Bucket Graph in Cyscale\")\n\nAlthough the bucket (shown on the right) has only two IAM policies attached, we can see that these have a significant impact on the infrastructure: the AmazonS3FullAccess policy gives full access rights to a specific user and to a VM that can assume an associated IAMRole.  \n\nIn addition, there's a lambda function that has a role which gives it permissions to perform actions on the bucket \n\nWithout context, we would not be able to understand a policy's impact and the associated risk. \n\nMoreover, the icon on the right shows us that the bucket violates three policies. Cyscale users can click on the icon and obtain more details regarding this alert. \n\nThis feature helps you quickly understand and fix any misconfigurations and vulnerabilities introduced in the cloud environment due to the bucket’s settings. \n\n  \n\nBesides the graph, you can also use controls to check your cloud configurations easily. Find any gaps in your buckets' configurations using Cyscale controls! Here are a few examples that can help you instantly check the most common misconfigurations regarding S3 buckets: \n\n* *Ensure S3 bucket ACL grants permissions only to specific AWS accounts* \n* *Ensure all S3 buckets employ encryption-at-rest* \n* *Ensure a log metric filter and alarm exist for S3 bucket policy changes* \n* *Ensure that there are no publicly accessible objects in storage buckets* \n\n \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"A Guide to Cloud Security Best Practices","seoTitle":"A Guide to Cloud Security Best Practices","description":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","seoDescription":"When it comes to data stored in the cloud, you must consider multiple aspects such as encryption, access control, backups, and how these map to the CIA triad. This article will cover the main mechanisms to ensure proper data security in the cloud, whether you are using AWS, Google Cloud, or Azure.","date":"2022-09-01T10:59:21.743Z","featuredpost":true,"permalink":"cloud-data-security-guide","featuredimage":{"publicURL":"/static/ede7e98a6093188a6e7edee54d1956fd/21-cover-01-min.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp","srcSet":"/static/ede7e98a6093188a6e7edee54d1956fd/913d0/21-cover-01-min.webp 205w,\n/static/ede7e98a6093188a6e7edee54d1956fd/91660/21-cover-01-min.webp 410w,\n/static/ede7e98a6093188a6e7edee54d1956fd/888e2/21-cover-01-min.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"In the ever-evolving landscape of digital security, understanding and implementing a robust **[cloud security strategy](https://cyscale.com/blog/cloud-security-strategy-best-practices-tutorials/)** is crucial. This guide provides insights into best practices that are integral to this strategy.\n\nData security is one of the biggest concerns of cloud-based organizations. When you think about protecting data, you need to make sure you’re providing the following features:\n\n* Confidentiality,\n* Integrity,\n* Availability.\n\nMoreover, these three security principles need to be implemented for all three states of data, which are:\n\n* In motion,\n* In use,\n* At rest.\n\nThis mission may seem daunting. Let’s break it down and understand every step of the process of securing data. In this article, you will find out:\n\n* The type of attacks that threaten your data,\n* Cloud security best practices,\n* Security solutions on the market from cloud service providers,\n* How to identify any gaps in your security policies.\n\n## **How do you ensure confidentiality?**\n\nConfidentiality is a security principle that states that only authorized users should be able to access the data. It should not be visible to unauthorized entities.\n\n### **Encryption**\n\n[Encryption](https://cyscale.com/blog/types-of-encryption/) is the process of scrambling data to obtain unreadable ciphertext. The algorithm uses a key to encrypt it, and if you are not in possession of the decryption key, you cannot reverse it back to its original state.\n\nEncryption solutions for the three states of data are: \n\n* For in motion data: SSL/TLS. They are transport protocols that encrypt data in transit. \n* For in use data: memory encryption, called Secure Encrypted Virtualization (SEV). It requires specialized hardware, and it encrypts RAM memory. \n* [For at rest data:](https://cyscale.com/blog/protecting-data-at-rest/) industry-recommended symmetric algorithms such as AES-256 are used to perform full disk, database, file system, and cloud assets encryption and to safely store data. \n\nUsing these best practices, you can improve your cloud security posture and prevent data breaches or other security incidents.\n\n### **Access control** \n\nA layered approach should be used when securing data in the cloud. This is where a robust **[cloud infrastructure security](https://cyscale.com/blog/cloud-infrastructure-security/)** becomes crucial. This means that encryption of data at rest should only be considered as the last measure of protection if access control rules are bypassed. \n\nYou must secure access to databases, buckets, and other storage assets by restricting it as much as possible. In doing this, you become compliant with the [Least Privilege Principle](https://cyscale.com/blog/check-for-least-privilege/). \n\nA few access control best practices for [database protection](https://cyscale.com/blog/best-practices-for-securing-databases/) are:\n\n* Filter inbound and outbound traffic,\n* Secure your database connection,\n* Keep your connection details secret.\n\nFor [buckets that contain sensitive information](https://cyscale.com/blog/common-cloud-misconfigurations-how-to-avoid-them/#storage-access), do not allow public read/write access and use access control lists to define granular rules.\n\nBesides access control, to ensure robust data protection, strong authentication mechanisms should be put in place. Multi-factor authentication (MFA) is a must-have security measure for cloud computing environments.\n\nBy implementing these IAM (Identity and Access Management) best practices, attack surface is reduced and your cloud infrastructure is secured.\n\n### **Data classification**\n\nClassifying data does not protect it on its own. However, this process can help you understand which is the most sensitive data in order to better focus your efforts to secure it.\n\nAWS (Amazon Web Services), Azure, and Google Cloud provide labels or tags for users to implement [data classification](https://cyscale.com/blog/data-classification/). Labels/tags can be predefined by the public cloud vendor or can be user-defined according to the user’s specific needs.\n\n## **How do you ensure integrity?**\n\nEnsuring integrity means that data must not be altered in transit or at rest. Integrity is usually accomplished using hashes and checksums.\n\nThey are computed before the data is used or transferred and then again after. If the two values of hashes/checksums match, then the data was not altered in transit or at rest. Otherwise, that data was tampered with.\n\nLet’s look at public cloud vendors and how they provide data integrity services:\n\n* AWS S3 uses CRC32, CRC32C, SHA-1, and SHA-256 to check the data integrity after uploading/downloading,\n* Google Cloud also uses CRC32C checksums to verify data integrity.\n\n## **How do you ensure availability?**\n\nData availability means that any user should be able at any point to access their data without disruptions.\n\nFor data in the public cloud, vendors provide solutions to replicate and backup it in different data centers and regions.\n\nWe need to look at **availability zones** to understand availability in the cloud.\n\nAvailability zones are groups of data centers in the same region containing replicated data. If a data center fails, the other data center in the availability zone takes the responsibility, providing fault tolerance and increased availability and preventing data loss.\n\nMoreover, public cloud vendors support region pairs. A region is paired with another region at a great distance (for example, at least 300km away for Azure). If a natural disaster, civil unrest, or any other unforeseen events occur, the secondary region becomes the main source of cloud service.\n\nAnother service available in the public cloud that helps ensure availability is **DDOS protection**.\n\nDDOS (Distributed Denial of Service) is an attack designed to crash an application or a service by sending substantial amounts of traffic to it.\n\nA few examples of available DDOS services to secure cloud infrastructure are:\n\n* AWS Shield,\n* Azure DDOS Protection,\n* Google Cloud Armor.\n\n**Implementing our recommendations**\n\nEnsuring [multi-cloud data security](https://cyscale.com/use-cases/cloud-data-security/) is not an easy task. There are many aspects to be considered, and a small mistake can leave a vulnerability in your cloud environment.\n\nCyscale provides powerful dashboards to ensure visibility of your assets, the identities in your cloud, and an overview of your data security.\n\nMoreover, 400+ security controls ensure that your security teams have implemented the cybersecurity principles and best practices. Here are some examples of controls that can be used to ensure data security:\n\n* **In motion data encryption**: *Ensure web app is using the latest version of TLS encryption* for Microsoft Azure\n* **At rest data encryption**: *Ensure VM disks for critical VMs are encrypted with Customer*-Supplied Encryption Keys (CSEK) for Google Cloud\n* **Access control**: *Ensure S3 bucket policy does not grant Allow permission to everyone* for AWS\n* **Data classification**: *Ensure Kubernetes Clusters are configured with Labels* for Google Cloud\n* **DDOS Protection**: *Ensure Anti-DDoS access and security log service is enabled* for Alibaba Cloud\n\nBefore diving into specific controls, it's essential to acknowledge the evolving **[cloud security challenges](https://cyscale.com/blog/cloud-security-challenges/)** that businesses face. With a constantly changing digital landscape, understanding these challenges can help shape your security strategies more effectively."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Best Practices for Securing Databases in the Cloud ","seoTitle":"Best Practices for Securing Databases in the Cloud ","description":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","seoDescription":"A database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  Best practices to protect a database are: filter inbound and outbound traffic, ensure availability through redundancy, encrypt your database, secure your database connection, keep your connection details secret, log connection attempts, and perform regular database backups. Keep RPO and RTO at a minimum to ensure high availability and protect your data.","date":"2022-08-26T07:19:11.434Z","featuredpost":true,"permalink":"best-practices-for-securing-databases","featuredimage":{"publicURL":"/static/79c9688bfcbf26210f6ca16250401cb0/20_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp","srcSet":"/static/79c9688bfcbf26210f6ca16250401cb0/913d0/20_blog-cover-photo.webp 205w,\n/static/79c9688bfcbf26210f6ca16250401cb0/91660/20_blog-cover-photo.webp 410w,\n/static/79c9688bfcbf26210f6ca16250401cb0/888e2/20_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nA database is one of the most important cloud assets. It usually stores sensitive information that should be well protected.  \n\nWhen we’re discussing databases in the cloud, there are two options for users. They can: \n\n* manage their own database in the cloud, or \n* use a service provided by their cloud vendor. \n\nThe latter is usually the easier choice since the cloud vendor takes care of security features.  \n\nHowever, your database may be vulnerable in both cases if you don’t configure your environment correctly. \n\nIn this article, we will look at best practices for securing databases in the cloud and how to identify any misconfigurations and vulnerabilities that may exist or appear in the future. \n\n## Best practices \n\n### 1. Filter inbound and outbound traffic. \n\nManaging traffic to and from the database is the first layer of database protection. Place databases behind firewalls and restrict the traffic allowed to reach them as much as possible. \n\nYou can implement more granular rules by only allowing a list of known IPs to connect to a database (for example, the range of addresses specific to a known data center), or by filtering traffic based on other criteria. \n\nMoreover, you can apply conditional access for users when administering the database. You can ask for additional security checks like Multi-Factor Authentication to ensure the entities managing the database are legitimate. \n\n### 2. Ensure availability through redundancy \n\nWhen deploying a database in the public cloud, you have the option to ensure availability through redundancy. You can replicate a database in different data centers and even different geographical regions. \n\nIf one data center or region fails, you can rely on a replication of the database located in a different data center to work. \n\n### 3. Encrypt your database \n\nDatabase [encryption](https://cyscale.com/blog/protecting-data-at-rest/) is important for protecting your data at rest.  \n\nEnsure that only authorized entities can see the data you’re storing in the database by [encrypting it ](https://cyscale.com/blog/protecting-data-at-rest/)with a strong, recommended algorithm such as AES-256. Keep your encryption keys safe by storing them separately from the data, use strong generation algorithms and rotate them every 90 days or less. \n\n### 4. Secure your database connection \n\nNot only data at rest is vulnerable. When you're transferring data to and from the database, it is essential to encrypt your traffic.  \n\nThis is called encryption for data in transit and is implemented with the TLS/SSL protocols. \n\n### 5. Keep your connection details secret \n\nDo not disclose database connection strings, keys, certificates, and other secrets that may be used to breach your database. You can use cloud solutions to keep your cryptographic secrets safe: \n\n* [Azure](https://cyscale.com/use-cases/azure-cloud-security/) Key Vault, \n* [AWS ](https://cyscale.com/use-cases/aws-cloud-security/)Key Management Service (AWS KMS), \n* [Google Cloud ](https://cyscale.com/use-cases/gcp-cloud-security/)Secret Manager, \n* dedicated hardware devices such as Hardware Security Modules (HSM), and others. \n\n### 6. Log connection attempts \n\nKeep track of who is trying to connect to your database by logging any authentication attempts. In this way, you can see if: \n\n* someone unauthorized is trying to or is connecting to the database, \n* there is a brute-force attack taking place.  \n\n### 7. Perform regular database backups \n\nDatabases should be backed up regularly, to prevent loss of data, in the case of: \n\n* Data corruption, and \n* Ransomware attacks. \n\nAlthough ransomware attacks are less common in cloud environments at the moment, attackers could in time develop the proper tactics. \n\n![RPO and RTO](/img/20_blog-rpo-and-rto.webp#shadow \"RPO and RTO\")\n\nThe time between the backups is known as RPO (Recovery Point Objective). It is measured as the time that passed between the last backup and the current one. If a disaster appears, the data written in that time is lost. \n\nRTO (Recovery Time Objective) is the time it takes for an application to go back online after a disaster and to restore its data.   \n\nRTO and RPO should be kept in acceptable limits. \n\n \n\nIt is difficult to ensure you’re implementing all the best practices we mentioned in this article. [Cyscale ](https://cyscale.com/)has over 400 controls that can help you secure your entire cloud environment. \n\nHere are some examples of controls that check for any misconfigurations and vulnerabilities regarding your database setup in the public cloud: \n\n* *Ensure encrypted storage is used for VMs that might host a database* for AWS \n* *Ensure no SQL Databases allow ingress 0.0.0.0/0 (ANY IP)* for Microsoft Azure \n* *Ensure that Cloud SQL database instances are configured with automated backups* for Google Cloud \n* *Ensure that Cloud SQL database instances require all incoming connections to use SSL* for Google Cloud \n* *Ensure parameter 'log_connections' is set to 'ON' for PostgreSQL Database* for Alibaba Cloud \n\nAlong with these controls that alert you on any findings, you receive remediation steps to quickly eliminate any vulnerabilities and secure your database in the cloud. \n\n \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Protecting Data at Rest Using Encryption  ","seoTitle":"Protecting Data at Rest Using Encryption  ","description":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.\n\n","seoDescription":"Data at rest is data that is not currently used or transmitted between computer systems.  This state of data is usually the most sought-for by attackers. You need to encrypt data to keep it confidential. To encrypt data, use industry-recommended algorithms, manage your keys by storing them in key vaults and rotating them.","date":"2022-08-20T07:06:54.032Z","featuredpost":true,"permalink":"protecting-data-at-rest","featuredimage":{"publicURL":"/static/4c004ae5409e8873ac3b77d3e3668417/19_blog-cover-photo.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp","srcSet":"/static/4c004ae5409e8873ac3b77d3e3668417/913d0/19_blog-cover-photo.webp 205w,\n/static/4c004ae5409e8873ac3b77d3e3668417/91660/19_blog-cover-photo.webp 410w,\n/static/4c004ae5409e8873ac3b77d3e3668417/888e2/19_blog-cover-photo.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nData at rest is data that is not currently used or transmitted between computer systems.  \n\nThis state of data is usually the most sought-for by attackers. Data at rest can be stored in: \n\n* Storage cloud assets such as buckets, \n* Databases, \n* Files, and others. \n\nThe most common method of protecting data at rest is through [encryption](https://cyscale.com/blog/types-of-encryption/). In this article, we will look at ways to perform encryption and understand its importance. \n\n## Why is it important to encrypt data at rest? \n\nThere are three main risks regarding data at rest: \n\n* loss,  \n* leakage,  \n* theft. \n\nIn all three cases, your data at rest will probably end up in somebody’s hands. You can forget your USB drive in a coffee shop, you can accidentally disclose your data to someone else or the public or it can be stolen by a malicious attacker. \n\nFor these reasons, a safeguarding mechanism is encrypting your data. \n\nWith this method, even if someone else gets ahold of your data, they will not be able to read it. \n\n## Client-side and server-side encryption \n\nClient-side encryption is done on a local device with the user's key. \n\nServer-side encryption is implemented in the cloud, and the cloud vendor usually takes care of the key. This method of encryption is easier to use, since the cloud provider takes care of the algorithm, the key management system, and other troubles you may have. \n\nIn this article, we will look at best practices for client-side encryption, as well as solutions offered for server-side encryption.  \n\n## How do you encrypt data at rest? \n\nThere are a few best practices that need to be considered when undergoing the encryption process: \n\n### 1. Use an industry-recommended standard with an appropriate key length. \n\nFor data at rest, symmetric encryption algorithms are usually used. An industry-recommended standard is AES-256 (Advanced Encryption Standard with a key of 256 bits). \n\n### 2. Classify data and decide what to encrypt. \n\nMake sure you don’t leave any sensitive data unencrypted. Use [data classification](https://cyscale.com/blog/data-classification/) to decide what data should be encrypted.  \n\nAlternatively, perform full disk encryption to protect all data, especially in case you lose the hardware. \n\n## Key management \n\nNow that we’ve established how to encrypt data at rest, let’s talk keys.  \n\nIf your key management is poor, no matter how strong and well-done an encryption is, it can become totally useless. \n\nFollow the best practices we’re recommending to ensure textbook key management.  \n\n### 1. Use a random key generation algorithm for your keys.  \n\nMost random number generator algorithms are not truly random; they are called Pseudo-Random Number Generators (PRNGs).  \n\nIf you’re using programmatic functions such as random() or rand() from C++, Java, and other languages, you’re not generating random keys; they use a seed (which always gives the same result), can be predicted, and are not for cryptographic usage. \n\nFor this reason, you need to use tools that utilize Cryptographically Secure Random Number Generators (CSRNGs). \n\nTo generate a random, secure key, you can use: \n\n* [GenerateRandom](https://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateRandom.html), a tool provided by AWS, \n* the [GenerateRandomBytes](https://cloud.google.com/kms/docs/generate-random) API from Google Cloud, \n* [SecureRandom](https://docs.oracle.com/javase/8/docs/api/java/security/SecureRandom.html), a class from Java, and others. \n\n### 2. Store your keys separately from your ciphertext. \n\nDo not store your keys in the same place as encrypted data, and do not hardcode them in the source code. You can use: \n\n* dedicated hardware devices such as Hardware security modules (HSM), \n* key management systems such as Azure Key Vault and AWS KMS, \n* open source KMS such as HashiCorp Vault. \n\n### 3. Rotate the keys. \n\nChange the keys regularly (every 90 days or less). This process involves retiring an encryption key and generating a new one. \n\nMoreover, if a key is compromised, immediately replace it and assess which data is at risk. \n\n### 4. Implement access control for keys \n\nEnsure that access to keys is heavily restricted in the following ways: \n\n* [Implement the Least Privilege Principle.](https://cyscale.com/blog/check-for-least-privilege/) Only the individuals that need the keys should be able to access them. You can also implement time windows when keys can be accessed. \n* Only authorized personnel should be able to access keys. Ensure that, after you’ve granted access rights to people, only they can see and use the keys. \n\n###  5. Manage key deletion \n\nIf a key is permanently deleted, all data encrypted with that key is lost. The key should be appropriately destroyed after all the encrypted data is decrypted and re-encrypted with a new key. \n\nSolutions from cloud vendors for safe key deletion are: \n\n* Soft delete in Azure Key Vault, \n* Key deletion scheduling in AWS. \n\n## Server-side encryption - cloud solutions \n\nAWS, Azure, and Google Cloud provide data at rest encryption and key management solutions. Let's look at the available options and how to make sure you're using them correctly. \n\n### Encryption in AWS \n\nThe following services in AWS support data at rest encryption capabilities: \n\n* Amazon EBS, \n* Amazon S3,  \n* Amazon RDS,  \n* Amazon Redshift, \n* AWS Lambda, and many others. \n\nKey management is done using the AWS Key Management Service, which allows users to utilize their own keys or let AWS deal with them. \n\n### Encryption in Azure \n\nIn Microsoft Azure, users have the following options: \n\n* Azure Disk Encryption, for Virtual Machines, \n* Azure Storage and Azure SQL Database, which encrypt all data at rest. \n\nFor key management, Azure provides the following services: \n\n* Azure Key Vault, \n* Vault Managed Hardware Security Model (HSM). \n\n### Encryption in Google Cloud \n\nFor key management, Google Cloud provides the Google Key Management Service. As an additional layer of security, the encryption key, named DEK (Data Encryption Key), is also encrypted using a KEK (Key-encryption key).  \n\n## How do you check for encryption misconfigurations? \n\nAs we’ve seen, there are many best practices to be considered, and therefore there is room for mistakes. \n\nYou can quickly [check for misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/) regarding data at rest encryption in the cloud using Cyscale’s controls. Here are a few examples of controls that check if you’re implementing the best practices described in this article: \n\n* *Ensure all S3 buckets employ encryption-at rest* for AWS \n* *Ensure storage for critical data are encrypted with Customer Managed Key* for Microsoft Azure, \n* *Ensure EBS encryption by default is enabled* for AWS, \n* *Ensure CloudTrail logs are encrypted at rest* for AWS. \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM","Product"],"title":"How to Check for Least Privilege with Cyscale’s New Identity Dashboard ","seoTitle":"How to Check for Least Privilege with Cyscale’s New Identity Dashboard ","description":"The Least Privilege Principle states that no user should be given more permissions and for more time than they require for their day-to-day tasks. Compliance with the Principle of Least Privilege (PoLP) is a security best practice in cloud security that should be implemented in all cloud environments. In order to implement PoLP, you must use timed privileges, set up minimum permissions to add more on the go and remove or disable identities that haven’t been active in the last 30 days or more. ","seoDescription":"The Least Privilege Principle states that no user should be given more permissions and for more time than they require for their day-to-day tasks. Compliance with the Principle of Least Privilege (PoLP) is a security best practice in cloud security that should be implemented in all cloud environments. In order to implement PoLP, you must use timed privileges, set up minimum permissions to add more on the go and remove or disable identities that haven’t been active in the last 30 days or more. ","date":"2022-08-15T05:45:35.102Z","featuredpost":true,"permalink":"check-for-least-privilege","featuredimage":{"publicURL":"/static/fbc039617d686e9adb5447d24c4ef5e3/blog_18-cover.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/fbc039617d686e9adb5447d24c4ef5e3/888e2/blog_18-cover.webp","srcSet":"/static/fbc039617d686e9adb5447d24c4ef5e3/913d0/blog_18-cover.webp 205w,\n/static/fbc039617d686e9adb5447d24c4ef5e3/91660/blog_18-cover.webp 410w,\n/static/fbc039617d686e9adb5447d24c4ef5e3/888e2/blog_18-cover.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nThe Least Privilege Principle states that no user should be given more permissions and for more time than they require for their day-to-day tasks. \n\nCompliance with the Principle of Least Privilege (PoLP) is a security best practice in cloud security that should be implemented in all cloud environments. \n\n## How do you implement Least Privilege? \n\n* Use timed privileges; only assign privileges in the moments they are needed and revoke them after. \n* Set up minimum permissions and add more on the go, if necessary. \n* Remove or disable identities that haven’t been active in the last 30 days or more. \n\n## Cyscale can help you implement the Principle of Least Privilege \n\nWith a new, powerful identity dashboard, Cyscale helps you improve the visibility of your cloud identities and pinpoint vulnerabilities or misconfigurations. \n\nUsing this page, you can see your organization's identities and their level of access. \n\nEntities that do not have permissions in the cloud but have an account are marked with the “No Access” tag on the right. \n\n![No access permissions in dashboard](/img/blog_18-1.webp#shadow \"No access permissions in dashboard\")\n\nMoreover, people who have left the organization are also visible on this dashboard. It is essential to know which entities have left to ensure you have a complete offboarding process and that they no longer have permissions. \n\nIf we expand a card of an identity that no longer exists in the company, we see that their account is disabled because it is greyed out. \n\n![Disabled identity](/img/blog_18-2-disabled-identity.webp#shadow \"Disabled identity\")\n\nTo understand an identity's impact on the entire organization's environment, you must have comprehensive visibility.  \n\nThe following image shows that the analyzed user has accounts in Alibaba, AWS, Azure, Google Cloud, and Okta. Furthermore, we can see that they are part of the \"**Admins**\" group, as well as others, and as a result, are \"**Highly Privileged**”. \n\n![Highly privileged identity](/img/blog_18-3-andrei-stefanie.webp#shadow \"Highly privileged identity\")\n\nIf we expand each account’s card, we can see the environment they have access to. Besides tracking permissions, it is crucial to also track the actual environments each user has access to. In the cloud, this tends to quickly become hard to track because applications often span multiple accounts. \n\n<br/>\n\nBeing highly privileged is not necessarily an issue, however, combining it with the lack of MFA does become a problem. Cyscale highlights this situation. This can be seen immediately after expanding a person’s card, so the vulnerability is not missed. \n\nIn this example, the user’s Okta account does not have MFA. [Okta is an identity and access management (IAM) service](https://cyscale.com/blog/provide-visibility-in-cloud-okta-integration/) where you can onboard your accounts, which helps you manage your organization’s access to other applications through SSO. \n\nIn the image below, you can see the accounts assigned using Okta. Therefore, if there is a vulnerability in your Okta account, all those accounts may be compromised. \n\n![Okta identity](/img/blog_18-4-okta.webp#shadow \"Okta identity\")\n\nAnother useful feature of the Identity Dashboard is the “Alerts” section. If an account has security alerts, the user can click on them and be redirected to the Alerts page. There, you can see failed controls along with: \n\n* Severity, \n* The asset involved, \n* The status, and others. \n\nYou can immediately pinpoint any misconfigurations and vulnerabilities using these alerts and quickly solve them with the remediation steps provided. \n\nBesides visibility, Cyscale provides controls that automatically check for misconfigurations. \n\nThere are over 400 controls currently available in Cyscale. A few examples of controls that verify you’re implementing the Least Privilege Principle correctly are: \n\n* *Eliminate use of the \"root\" user for administrative and daily tasks* for AWS \n* *Ensure that ServiceAccount has no Admin privileges* for Google Cloud Platform \n* *Ensure IAM policies that allow full \"\\*:\\*\" administrative privileges are not created* for AWS \n* *Ensure IAM Users that are inactive for 30 days or more are deactivated* for AWS \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Types of Encryption for in Motion, in Use, at Rest Data ","seoTitle":"Types of Encryption for in Motion, in Use, at Rest Data ","description":"Encryption is the process of altering data in order to hide its content and ensure confidentiality. Entities that do not have the decryption key in their possession cannot decrypt the data and, therefore, read its content. Encryption algorithms can be symmetric and asymmetric. When protecting data, you need to ensure you're taking in consideration all three states: in motion, in use, and at rest data.","seoDescription":"Encryption is the process of altering data in order to hide its content and ensure confidentiality. Entities that do not have the decryption key in their possession cannot decrypt the data and, therefore, read its content. Encryption algorithms can be symmetric and asymmetric. When protecting data, you need to ensure you're taking in consideration all three states: in motion, in use, and at rest data.","date":"2022-08-09T10:02:07.086Z","featuredpost":true,"permalink":"types-of-encryption","featuredimage":{"publicURL":"/static/5e96b8c90dae2186df631d9c5489b68e/blog_17-cover-image.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/5e96b8c90dae2186df631d9c5489b68e/888e2/blog_17-cover-image.webp","srcSet":"/static/5e96b8c90dae2186df631d9c5489b68e/913d0/blog_17-cover-image.webp 205w,\n/static/5e96b8c90dae2186df631d9c5489b68e/91660/blog_17-cover-image.webp 410w,\n/static/5e96b8c90dae2186df631d9c5489b68e/888e2/blog_17-cover-image.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nEncryption is the process of altering data in order to hide its content and ensure confidentiality. Entities that do not have the decryption key in their possession cannot decrypt the data and, therefore, read its content. \n\n## How does encryption work? \n\nPlaintext data is transformed, using an encryption algorithm and a secret key, to ciphertext, which is unreadable text.  \n\nThere are two types of encryption algorithms: \n\n* Symmetric,  \n* Asymmetric. \n\nIn symmetric algorithms, the key used to perform the encryption is the same as the one used to decrypt it and is, therefore, secret. \n\nExamples of symmetric algorithms are: \n\n* DES (Data Encryption Standard),  \n* 3DES (Triple DES), \n* AES (Advanced Encryption Standard). \n\nThe latter one is, in 2022, the industry standard and is recommended to be used with 128 bits keys. \n\n![Symmetric encryption](/img/blog_17-cisco_encryption.webp#shadow \"Symmetric encryption\")\n\nImage source – cisco.com \n\nAsymmetric algorithms use two different keys: a public key for encryption and a private key for decryption. \n\nAsymmetric algorithm examples are: \n\n* RSA (Rivest-Shamir-Adleman), \n* ECC (Elliptic Curve Cryptography). \n\nAsymmetric algorithms are not commonly used for encryption because they are slower. For example, the RSA algorithm requires keys between 1024 and 4096 bits, which slows down the encryption and decryption process.  \n\nThese algorithms can be used, however, to encrypt symmetric algorithm keys when they are distributed. \n\nA more common usage of asymmetric algorithms is digital signatures. They are mathematical algorithms that are used to cryptographically validate the authenticity and integrity of a message or media on the internet. \n\n## What is encryption used for? \n\nEncryption ensures confidentiality of data. The unreadable ciphertext keeps the data private from all parties that do not possess the decryption key. \n\nData has three states: \n\n* In motion, \n* In use, \n* At rest. \n\nIt is essential to understand these states and ensure that the data is always encrypted. It is not enough to encrypt data only when it is stored if, when in transit, a malicious party can still read it.  \n\nTherefore, we will look at encryption mechanisms for all three data states. \n\n### In Motion Encryption \n\nData in motion, or in transit, is data that is moved from one location to another, for example, between: \n\n* computers,  \n* services,  \n* virtual machines,  \n* applications, \n* networks.  \n\nExamples of data in motion are: \n\n* emails, \n* files, \n* messages. \n\nData in motion can be encrypted using SSL/TLS. TLS (Transport Layer Security) and SSL (Secure Sockets Layer) are transport layer protocols that protect the data in transit. TLS is a newer and improved version of SSL. \n\nSSL/TLS ensure confidentiality through encryption. Firstly, a session is created between the two parties exchanging a message using asymmetric encryption. Then, after the secure session is established, symmetric algorithms are used to encrypt the data in motion. \n\nUsing one of the mentioned protocols prevents attackers from reading the data in motion. \n\nWebsites should use HTTPS (Hypertext Transfer Protocol Secure) instead of HTTP to ensure encryption between websites and browsers. HTTPS uses SSL/TLS. \n\n**What is in motion data vulnerable to?** \n\n**Eavesdropping attacks.** In this situation, malicious entities can analyze traffic sent over the internet and read unencrypted data.   \n\n### In Use Encryption \n\nData currently accessed and used is considered in use.   \n\nExamples of in use data are: \n\n* files that are currently open, \n* databases, \n* RAM data. \n\nBecause data needs to be decrypted to become in use, it is essential that data security is taken care of before the actual use of data begins. \n\nTo do this, you need to ensure a good authentication mechanism. Technologies like Single Sign-On (SSO) and Multi-Factor Authentication (MFA) can be implemented to increase security. \n\nMoreover, after a user authenticates, access management is necessary. Users should not be allowed to access any available resources, only the ones they need to, in order to perform their job.  \n\nA method of encryption for data in use is Secure Encrypted Virtualization (SEV). It requires specialized hardware, and it encrypts RAM memory using an AES-128 encryption engine and an [AMD EPYC processor](https://developer.amd.com/sev/). Other hardware vendors are also offering memory encryption for data in use, but this area is still relatively new. \n\n**What is in use data vulnerable to?**  \n\nIn use data is vulnerable to **authentication attacks**. These types of attacks are used to gain access to the data by bypassing authentication, brute-forcing or obtaining credentials, and others. \n\nAnother type of attack for data in use is a **cold boot attack**. Even though the RAM memory is considered volatile, after a computer is turned off, it takes a few minutes for that memory to be erased. If kept at low temperatures, RAM memory can be extracted, and, therefore, the last data loaded in the RAM memory can be read. \n\n### At Rest Encryption \n\nOnce data arrives at the destination and is not used, it becomes at rest.  \n\nExamples of data at rest are: \n\n* databases, \n* cloud storage assets such as buckets, \n* files and file archives, \n* USB drives, and others. \n\nThis data state is usually most targeted by attackers who attempt to read databases, steal files stored on the computer, obtain USB drives, and others. \n\nEncryption of data at rest is fairly simple and is usually done using symmetric algorithms. When you perform at rest data encryption, you need to ensure you’re following these best practices: \n\n* you're using an industry-standard algorithm such as AES, \n* you’re using the recommended key size, \n* you’re managing your cryptographic keys properly by not storing your key in the same place and changing it regularly, \n* the key-generating algorithms used to obtain the new key each time are random enough. \n\nFor the examples of data given above, you can have the following encryption schemes: \n\n* full disk encryption, \n* database encryption, \n* file system encryption, \n* cloud assets encryption. \n\nOne important aspect of encryption is cryptographic keys management. You must store your keys safely to ensure confidentiality of your data. \n\nYou can store keys in Hardware Security Modules (HSM), which are dedicated hardware devices for key management. They are hardened against malware or other types of attacks. \n\nAnother secure solution is storing keys in the cloud, using services such as: \n\n* Azure Key Vault, \n* AWS Key Management Service (AWS KMS),  \n* Cloud Key Management Service in Google Cloud. \n\n**What is at rest data vulnerable to?** \n\nAlthough data at rest is the easiest to secure out of all three states, it is usually the point of focus for attackers. There are a few types of attacks data in transit is vulnerable to: \n\n* **Exfiltration attacks.** The most common way at rest data is compromised is through exfiltration attacks, which means that hackers try to steal that data. For this reason, implementing a very robust encryption scheme is important.  <br>Another essential thing to note is that, when data is exfiltrated, even if it is encrypted, attackers can try to brute-force cryptographic keys offline for a long period of time. Therefore a long, random encryption key should be used (and rotated regularly). \n* **Hardware attacks.** If a person loses their laptop, phone, or USB drive and the data stored on them is not encrypted (and the devices are not protected by passwords or have weak passwords), the individual who found the device can read its contents. \n\n## Are you protecting data in all states? \n\nUse Cyscale to ensure that you’re protecting data by taking advantage of over 400 controls. \n\nHere are just a few examples of controls that ensure data security through encryption across different cloud vendors: \n\n* *Ensure all S3 buckets employ encryption-at-rest* for AWS \n* *Ensure web app is using the latest version of TLS encryption* for Azure \n* *Ensure VM disks for critical VMs are encrypted with Customer-Supplied Encryption Keys (CSEK)* for Google Cloud \n* *Ensure server-side encryption is set to 'Encrypt with Service Key'* for Alibaba \n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance","CSPM"],"title":"SOC 2 Compliance in The Cloud","seoTitle":"SOC 2 Compliance in The Cloud","description":"SOC 2 is an international compliance standard that defines rules for B2B (business-to-business) organizations regarding data security. SOC (Service and Organization Controls) 2 was developed by AICPA (The American Institute of Certified Public Accountants). The 5 TSC (Trust Service Criteria) you have to follow to become SOC 2 compliant are: security, availability, processing integrity, confidentiality, privacy. In order to become SOC 2 compliant, you must fulfill 64 controls across the 5 TSCs mentioned.","seoDescription":"SOC 2 is an international compliance standard that defines rules for B2B (business-to-business) organizations regarding data security. SOC (Service and Organization Controls) 2 was developed by AICPA (The American Institute of Certified Public Accountants). The 5 TSC (Trust Service Criteria) you have to follow to become SOC 2 compliant are: security, availability, processing integrity, confidentiality, privacy. In order to become SOC 2 compliant, you must fulfill 64 controls across the 5 TSCs mentioned.","date":"2022-08-03T09:00:42.862Z","featuredpost":true,"permalink":"soc-2-compliance-in-cloud","featuredimage":{"publicURL":"/static/1bda2a701dc2eedacc68ebf07ba12030/blog_16-soc2.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/1bda2a701dc2eedacc68ebf07ba12030/888e2/blog_16-soc2.webp","srcSet":"/static/1bda2a701dc2eedacc68ebf07ba12030/913d0/blog_16-soc2.webp 205w,\n/static/1bda2a701dc2eedacc68ebf07ba12030/91660/blog_16-soc2.webp 410w,\n/static/1bda2a701dc2eedacc68ebf07ba12030/888e2/blog_16-soc2.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nSOC 2 is an international [compliance](https://cyscale.com/use-cases/cloud-compliance-and-auditing/) standard that defines rules for B2B (business-to-business) organizations regarding data security. \n\nSOC (Service and Organization Controls) 2 was developed by AICPA (The American Institute of Certified Public Accountants). \n\nIt regulates data security management based on the following five cybersecurity principles, which are also defined as **Trust Service Criteria (TSC)**: \n\n1. Security \n2. Availability \n3. Processing Integrity \n4. Confidentiality \n5. Privacy \n\n## SOC 2 requirements, explained for cloud \n\nIn order to become [SOC 2 compliant](https://cyscale.com/blog/soc-2-vs-ISO-27001-SaaS/), you must fulfill 64 trust service criteria across the 5 TSCs mentioned above.. Based on them, the organization establishes corresponding controls to demonstrate compliance. \n\nIn this section, we will look at some of the points of focus necessary to obtain the accreditation. They should be taken into account by companies that use cloud services.  \n\nGrouped by criteria and explained, here are examples of requirements: \n\n#### 1. Security \n\n* Implements Boundary Protection Systems - The company uses firewalls, IDSs, DMZs to secure devices. \n* Requires Additional Authentication or Credentials - [Multi-Factor Authentication (MFA)](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/#MFA) is configured for all users. \n\n#### 2. Availability \n\n* Designs Detection Measures - Logging and monitoring are implemented. \n* Implements Alerts to Analyze Anomalies – Targeted alerts are used to ensure fast remediation for high-priority assets. \n\n#### 3. Processing Integrity \n\n* Protects Stored Items – Sensitive data is safely stored in order to prevent it from being tampered. \n* Creates and Maintains Records of System Storage Activities – Logging and monitoring are required for this criterion as well. \n\n#### 4. Confidentiality \n\n* Restricts Logical Access– Access to sensitive cloud assets is limited, and the Least Privilege Principle is implemented. \n* Identifies and Authenticates Users – The company follows good practices regarding [IAM](https://cyscale.com/blog/iam-best-practices-from-aws-azure-gcp/). \n\n#### 5. Privacy \n\n* Uses Encryption to Protect Data – All assets of type storage are encrypted. \n* Protects Identification and Authentication Credentials – Managing access to cloud assets is a matter of privacy since an entity that isn't authorized should not be able to access them. \n\n## How do you obtain the SOC 2 accreditation? \n\nThe process of obtaining it depends on the type of accreditation you’re going for. There are two types of SOC audits, which require different reports: \n\n* **Type 1:** a single audit and a single report are required at a specific date and time. For this type, the design of the security program put in place is evaluated. \n* **Type 2:** to obtain the SOC 2 Type 2 accreditation, an audit is carried out over a period of time, usually a minimum of six months. For type 2, the execution of the security program is evaluated. \n\nThere are advantages and disadvantages to both types.  \n\nWhile type 1 requires less effort and is easier to get, it is also less valuable, since the evaluation result only reflects the state of the company's data security at a given point in time.  \n\nWith type 2, you invest more time and resources into getting accredited, but the result shows more effort and commitment toward the customer's [data security](https://cyscale.com/use-cases/cloud-data-security/). \n\nOnce you’ve decided which SOC 2 type you want to obtain, you need to start the long process of obtaining the accreditation. \n\n## Use Cyscale to make this process easier for you \n\nCyscale can help you obtain the SOC 2 accreditation for your company by: \n\n* checking with the use of in-app controls whether you're implementing the requirements, \n* providing you with remediation steps for any findings, \n* helping you to demonstrate, during the audit, that you’re SOC 2 compliant and should receive the accreditation. \n\nIn the image below, you can see a part of the SOC 2 standard page in Cyscale, which gives you metrics to know how you're doing in your process of becoming compliant. \n\n![SOC 2 standard page in Cyscale](/img/blog_16-soc-2-page-in-cyscale.webp#shadow \"SOC 2 standard page in Cyscale\")\n\nA large set of technical controls included in this standard are mapped to SOC 2 points of focus to easily understand which ones you’re correctly implementing, and which require your attention. \n\n<!--EndFragment-->\n"}}]}},"pageContext":{"limit":9,"skip":18,"numPages":5,"currentPage":3,"category":"CSPM","seoTitle":"Cyscale - CSPM","seoDescription":"News about Cyscale CSPM","categoriesList":["News","CSPM","CNAPP","Product","Compliance","Engineering"]}},"staticQueryHashes":["220583031","4109069157","632500807","981947644"],"slicesMap":{}}