{"componentChunkName":"component---src-template-blog-all-posts-template-js","path":"/blog/10/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"SOC 2 vs ISO 27001: What every SaaS needs to know","seoTitle":"SOC 2 vs ISO 27001: What every SaaS needs to know","description":"When looking into consolidating your data protection services, you may decide to implement SOC 2 or ISO 27001. Acquiring one of these accreditations is a thorough process and choosing the right one for your company is the first step. In case you are a SaaS provider and are not certain which one to choose, this article maps out the key differences between them.\n","seoDescription":"A comparison between the standards SOC 2 and ISO 27001 and how to acquire them, including price, duration and others.","date":"2022-03-29T06:31:44.659Z","featuredpost":true,"permalink":"soc-2-vs-ISO-27001-SaaS","featuredimage":{"publicURL":"/static/48809b2bb298642ad9c8e20940f43f8f/microsoftteams-image.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/48809b2bb298642ad9c8e20940f43f8f/888e2/microsoftteams-image.webp","srcSet":"/static/48809b2bb298642ad9c8e20940f43f8f/913d0/microsoftteams-image.webp 205w,\n/static/48809b2bb298642ad9c8e20940f43f8f/91660/microsoftteams-image.webp 410w,\n/static/48809b2bb298642ad9c8e20940f43f8f/888e2/microsoftteams-image.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"When looking into consolidating your data protection services, you may decide to implement one of the following two standards:\n\n* SOC 2\n* ISO 27001\n\nAcquiring one of these accreditations is a thorough process and choosing the right one for your company is the first step.\n\n**In case you are a SaaS provider** and are not certain which one to choose, keep reading to understand the key differences between them.\n\n**What are these accreditations** and what is their scope?\n\nThe SOC 2 and [ISO 27001](https://cyscale.com/use-cases/iso-27001-compliance/) standards are normally acquired by B2B (Business-to-business) companies.\nThey:\n\n* represent international standards for Information Security Management Systems (ISMSs)\n* describe best practices for service providers who manage customer data\n\nAs a SaaS, in order to obtain one of the two accreditations, you must implement all the policies of that standard that apply to your organization.\n\n**What do these standards say about your company?**\n\nSOC 2 and ISO 27001 are very similar.\nAcquiring one of them promotes the following principles about your organization:\n\n* You recognize the importance of cybersecurity\n* Your company is making efforts to mitigate information security risks\n* You are properly managing information security\n\nGiven the statements above, you can safely assume that a customer will prefer an organization with one of the described accreditations in their possession, to the detriment of one without any.\n\n### A comparison\n\n#### Geographical recognition\n\n* SOC 2 is governed by The American Institute of Certified Public Accountants (AICPA)\n* ISO 27001 was developed by ANSI-ASQ National Accreditation Board (ANAB)\n\n#### Duration\n\n* SOC 2: an audit takes **between 3 to 12 months**, depending on the type of audit\n* ISO 27001: takes **between 12 to 18 months** to complete\n\n#### Validity duration\n\n* For SOC 2: one year\n* For ISO 27001: three years (with surveillance audits once every year)\n\n##### Requirements\n\n**For SOC 2**, you need to fulfill **64 criteria** integrated through five trust service criteria (TSC), as seen below (along with a few criteria examples):\n\n1. Security\n\n   * Contains Security Incidents\n   * Communicates Remediation Activities\n2. Availability\n\n   * Identify environmental threats\n   * Measure Current Usage\n3. Processing Integrity\n\n   * Create and maintain records of system inputs\n   * Defines processing activities\n4. Confidentiality\n\n   * Identify confidential information\n   * Destroy confidential information\n5. Privacy\n\n   * Use clear and conspicuous language\n   * Collect information from reliable sources\n\n**For ISO 27001**, you need to:\n\n1. Implement an ISMS (Information Security Management Systems)\n2. Fulfill **7 requirements with 114 suggested controls** divided into 14 sections.\n\nThe requirements are described in the following clauses:\n\n* Clause 4: Context of the organization\n* Clause 5: Leadership\n* Clause 6: Planning\n* Clause 7: Support\n* Clause 8: Operation\n* Clause 9: Performance evaluation\n* Clause 10: Improvement\n\nIn the Annex of ISO 27001, you can find a list of controls and objectives to help you meet the requirements.\n\nYou can find more information [here](https://cyscale.com/blog/ISO-27001-certification-standard-policies-procedures/).\n\n**Price (of audit)**\n\n* For SOC 2, the cost depends on the type of audit and can range **between $5,000 and $60,000** with an average of about $20,000.\n* For ISO 27001, the price of an audit depends on the number of employees in the organization. It can go **as low as $5,400 up to $27,000**.\n\nIt is important to note that the price of implementing the standards may significantly increase the total cost of obtaining the accreditation.\n\nOne thing to note is that, although SOC 2 and ISO 27001 seem very different, their specifications overlap.\n\nThe level of similarity between the requirements of the two depends on:\n\n* The type of business you run\n* The scope of the audit\n\nThe similarity can be between 53% and 90%, according to AICPA’s mapping to ISO 27001.\n\nTaking into account all of the differences and similarities of the SOC 2 accreditation and the ISO 27001 certification, you can now choose the best standard for your company.\n\nFinally, implementing all the policies required by the described standards can be a difficult and time-consuming task.\n\nYou can make this process easier for you.\n\nWith [Cyscale](https://cyscale.com/), you can ensure easy and continuous compliance for ISO 27001.\n\nCyscale helps you meet the much-needed requirements described by this standard.\n"}},{"node":{"frontmatter":{"authors":"Manuela Țicudean","categories":["Compliance"],"title":"PSD2 Requirements through the Technical Security Lens","seoTitle":null,"description":"A deeper look at the most important regulation for payment services in Europe (PSD2), surfacing security requirements for the technology at the core of these businesses, tech-governance included.","seoDescription":null,"date":"2022-03-04T13:12:59.854Z","featuredpost":true,"permalink":"PSD2-technical-requirements","featuredimage":{"publicURL":"/static/f7099646cc0f3e38c229f2faa1f6ee44/cyscale_psd2.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/f7099646cc0f3e38c229f2faa1f6ee44/888e2/cyscale_psd2.webp","srcSet":"/static/f7099646cc0f3e38c229f2faa1f6ee44/913d0/cyscale_psd2.webp 205w,\n/static/f7099646cc0f3e38c229f2faa1f6ee44/91660/cyscale_psd2.webp 410w,\n/static/f7099646cc0f3e38c229f2faa1f6ee44/888e2/cyscale_psd2.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}}},"rawMarkdownBody":"\nThe fintech sector has known an impressive growth in funding over the past year. A recent Insider Intelligence [report](https://www.emarketer.com/content/insider-intelligence-fintech-trends-watch-2022) shows that the global funding for fintech in the first three quarters of 2021 reached $94.7 billion, which is shy of the total for 2019 and 2020 combined. [In the UK](https://member.fintech.global/2021/12/15/uk-fintech-funding-nearly-doubled-in-the-first-three-quarters-of-2021-outpacing-global-average/) alone, fintech funding nearly doubled in the mentioned timeframe, as compared to the year before (2020).\n\nAround the fintech businesses, entire ecosystems have emerged. There are national as well as international level organizations that collaborate and launch initiatives to drive the competition as well as innovation in the sector. Regulatory bodies are part of the ecosystems as well, making sure that businesses are doing the best they can to protect fintech consumers.\n\nThe purpose of this article is to take a deeper look at the most important regulations for payment services (which is a large subset of fintech services) in Europe, trying to showcase the security requirements for the technology at the core of these businesses, its governance included.\n\nWe keep in mind that although the UK has left the European Union, they decided to adopt a great part of the regulation under their legislation as well.\n\n## The PSD2 Directive\n\nProbably the most important European regulation that impacts fintech is the PSD2 Directive. Developed by the European Parliament and the European Council, introduced in 2015, and enforced since 2018, it describes rules, rights and obligations of Payment Service Providers and the users of these services. In the next sections, we go through the structure of the document, emphasizing the articles that regulate the “tech” in “fintech”.\n\nIt starts with 113 points that set up the context for the regulation and then follows with 6 main sections (also called titles).\n\n### Scope\n\n**The first section** clarifies the subject matter (who is affected), and that is Payment Service Providers. As we’ll see below, this includes traditional financial services providers, for example banks, but also new providers, such as fintechs. There’s also an article regarding scope: it applies to payment services provided within the European Union.\n\nPayment Service Providers are grouped under 6 distinct categories, but most fintechs fall under **payment institutions** and **electronic money institutions**.\n\nAny institution that provides payment services (enumerated below) after being authorized to do so, becomes a **payment institution**.\n\nThe different types of **payment services**, as understood from Annex 1 of the Directive are:\n\n-   operating a payment account for a user\n-   placing or withdrawing cash from a payment account\n-   payment transactions (i.e. transfers of funds) within the same provider, or to an external provider\n-   issuing of payment cards\n-   issuing sets of rules agreed between the issuer and the user that are then used to initiate a payment\n-   accepting and processing payment transactions\n-   money remittance, which is transfer of money without any payment accounts being created or used (think Western Union)\n-   payment initiation — initiate payment orders on behalf of the user (with his previous consent), from a payment account that is held at a different provider. This is possible due to the open banking framework.\n-   account information — provides information on payment accounts held by the user at a different provider. Again, this service has been made possible through open banking.\n\nAn **electronic money institution** is a legal entity that is authorized to issue electronic money. An electronic money institution can at the same time be a payment institution. There is a specific authorization license for each of these types of providers.\n\n### Becoming a PSP\n\n**The second section**, or title, adds further provisions for Payment Service Providers, including the procedure to become licensed as one.\n\n_Article 5_, titled “Applications for authorization”, contains the list of artefacts to submit when applying to become a payment institution. Among these, the directive requires **a security policy document** that must contain \"a detailed risk assessment\", along with the \"security control and mitigation measures taken\" to protect users against identified risk. It also explicitly states that the policy must indicate how the institution ensures \"a high level of **technical security and data protection**, including of the software and IT systems used\", and even when these are entirely or partly outsourced.\n\nAs we can see, already during the application process, a fintech business must have technical security controls in-place, as well as ways to describe them.\n\n**The third section** (title) of the directive refers to the transparency of conditions, as well as information requirements for payment service providers, meaning data regarding the payments which must be communicated to the service user at specific points in time. It does not contain any requirements for tech.\n\n### Proper Security\n\n**The fourth section** (title) details the rights and obligations around the provision and use of payment services, of both the providers and the users. This section is again relevant for those in charge of technology inside fintech companies providing payment services.\n\n*Article 66* and *Article 67* describe the obligations of PISPs (Payment Initiation Service Providers) and AISPs (Account Information Service Providers), which are both types of payment service providers.\n\nAn example of a PISP would be an application that, based on previously given user consent, makes regular (i.e. monthly) payments from the user’s bank account, and invests those funds on behalf of the user. In other words, by providing payment initiation services, the app makes payment transactions without the user having to do anything.\n\nTo understand an AISP, think of an application that queries information about a user’s bank account and then analyzes that data in order to give the user insights about his financial behavior. Previously given user consent is, of course, mandatory.\n\nUnder PSD2, the PISP and the AISP must:\n\n-   Protect user's personalized security credentials (PSC), if used, by transmitting them safely, and making sure they are not shared with other parties.\n\n    **PSCs** are, for example, your internet banking password, the code you use to authenticate to your neobank's mobile app, or any other means of authenticating with a Payment Service Provider. These credentials should not be shared with a PISP, or, when they are, they must be handled securely.\n\n-   Ensure that any information received about the payment service user is only provided to the payee (with user consent)\n-   When communicating with the entity that provides the user's payment account (i.e the bank), use common and secure open standards of communication\n-   Not store sensitive payment data of the user\n-   Not request from the user data that is not needed, in order to provide the services\n-   Not use, access, or store any user data for purposes other than the provided service\n-   In case of payment transactions, not modify the transaction amount\n\n*Article 70* states the obligations of a Payment Service Provider in relation to payment instruments (remember, these may be payment cards, but also procedures agreed between the user and the service provider on how to initiate payment orders). Again, the protection of personalized security credentials is required, by making sure that they are not accessible to other parties.\n\n*Article 74* states that when a Payment Service Provider doesn’t enforce strong customer authentication (**SCA**; think MFA) to protect transactions, it is liable for any financial losses incurred by the payer because of that.\n\n*Article 89* details the liability of Payment Service Providers in case they fail to correctly and in-time execute payment transactions. This part stresses out the importance of a solid **business continuity policy** and plan.\n\n*Article 95* requires two things from the Payment Service Providers:\n\n-   mitigation measures and control mechanisms in place, to manage operational and security risks\n-   to regularly provide operational and security risk assessments to competent authorities, as well as evidence that mitigation measures are adequate\n\n_Article 97_ requires from the PSP the implementation of strong customer authentication, meaning multi-factor authentication, involving something the user knows, something the user possesses or something that the user is (knowledge, possession or inherence). It also requires that “payment service providers have in place adequate security measures to protect the confidentiality and integrity of payment service users’ personalized security credentials”.\n\n### Ending Notes\n\nFinally, *Article 98* requires that, by July 2017, the Euro Bank Association (which is another EU institution) will have drafted regulatory technical standards to address the security requirements from previous articles (strong customer authentication and protecting the users’ personalized security credentials).\n\nThe **last two sections** refer to procedures for the settlement of disputes, user information rights, and final provisions, respectively, but neither of them contains additional technical requirements.\n\nThe regulatory technical standards developed by the EBA will be the subject of the next article in the series, where we will take a deeper dive into what they mean for a fintech.\n"}},{"node":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["Product"],"title":"Integrating NATS Into the Cyscale Platform","seoTitle":"Integrating NATS Into the Cyscale Platform","description":"Some concepts and techniques we leveraged to switch to a cloud-native message broker.","seoDescription":"Discover how Cyscale has enhanced cloud security integration by utilizing NATS on Kubernetes for efficient, scalable message-based communication. Read about the journey, benefits, and technical implementation on our blog.","date":"2021-12-22T10:11:16.968Z","featuredpost":true,"permalink":"integrating-nats-into-the-cyscale-platform","featuredimage":{"publicURL":"/static/cb4216e63701672e106156941ccdecaf/nats-horizontal-color.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/cb4216e63701672e106156941ccdecaf/02dc4/nats-horizontal-color.webp","srcSet":"/static/cb4216e63701672e106156941ccdecaf/913d0/nats-horizontal-color.webp 205w,\n/static/cb4216e63701672e106156941ccdecaf/85995/nats-horizontal-color.webp 410w,\n/static/cb4216e63701672e106156941ccdecaf/02dc4/nats-horizontal-color.webp 820w,\n/static/cb4216e63701672e106156941ccdecaf/62a3a/nats-horizontal-color.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":461}}}},"rawMarkdownBody":"\n<!--StartFragment-->\n\n## Backstory\n\nCyscale helps you secure your cloud infrastructure. To achieve this, the platform must be able to read (sync) the cloud resources, perform assessments against a set of controls (security and architecture guidelines and best practices), send notifications, generate reports, perform scheduled tasks, and so on. Given the highly distributed and segregated nature of the platform, we chose a microservices architecture on top of Kubernetes. Also, by design, these processes are mostly asynchronous, happening in the background as a result of a certain event or trigger.\n\nBesides direct HTTP communication (REST mostly for the account/user management and GraphQL for everything cloud-related), we make heavy use of message-based communication.\n\nUp until recently, Redis served as our backbone for sending messages. We used Redis Lists to simulate queues (e.g., for sending emails) and Redis Pub/Sub for, well, implementing the publish-subscribe pattern (e.g., for triggering the synchronization of the cloud resources). We knew since the beginning that Redis will not serve as the messaging middleware forever, but we started with it since it was already there for caching and tasks (through [Go Celery](https://github.com/gocelery/gocelery)).\n\nDue to a mix of accumulated technical debt and a desire for simplicity, we decided to invest in integrating a purpose-built technology for handling messages. After a good amount of research covering topics such as operational simplicity, community, and documentation, we decided to go with [NATS](https://nats.io/). As a side note, we continue to love Redis and there are plenty of well-established companies using it as their messaging middleware with great success.\n\nThe rest of the article will cover the main steps we took to integrate NATS into our platform such as understanding the NATS ecosystem, deploying the relevant tools on our Kubernetes cluster using Helm - this will form the main part since this is where we faced the most challenges, and, of course, sending and consuming messages.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\n**The NATS Ecosystem**\n\n![The NATS ecosystem encompassing the core NATS server, JetStream, the NATS clients and CLI, and the NATS resources for Kubernetes](/img/cyscale-nats.webp 'The NATS ecosystem')\n\n### Core NATS\n\nAt its core, **the NATS server** is a **publish/subscribe** message broker. It offers **at most once delivery** and works based on **subjects**. These can have a hierarchical structure such as `sync.aws` and `sync.gcp`. Services concerned with messages related to syncing operations for AWS will only subscribe to `sync.aws` while other services might listen for all sync-related messages on `sync.*` (which covers both subjects) or even `sync.>` (which will also cover `sync.aws.ec2` - a separate subject).\n\nAnother feature that provides us with great value is called **queue groups**. This helps us horizontally scale our consumers while making sure that only one instance of a service receives a certain message. If you have experience with Kafka, it resembles consumer groups. What’s nice about queue groups is that they are automatically created when consumers subscribe to a subject and provide the queue group parameter (a simple string that, just like subjects, can have a hierarchical structure). For example, we use the name of the service (e.g. notifier) as the queue group.\n\nWhile the core functionality is great and simple, plain old pub/sub with at most once delivery will not cover all use cases. Subscribers might be under heavy load or even down, there might be a network partition or we might even want to keep messages and follow an approach based on event sourcing (you can find more examples in the [NATS docs](https://docs.nats.io/using-nats/developer/develop_jetstream)). In other words, as soon as we need **temporal decoupling** between publishers and subscribers, we need **persistence**, which for NATS is provided by JetStream.\n\n### JetStream\n\nJetStream adds the concept of **streams** on top of the core NATS subjects. Basically, if you want your messages to be persisted, you can enable JetStream on the NATS server and create a stream that will actually store the messages sent to a subject (or multiple subjects - this is mostly to optimize resource utilization; for example, we have one stream called sync that stores all messages sent to any sync subject - i.e. sync.>).\n\nIf your system takes full advantage of JetStream, at most once delivery transforms into **at least once** and even **exactly once** by leveraging [message deduplication](https://docs.nats.io/using-nats/developer/develop_jetstream/model_deep_dive#message-deduplication) (NATS will discard a message if another message with the same publisher-provided ID exists in the stream over a window of a certain time - 2 minutes by default).\n\nOne confusion we had at the beginning was whether we actually had to do anything to take advantage of JetStream besides enabling it. Again, bringing the simplicity up front, publishers will not require any modification unless you are looking for exactly-once delivery (you will have to add the message ID). They still send messages on a certain subject and, behind the scenes, JetStream will persist them in the configured stream.\n\nOn the other hand, **you do have to create the actual streams** (we will talk about this below) and **adjust the subscribers to use the JetStream API** (part of the client NATS library). Note that you can still use the core NATS API, but your subscribers will not receive messages sent before they started listening (even though they are stored in the stream). The reason behind this is that JetStream actually creates consumers that handle the delivery of messages for each subscriber. You will have to manually create the consumer when using the CLI, but the client libraries will handle this automatically when subscribing to a subject through the JetStream API.\n\nHaving the messages persisted also enables us to take different approaches based on what we want to achieve. We might still follow a pub/sub approach for certain subscribers (these are known as **push consumers**) (e.g. we use this approach for generating user-requested reports) or we might want to have more control over how messages are retrieved in which case we will use a **pull consumer**. This enables us to batch messages (e.g. we do this for sending notifications). Here is how we handle the messages in our notifier service:\n\n```typescript\nexport type MessageHandler = (data: NotificationDto[]) => Promise<void>;\n\nexport const handleNotificationMessages = async (handler: MessageHandler) => {\n    try {\n        const nc = await getNatsClient();\n\n        if (!process.env.NOTIFICATIONS_SUBJECT) {\n            throw Error('NOTIFICATIONS_SUBJECT not set');\n        }\n\n        const jc = JSONCodec<NotificationDto>();\n\n        const psub = await nc.jetstream().pullSubscribe(process.env.NOTIFICATIONS_SUBJECT, {\n            queue: 'notifier',\n            config: { durable_name: 'notifier' }\n        });\n\n        const done = (async () => {\n            let notifications: NotificationDto[] = [];\n            for await (const m of psub) {\n                try {\n                    notifications.push(jc.decode(m.data));\n                    m.ack(); // Wait to gather all messages from the current batch\n                    if (m.info.pending === 0) {\n                        await handler(notifications);\n                        logger.info(`Processing ${notifications.length} messages`);\n                        notifications = [];\n                    }\n                } catch (error) {\n                    logger.error(error);\n                }\n            }\n        })();\n\n        setInterval(() => {\n            psub.pull({ batch: 30, expires: 1000 });\n        }, 1000 * 30);\n\n        logger.info(`Listening for messages on ${process.env.NOTIFICATIONS_SUBJECT}`);\n\n        await done;\n        await psub.destroy();\n    } catch (e) {\n        logger.error(`Failed to initiate message listening ${e}`);\n    }\n};\n```\n\n(yes, most of our services are actually written in Go, hence the naming of some variables)\n\nAnother dilemma we faced was regarding **stream creation**. Who/what is responsible for creating the streams? One option is using the client libraries which expose a method to **idempotently** create streams. While this can work just fine, we didn’t want our services to bother with the technical details of NATS. Also, streams felt more like being part of the infrastructure than part of the actual services. So we continued our research and found [NACK](https://github.com/nats-io/nack) which we cover below.\n\nAs a side note regarding persistence/streaming with NATS, the precursor of JetStream is called STAN, which is now deprecated. We are mentioning this because there are still plenty of tutorials that focus on STAN, but JetStream is the way forward.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\n## NATS on Kubernetes with Helm\n\nBeing part of the CNCF, we can expect NATS to have first-class support for Kubernetes. And it does.\n\nSince the entire Cyscale platform is specified as a Helm chart we just needed to add the [NATS](https://github.com/nats-io/k8s/tree/main/helm/charts/nats) subchart as a dependency and configure the values. You can check the [values file](https://github.com/nats-io/k8s/blob/main/helm/charts/nats/values.yaml) from the chart repo for reference. One small detail that cost us a few hours was how we were specifying the values for NATS. If you look at [the documentation](https://docs.nats.io/running-a-nats-service/introduction/running/nats-kubernetes/helm-charts#jetstream), you will notice the `nats` object. However, since we are deploying NATS as a subchart, we will need an additional parent `nats` object to instruct Helm to pass the values down to the nats subchart. Here are our values for NATS on the dev cluster:\n\n```yaml\nnats:\n  nats:\n    image: nats:alpine\n    resources:\n      requests:\n        cpu: 100m\n        memory: 100Mi\n      limits:\n        cpu: 200m\n        memory: 200Mi\n    jetstream:\n      enabled: true\n      memStorage:\n        enabled: true\n        size: 80Mi\n      fileStorage:\n        enabled: true\n        size: 1Gi\n        storageDirectory: /data/\n        storageClassName: default\n```\n\n(notice the two `nats`)\n\nBesides the actual NATS server (which is a container running in the NATS pod along with the monitoring and config reloader containers), we also have a **NATS Box** pod (comes with the NATS Helm chart) that helps us with testing and administrative tasks - basically its a **preconfigured NATS CLI**. We access it using the command `kubectl exec -it <nats-box-container> -- /bin/sh -l`. The other alternative would have been to install the NATS CLI on our machines and port forward the NATS server from the cluster.\n\n### Creating the Streams with NACK\n\nBesides NATS, we also added the [NACK subchart](https://github.com/nats-io/k8s/tree/main/helm/charts/nack) which requires the NACK **CRDs** (install using `kubectl apply -f <https://raw.githubusercontent.com/nats-io/nack/v0.6.0/deploy/crds.yml>`). That’s because it enables us to treat JetStream streams as Kubernetes resources deployed as part of the rest of the platform.\n\nInstead of having our services handle the stream creation or manually creating them from the NATS box, we specify them declaratively as follows (`templates/nats-streams.yaml`):\n\n```yaml\n# See https://github.com/nats-io/nack/blob/main/deploy/crds.yml for more properties\n{{- range .Values.nack.streams }}\napiVersion: jetstream.nats.io/v1beta2\nkind: Stream\nmetadata:\n  name: {{ .name | quote }}\nspec:\n  name: {{ .name }}\n  subjects: {{ .subjects }}\n  storage: {{ .storage | quote | default \"file\" }}\n  retention: {{ .retention | quote | default \"limits\" }}\n---\n{{- end }}\n```\n\nWe also declare the streams as a list in the values file (notice the `range`).\n\nOnce these are deployed, you can inspect the streams just like any other k8s resource using `kubectl get streams`. One issue we faced was that the streams were not actually created in JetStream (`nats stream ls` from the nats box) even though the k8s resources existed. We simply manually deleted them from the cluster (`kubectl delete streams.jetstream.nats.io --all`) and re-deployed the helm chart.\n\nThere is another alternative we considered - the [jetstream Terraform provider](https://registry.terraform.io/providers/nats-io/jetstream/latest/docs). While we do use Terraform to declare our infrastructure on top of which the Kubernetes cluster is running, we chose NACK because it fit our abstraction layers best and because the terraform provider, running locally or in our pipelines, has to somehow reach the NATS server. In our case, the NATS server is not exposed outside of the cluster (again, port-forwarding is an option).\n\n### Ending Notes\n\nWhile there are more subjects to cover such as [authentication](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/auth_intro) and [authorization](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/authorization), clustering (and [super-clusters](https://docs.nats.io/running-a-nats-service/configuration/gateways)), and multi-tenancy using [accounts](https://docs.nats.io/running-a-nats-service/configuration/securing_nats/accounts), we hope this article helps you better understand how NATS works and how to deploy it. This is our way of giving back to a growing community and expressing our appreciation for getting to work with such great technologies.\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Virginia Mitea","categories":["CNAPP"],"title":"CNAPP: A mix of CSPM & CWPP","seoTitle":"CNAPP: A mix of CSPM & CWPP - Cyscale","description":"Gartner has defined a new category that is focused on securing cloud services and cloud-native applications, the so-called CNAPP- Cloud-Native Application Protection Platform.\n\nAccording to Gartner, “CNAPP is an integrated set of security and compliance capabilities designed to help secure and protect cloud-native applications across development and production.”\n\nThe legitimate question would be: Why do I need another security tool?","seoDescription":"Unveil CNAPP, a blend of CSPM & CWPP for advanced cloud security. Learn the benefits, compare it with separate tools, and understand its impact on the future of cybersecurity. A comprehensive guide by Cyscale on the latest trend in cloud protection.","date":"2021-11-24T15:35:49.333Z","featuredpost":true,"permalink":"cnapp-a-mix-of-cspm-cwpp","featuredimage":{"publicURL":"/static/e94d8cb96cb8569f098d571aba981b9e/cspm-cwpp.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/e94d8cb96cb8569f098d571aba981b9e/1946f/cspm-cwpp.webp","srcSet":"/static/e94d8cb96cb8569f098d571aba981b9e/19b88/cspm-cwpp.webp 205w,\n/static/e94d8cb96cb8569f098d571aba981b9e/f7577/cspm-cwpp.webp 410w,\n/static/e94d8cb96cb8569f098d571aba981b9e/1946f/cspm-cwpp.webp 820w,\n/static/e94d8cb96cb8569f098d571aba981b9e/d54ec/cspm-cwpp.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":547}}}},"rawMarkdownBody":"<!--StartFragment-->\n\nEven before the Covid-19 pandemic, it was clear that more and more companies were adopting a cloud-first strategy.\n\nOver the last 2 years, the number of companies using the services of at least one public cloud provider continued to grow.\n\nAs a result, Gartner predicted that by the end of 2021 “public cloud deployments will outnumber private data center workloads”.\n\nOnce again, security specialists insist that cloud security is a complex subject that should be considered a high priority.\n\nThere already are a lot of tools to take into consideration when you're concerned with cloud security. Up until now, cloud professionals were talking about three main security solutions: [Cloud Security Posture Management (CSPM)](https://cyscale.com/blog/cloud-security-posture-management-cspm-guide/), Cloud Workload Protection Platform (CWPP), and Cloud Access Security Broker (CASB).\n\nBut recently, Gartner has defined a new category that is focused on securing cloud services and cloud-native applications, the so-called CNAPP- Cloud-Native Application Protection Platform. CNAPP combines the capabilities of Cloud Security Posture Management (CSPM) and Cloud Workload Protection Platform (CWPP) to provide comprehensive [cloud native application security](https://cyscale.com/blog/cnapp-secure-native-applications/) across development and production environments.\n\nThe legitimate question would be: ***Why do I need another security tool?***\n\nWell, the idea is to focus not only on your [cloud infrastructure's security](https://cyscale.com/blog/cloud-infrastructure-security/) configurations but also on your applications that run in the cloud.\n\nYou could argue that your CWPP or your CSPM is already doing something about this - and you would be right!\n\nIf you dig deeper, CNAPP is basically a mix of 2 separate solutions:  Cloud Security Posture Management (CSPM) & Cloud Workload Protection Platform (CWPP)\n\n### What is CSPM?\n\n[Cloud Security Posture Management solutions (CSPM)](https://cyscale.com/products/cloud-security-posture-management/) have as main purpose the [detection of misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/). They will continuously monitor the cloud environment in order to provide visibility across multi-cloud and alert the company about compliance drift or risky behavior. CSPMs focus on cloud infrastructure.\n\n### What is CWPP?\n\nCloud Workload Protection Platforms (CWPPs) are designed to protect the workloads deployed in the cloud. They will perform vulnerability assessments and handle the security of the applications. Based on assessment results, you can implement security controls or you can remediate the threats. CWPPs focus on the applications running in the cloud.\n\n## **Which is better? CNAPP vs CSPM+CWPP**\n\nThe increasing features overlap between these two solutions will make this \"merge\" inevitable.\n\n You can still use separate tools, or you can try a CNAPP, that's entirely up to you.\n\n#### ***Advantages of using CNAPP:***\n\n* better visibility and control of cloud-native application risk (when using separate tools, the identification and remediation actions can be fragmented, and not as efficient as having it all in one tool)\n* better collaboration for development and operations teams\n* simpler CI/CD pipelines (reduced complexity and cost since fewer tools are involved)\n* it scans all the source code, containers, VM images, IaC scripts, API\n\n#### ***Advantages of using separate tools:***\n\nThe most important one is the *maturity of the tools*.\n\nYou need to consider that Gartner expects this new category to have a high impact, but also predicts that it will take five to ten years before CNAPP is established in regular use.\n\nSince this is a new category of products, the market for CNAPP has just started to evolve and vendors need time to integrate all these capabilities.\n\nCWPP vendors have started to add new features capabilities, including IaC scanning.\n\nSome CSPMs have cutting edge-technology in place and can already give you some of the features promised a [CNAPP solution](https://cyscale.com/products/cnapp/).\n\nThis is the case of [Cyscale Cloud Security Platform](https://cyscale.com), the solution that offers advanced visibility, but more importantly, gives you context so you can better prioritize.\\\nThe [Security Knowledge Graph](https://cyscale.com/products/security-knowledge-graph/)™ built within the platform may reveal, for example, that one of the resources usually reported to have a high-security risk, is not as vulnerable as it seems. (Let's think about a VM that has unencrypted disks attached, but is not being used in a production environment, or is not externally accessible from the internet).\\\nThis type of approach can make you realize that you need a more advanced risk analysis and a look beyond the classic list of logs, where the vulnerable components are reported without taking into consideration the bigger picture.\n\nRegardless of your choice of tool, just remember to give security posture the importance it deserves.\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\nPhoto by Markus Spiske\n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Virginia Mitea","categories":["CSPM"],"title":"CSPM: A Comprehensive Guide","seoTitle":"CSPM: A Comprehensive Guide - Cyscale","description":"A Cloud Security Posture Management solution is a critical part of a Cloud Security Program because it covers the unintentional risks that can expose your data. \nThese unintentional configuration mistakes are likely to occur because of the complexity of the environment or because of poor visibility. Regardless of the reason, it is important to understand that even one misconfiguration can lead to data breaches and possibly data leakage.","seoDescription":"Explore the intricacies of Cloud Security Posture Management (CSPM). Understand its role in cloud infrastructure, its evolution, and why it's pivotal for securing cloud environments against misconfigurations and threats","date":"2021-10-25T13:52:42.171Z","featuredpost":true,"permalink":"cloud-security-posture-management-cspm-guide","featuredimage":{"publicURL":"/static/feddd235dcd06654566b0aed36d293c9/hal-gatewood-tzc3vjpck-q-unsplash.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/feddd235dcd06654566b0aed36d293c9/1946f/hal-gatewood-tzc3vjpck-q-unsplash.webp","srcSet":"/static/feddd235dcd06654566b0aed36d293c9/19b88/hal-gatewood-tzc3vjpck-q-unsplash.webp 205w,\n/static/feddd235dcd06654566b0aed36d293c9/f7577/hal-gatewood-tzc3vjpck-q-unsplash.webp 410w,\n/static/feddd235dcd06654566b0aed36d293c9/1946f/hal-gatewood-tzc3vjpck-q-unsplash.webp 820w,\n/static/feddd235dcd06654566b0aed36d293c9/d54ec/hal-gatewood-tzc3vjpck-q-unsplash.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":547}}}},"rawMarkdownBody":"<!--StartFragment-->\n\n## CSPM - short history & definition\n\nThe increasing rate of cloud adoption encountered in the last few years has brought new security challenges along, the main one being the need to correctly configure cloud infrastructures.\n\nEmploying a cloud-first strategy, using Infrastructure as Code (IaC), or having an API-driven approach gained popularity and opened the door to new vulnerabilities and potential misconfigurations.\n\nAccording to Gartner's report from 2016, “By 2020, 95 % of all security breaches in the cloud will be caused by misconfigurations”. Something had to be done, and fast!\n\nThe Cybersecurity market responded with innovation, and so a new security category was born: the *Cloud Infrastructure Security Posture Assessment.*\n\nThe main objective of tools in this category was to report configuration errors discovered in the rapidly changing environment that is the cloud.\n\nAs the products quickly evolved and gained in complexity, the initial name was changed to [***CSPM*** - or ***Cloud Security Posture Management***](https://cyscale.com/blog/understanding-cspm-an-essential-guide/), but the main purpose of the solutions remained the same: to monitor the cloud infrastructure, [identify potential misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/) and help with security policy enforcement.\n\nIn this age of rapid technological advances, it's crucial to recognize the ever-evolving [cloud security challenges](https://cyscale.com/blog/cloud-security-challenges/). With the digital landscape shifting constantly, businesses face new threats and vulnerabilities. It's against this backdrop that the importance and necessity of solutions like CSPM become even more evident.\n\nIncluded in Gartner's “Top 10 Security Projects for 2019”, the CSPM represents one of the most important technologies that leaders should invest in when using cloud or multi-cloud infrastructures.\n\n## When to choose a CSPM and when not to\n\nA Cloud Security Posture Management solution is a critical part of a Cloud Security Program because it covers the **unintentional risks** that can expose your data.\n\nThese unintentional configuration mistakes are likely to occur because of the complexity of the environment or because of poor visibility. Regardless of the reason, it is important to understand that even one misconfiguration can lead to data breaches and possibly data leakage.\n\n### Misconfigurations - cause and effect\n\nWe've all heard about major breaches that happened because of AWS S3 buckets being publicly accessible. (This exact [misconfiguration happened to Romania's largest real estate portal](https://cyscale.com/blog/realestate-data-breach/ \"https\\://cyscale.com/blog/realestate-data-breach\") ).\n\nMany cloud application creators or maintainers don't believe this can happen to them, but, for example, when new virtual machines are launched in a hurry by a less experienced DevOps engineer, mistakes can occur and networks that should have been private are now public and exposed.\n\nOther common misconfigurations that attackers are often exploiting are overprivileged credentials. Restricting users' access to data and resources to only what is strictly required for them to do their jobs is a must, in other words, you need to use the **least privilege principle**.\n\nThe [CSPM tool](https://cyscale.com/products/cloud-security-posture-management/) will report and advise against using overly permissive account settings for your users, and at the same time remind you to use encryption, thus strengthening your security and making it even harder for an unauthorized or malicious individual to access and expose your data.\n\nThe advanced CSPM solutions we see these days offer continuous monitoring, risk assessments, remediation recommendations based on security best practices, and assistance for compliance with the most common security frameworks and standards.\n\nWhat if you could have a powerful solution that offers full visibility over your cloud accounts, enabling better communication and collaboration between your Security team, the DevOps, and the Compliance team?\n\nThis solution exists! You need to implement a CSPM to improve your cloud security posture and to build a strong Security Program.\n\nUnlike other security software which takes a lot of time to set up, requiring multiple steps to achieve proper installation and configuration, a CSPM platform is agentless. To have it up and running takes only minutes and best of all, it has no negative impact in your infrastructure's performance.\n\nThe scan of your cloud account infrastructure will start immediately after onboarding and the results, meaning the identified issues and security risks will be displayed, usually ranked by severity or risk score.\n\n## Take advantage of the extra visibility\n\nA CSPM will provide you with a comprehensive overview of the vulnerabilities in your cloud infrastructure, making it easy to prioritize the order and urgency of solving these issues.\n\nYour cloud infrastructure is not a one-way road, cloud assets are interconnected, and it is critical to understand how this can lead to exposed resources.\n\nThe complete cloud assets inventory will automatically be compared against a set of best practices.\n\nHaving full visibility is key when implementing security best practices.\n\nManaging your cloud assets from a single dashboard is an important and useful feature.\n\nYour Security team is responsible for monitoring the cloud against threats, possible attacks, or malicious behavior. Your DevOps team is rapidly building and deploying applications in the cloud (and therefore adding new cloud assets), while your Compliance and Auditing team needs to make sure the company and its cloud infrastructure stay compliant with regulations and standards. What a dedicated solution such as a CSPM does for you, is to make sure that the relevant information is available to each of these teams in an easily comprehensible manner.\n\n## Better security for your cloud environments with the CSPM solution\n\nSome cloud providers like AWS, Azure, or Google Cloud Platform have security recommendations in place, however, you need to understand that they apply only to that specific cloud provider and in many cases, they turn out to be false positives, since the context is not taken into consideration.\n\nNot to mention that a multi-cloud strategy will complicate security efforts since IT security teams must deal with the fact that configuration is different from one cloud provider to the other.\n\nCSPM solutions do not require the deployment of any additional resources to enforce cloud security best practices and will identify and help mitigate these security risks across cloud providers.\n\nAccording to Gartner, CSPM tools can identify risks in the configurations of your [cloud infrastructure security](https://cyscale.com/blog/cloud-infrastructure-security/) and will immediately react either with automatic remediations or with specific instructions on how to fix the misconfiguration and eliminate risks.\n\nThere are other types of tools that handle sensitive workloads and data in the cloud or that monitor user activity. All these tools are enforcing security policies and together they can ensure the proper protection in the cloud.\n\nSolutions such as Cloud Workload Protection Platforms (CWPP) or Cloud Access Security Brokers (CASB) can have similar features with a CSPM.\n\nCASB software, for example, was created to monitor and enforce enterprise security, and it is not necessarily cloud-based. It can be installed on-premise, placed between cloud applications and their users acting as a central gateway that controls users' access to the cloud. It includes DLP (Data Loss Prevention) capabilities, Governance, Data encryption, MDM (Mobile Device Management).\n\nCWPP comprises agent-based solutions that offer visibility and security management for workloads. So, the provided inventory mainly covers VMs (Virtual Machines), public cloud IaaS (infrastructure as a service), and container-based application architectures. A CWPP solution does not provide event monitoring outside workloads.\n\nEven if CASB, CWPP, and CSPM may sound similar at first, their scope and coverage are different, as they represent different categories. You will need to decide which tool or tools are the right ones for your organization.\n\n## Compliance controls across your environment in the cloud\n\nCompanies that closely follow regulatory compliance are using Cloud Security Posture Management tools to avoid breaches that usually ruin the brand reputation and bring monetary fines to the company.\n\nA CSPM solution can offer predefined Policies needed for compliance with the most common benchmarks and regulations such as CIS, NIST, HIPPA, ISO27001, or others.\n\nConsidering the compliance aspect, you could be tempted to believe that a CSPM solution is just another GRC tool (Governance Risk and Compliance), but in reality, it is more than that.\n\nUsing CSPM software, you can get a grip on your cloud compliance strategy in just a couple of steps:\n\n**Start by identifying the applicable standards for your company.**\n\nUsually, you will find a specific section in the platform where the most common standards and regulations are defined and implemented from a cloud security perspective. PCI-DSS, NIST, GDPR, CIS, ISO, HIPPA - are just some examples of what you can expect to find.\n\n**Next, you will determine the requirements and start documenting your compliance processes.**\n\nPredefined compliance policies are offered, but you will be able to define custom ones, specific to your needs. Policies have technical controls attached that are automatically assessed. In case of a failed assessment, remediation actions are suggested.\n\nA CSPM solution can be a powerful reporting and evidence collection tool, making it easy to always be prepared for audits and inspections.\n\nWhen it comes to defining Policies and Procedures for the governance of your organization — for example, Access Management Policy, Change Management Policy, and so on — Cyscale's solution offers these out-of-the-box and you can use them as baselines, customizable to your needs.\n\n**The last but very important step is to monitor changes and configuration drifts.**\n\nThis is when the ongoing monitoring capability of the CSPM software comes in handy. Once you define your set of policies, the solution will help identify compliance drifts.\n\nYour Compliance Officers can use the CSPM as an in-house audit tool, assisting them in preparing for externally conducted or formal compliance audits.\n\nA CSPM tool will help you handle compliance concerns, minimize threats, catch errors and empower you to align [cloud security strategy](https://cyscale.com/blog/cloud-security-strategy-best-practices-tutorials/) across the company.\n\nWhen you are looking for a CSPM solution, keep in mind that visibility and context go hand in hand and that Cyscale Cloud Platform can offer the most comprehensive context thanks to its unique Security Knowledge Graph™.\n\nAs Gartner stated: “the use of a CSPM tool can reduce cloud-based security incidents due to misconfigurations by 80%”. So, although, there are cases when a CSPM solution's functionalities can overlap with those of other security tools, it could never be fully replaced by any of them.\n\n<!--StartFragment-->\n\n*Photo by [Hal Gatewood](https://unsplash.com/@halacious?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)*\n\n<!--EndFragment-->\n\n<!--EndFragment-->"}},{"node":{"frontmatter":{"authors":"Manuela Țicudean","categories":["Compliance"],"title":"The ISO 27001 certification, policy by policy","seoTitle":null,"description":"Going through an ISO 27001 implementation means that people in your company must work closely together towards that end, as most everyone will need to be involved in the process at one stage or the other. Across departments, team members will have to question their processes and their day-to-day work to make sure they are doing the right thing in the right way from a security perspective.","seoDescription":null,"date":"2021-09-30T09:07:50.384Z","featuredpost":true,"permalink":"ISO-27001-certification-standard-policies-procedures","featuredimage":{"publicURL":"/static/19f09646b5c55e3482cc77ef24c62411/scott-graham-5fnmwej4taa-unsplash.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/19f09646b5c55e3482cc77ef24c62411/1946f/scott-graham-5fnmwej4taa-unsplash.webp","srcSet":"/static/19f09646b5c55e3482cc77ef24c62411/19b88/scott-graham-5fnmwej4taa-unsplash.webp 205w,\n/static/19f09646b5c55e3482cc77ef24c62411/cb077/scott-graham-5fnmwej4taa-unsplash.webp 410w,\n/static/19f09646b5c55e3482cc77ef24c62411/1946f/scott-graham-5fnmwej4taa-unsplash.webp 820w,\n/static/19f09646b5c55e3482cc77ef24c62411/ea25e/scott-graham-5fnmwej4taa-unsplash.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":547}}}},"rawMarkdownBody":"\n<!--StartFragment-->\n\nAt some point during its activity, perhaps depending on size or maturity level, or rather based on industry requirements or customer requests, a company might decide to implement an ISMS (Information Security Management System) and obtain the ISO 27001 certification. This marks the beginning of an empowering, although intimidating journey.\n\n**Why empowering?**\n\nGoing through an ISO 27001 implementation means that people in your company must work closely together towards that end, as most everyone will need to be involved in the process at one stage or the other. Across departments, team members will have to question their processes and their day-to-day work to make sure they are doing the right thing in the right way from a security perspective. Some things may need to change, which means that employees will have to take part in security awareness training sessions. Others will be involved in evidence collection: can your company prove that it is operating securely? One thing's for sure: everyone in the company will have to CARE. It is empowering and meaningful to care about your place of work and the people you serve as a business.\n\n**Why intimidating?**\n\nIf you've never dealt with regulatory standards before, you might find the text hard to distill in terms of “to-do items\" — it's not necessarily vague, but not that specific either. Its purpose is to offer guidelines that are general enough to encompass the particularities of each organization. The standard references quite a few documents that the company may need to create from scratch and then adhere to. On top of it all, the entire process ends with an audit, which means that an external entity will analyze your work and judge its value.\n\n**There's help out there!**\n\nThere are many comprehensive resources available regarding ISO implementation, and all of them will point to documents that need to be created — be it policies, procedures, or other lists and registers. It's important to understand that some of them will be mandatory for ANY organization getting certified, while others will be mandatory only for some, depending on identified risks. Keep in mind that some of these policies might exist in your organization even before considering implementing the standard.\n\nBelow is the list of documents that any organization must create:\n\n-   ISMS scope document (cl. 4.3)\n-   Information Security Policy (cl. 5.1, 5.2, 5.3, 6.2)\n    -   defines how security objectives will be set, and it may include the objectives themselves\n    -   should include roles and responsibilities\n-   Risk assessment process definition (cl. 6.1.2)\n    -   describes how risk assessment is done\n-   Statement of Applicability (cl. 6.1.3)\n    -   for each control from the Annex, the company must state whether it applies to them or not\n-   Risk treatment process (cl. 6.1.3)\n    -   describes how addressing risk is done\n\nThen there will be the documented results of performing certain actions:\n\n-   Risk assessment results - performed regularly (cl. 8.2)\n    -   contains the results of the risk assessment\n-   Risk treatment plan - performed regularly (cl. 6.1.3, cl. 8.3)\n    -   contains the plan to address identified risk\n-   Evidence of competence of persons doing work that affects information security performance (cl 7.20)\n-   Evidence of monitoring and measurement results (cl 9.1)\n-   Evidence of audit results (9.2)\n-   Evidence of the results of management reviews (9.3)\n-   Evidence of nonconformities encountered and subsequent actions taken; evidence of the results of any corrective action (cl 10.1)\n\n\\\n**And then there's the Annex**\n\nThe risks identified during risk assessment can and should be addressed with controls provided by the Standard in Annex A. As some of these controls mandate that other policies, procedures, or documents are created, we can conclude that these will only be required when they help mitigate an identified risk. These additional documents are:\n\n-   Mobile device policy (A.6.2.1)\n-   Teleworking (Remote working) policy (A.6.2.2)\n-   Disciplinary process (A.7.2.3)\n-   Inventory of assets (A.8.1.1)\n-   Acceptable use of assets (A.8.1.3)\n-   Information labeling policy (A.8.2.2)\n-   Handling assets policy (A.8.2.3)\n-   Management of removable media policy (including disposal of media) (A.8.3.1)\n-   Access control policy (A.9.1.1)\n-   User access management policy (A.9.2.1, A.9.2.2, A.9.2.4)\n-   Use of cryptographic controls policy (A.10.1.1)\n-   Use, protection and lifetime of cryptographic keys (A.10.1.2)\n-   Working in secure areas (A.11.1.5)\n-   Clear desk and clear screen policy (A.11.2.9)\n-   Operating procedures (A.12.1.1)\n-   Backup policy (A.12.3.1)\n-   Installation of software policy (A.12.5.1)\n-   Information transfer policy (A.13.2.1)\n-   Secure development policy (A.14.2.1)\n-   Change control procedures (A.14.2.2)\n-   Secure systems engineering policy(A.14.2.5)\n-   IS Policy for supplier relationships (A.15.1.1)\n-   Information Security incidents response policy (A.16.1.1, A.16.1.5)\n-   Information security continuity policy (A.17.1.2)\n-   Legislation and contractual requirements (A.18.1.1)\n-   IP (A.18.1.2)\n\nIf you're a company that's just beginning to consider developing an ISMS and getting certified, you might need help creating some or all of these documents. Cyscale offers quite a few of them out-of-the-box, giving you the possibility to use them as templates and add customizations to your needs, or to just use them as they are.\n\n[Easy & continuous compliance for ISO 27001](https://cyscale.com/use-cases/iso-27001-compliance/), with a set of battle-tested policies to jumpstart your ISMS\n\n_Photo by Scott Graham_\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["Compliance"],"title":"Bridging the Gap Between ISO 27001 and Cloud-Native Systems","seoTitle":null,"description":"Being compliant is a huge selling point and many well-established customers will even require this from their service providers. One missing product feature will probably not make or break the deal, but missing compliance will.","seoDescription":null,"date":"2021-08-31T12:54:05.925Z","featuredpost":true,"permalink":"implementing-iso-27001-for-cloud-native-systems","featuredimage":{"publicURL":"/static/370d42a6af43f75d9ec833998dda8c2c/romain-dancre-doplsdelx7e-unsplash.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/370d42a6af43f75d9ec833998dda8c2c/f0c3d/romain-dancre-doplsdelx7e-unsplash.webp","srcSet":"/static/370d42a6af43f75d9ec833998dda8c2c/e58e4/romain-dancre-doplsdelx7e-unsplash.webp 205w,\n/static/370d42a6af43f75d9ec833998dda8c2c/1cfb4/romain-dancre-doplsdelx7e-unsplash.webp 410w,\n/static/370d42a6af43f75d9ec833998dda8c2c/f0c3d/romain-dancre-doplsdelx7e-unsplash.webp 820w,\n/static/370d42a6af43f75d9ec833998dda8c2c/c9029/romain-dancre-doplsdelx7e-unsplash.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":615}}}},"rawMarkdownBody":"\n<!--StartFragment-->\n\n<sub><sup>Photo by [Romain Dancre](https://unsplash.com/@romaindancre?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)</sup></sub>\n\n<!--EndFragment-->\n\n<!--StartFragment-->\n\nAnd no, unfortunately, ISO/IEC 270**17** - which focuses on cloud services - doesn't fill in the gap. Or at least not entirely.\n\nThe trend over the past few years has been clear: shift left. The idea is to identify and prevent issues (not only security-related) as soon as possible. This implies more collaboration during the day-to-day development and even mixed teams that handle all the aspects of the product (there is no limit to how many words we can fit between “Dev” and “Ops”).\n\nWhile some might be inclined to believe organizations are doing this just to cut down costs (of course this is one of the reasons and it should be), the reality is that the team that builds the product also knows the product best. A virtual machine that can theoretically be accessed on port 22 (SSH) from any IP might mean a security hazard to someone that sees the system for the first time. On the other hand, the team will probably have more context and will be able to provide a more accurate risk assessment - maybe the VM is not actually accessible over the internet because it's deployed in a private subnet. Context matters.\n\nAnd the truth is that most teams will happily take on more responsibility and/or collaborate closely with their colleagues. Actually, the best teams want and demand this. They want to contribute to the architecture of the product, be involved in the risk assessments, and help with sales. They will gladly do this as long as the **purpose is clear** and **the job involves actually building something** (this is what software engineers refer to as fun).\n\nOn the other hand, pursuing something like compliance with ISO 27001 which involves reading and writing a lot, might be met with some resistance. While some might get “fooled” when being told they will **build** an Information Security Management **System** (**ISMS** from now on), most people will stop listening when they hear compliance (are you still reading this?). But it doesn't have to be like this.\n\nBeing compliant is a huge selling point and many well-established customers will even require this from their service providers. One missing product feature will probably not make or break the deal, but missing compliance will.\n\n## The Standard\n\nThe ISO/IEC 27001:2013 standard is targeted towards information security. It guides us in the process of building an ISMS that takes a holistic approach (i.e. look at the facts from multiple perspectives) to achieve better **confidentiality, integrity, and availability of our assets (i.e. reduce risks)**.\n\nSince it can be applied in a wide range of industries and companies, ISO 27001 provides general recommendations and approaches. It doesn't tell us how to do anything and there is no recipe for success. **Looking through a simplified view, ISO 27001 guides us through our journey of discovering our assets, identifying risks, and devising strategies for eliminating, mitigating, and remediating the relevant risks.** These can go from ensuring we use encryption to having a designated responsible for contacting authorities when bad things happen (and they will happen).\n\nSo basically it helps us document how we protect our assets. Now, these assets can be anything from physical devices (e.g. laptops) to data stored in an S3 bucket. The standard covers all kinds of assets and situations such as a new employee joining the company (how are they assigned access? have we performed the relevant background checks?) or segregating our networks based on users and services.\n\nIn fact, ISO 27001 provides 114 controls structured in 14 sections (called clauses), each covering a specific area. For example, clause A.13 refers to communications security and has two objectives:\n\n-   Network security management\n-   Information transfer\n\nBoth objectives contain several so-called **controls** that aim to help us **reduce the risk** when applicable. One of the controls, A.13.2.3, refers to _Electronic messaging_ and says the following:\n\n_Information involved in electronic messaging shall be appropriately protected._\n\nThe control tells us what should be achieved, but doesn't tell us how. This is where the compliance team and the development team (usually represented by the architect) start gathering information. Their duty is to research the options and possibilities they have and to find out how the system/application handles it currently.\n\n### Translating ISO controls to the cloud\n\nAssuming they are building their software on top of a hyperscaler (AWS, Azure, Google Cloud), they might start by enforcing HTTPS traffic through security groups/firewalls and leveraging private subnets. This should be good enough for virtual machines, but their applications might use more services such as object storage (S3, Azure Blob Storage, GCS), load balancers, managed databases (RDS, Cloud SQL, the Azure SQL suite of services), integration services such as queueing and pub/sub systems, and the list goes on and on (and probably got longer while you were reading this article).\n\nAfter 6 days of research, they might have identified the following options, let's say on AWS:\n\n1. Since they have been using AWS for the past 9 years, they have to make sure all their EC2 instances are migrated and deployed in a VPC, as opposed to EC2-Classic.\n2. The security groups attached to the load balancers should allow traffic only on port 443.\n3. The load balancers should have TLS listeners set up and accept only safe cipher suites - e.g. it shouldn't accept TLS 1.0 or older SSL protocols that are considered unsafe.\n4. The security groups attached to virtual machines running the application should only accept traffic from the load balancer.\n5. Self-hosted databases such as Elasticsearch should only accept traffic from the EC2 instances running the application.\n6. RDS instances should not be publicly accessible and should only accept traffic from the same EC2 instances.\n7. S3 buckets should have a bucket policy that enforces HTTPS.\n8. S3 buckets should not allow public access through the bucket policy or the ACL (some buckets are pretty old so they heavily rely on ACLs).\n9. And finally, since they leverage AMIs, they would like to ensure that these are private.\n\nCovering all these should provide a great starting point to ensure electronic messaging security. The compliance team adds them to the policy (remember, the output of ISO 27001 is an ISMS which is a set of policies), the development team configures the infrastructure, and the target is achieved. Or is it?\n\n### If it hurts, do it more often\n\n**Adopting a standard means setting a new bar**. It means that all changes from now on must respect the new rules. Of course, the development team is unlikely to print the security policies and attach them to their wall so the product owner creates tasks with checklists as part of their stories. Everything is great now. Every time they add a new cloud resource all they have to do is to go through a 235 items checklist. And also they have to add the resource to their asset inventory.\n\nBeing smart engineers, the development team decides to use AWS Config and implement custom rules to perform these checks whenever a resource is changed. They plan to implement this over the next 4 months and try to keep the compliance team in the loop because they don't want to deal with a stack of Word documents (even though they represent the heart and soul of the compliance team).\n\nNow, if your organization is at this point, you adopted the DevOps culture at this level and you have all these resources, you will probably be fine. Of course, you will have to:\n\n1. practically spam all your employees with presentations about the policies\n2. train and retrain everyone involved including every new employee\n3. wonder whether anyone has actually ever read the policies\n4. wonder whether your research was comprehensive enough\n5. oppose adopting any new cloud provider because it would mean implementing and mapping all the controls again and again\n\n**However, if this sounds like a lot of work to do and/or you want to take your [ISO 27001 Compliance & Cloud Security](https://cyscale.com/use-cases/iso-27001-compliance/) to the next level by giving power to your policies and ultimately to your people, check out [cyscale.com](https://app.cyscale.com/ 'https://app.cyscale.com/').**\n\n<!--EndFragment-->\n"}},{"node":{"frontmatter":{"authors":"Ovidiu Cical","categories":["News"],"title":"How the largest Romanian real estate portal could have prevented a massive cloud data breach","seoTitle":null,"description":"The adoption of public cloud providers can bring many advantages to a business, but at the same time, cybersecurity threats can appear because of this usage.","seoDescription":null,"date":"2021-02-09T06:08:46.468Z","featuredpost":true,"permalink":"realestate-data-breach","featuredimage":{"publicURL":"/static/601e87d1e42c4db9236f5372131ceb7a/data-breach.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/601e87d1e42c4db9236f5372131ceb7a/df340/data-breach.webp","srcSet":"/static/601e87d1e42c4db9236f5372131ceb7a/f4465/data-breach.webp 205w,\n/static/601e87d1e42c4db9236f5372131ceb7a/c6392/data-breach.webp 410w,\n/static/601e87d1e42c4db9236f5372131ceb7a/df340/data-breach.webp 820w,\n/static/601e87d1e42c4db9236f5372131ceb7a/2e599/data-breach.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":316}}}},"rawMarkdownBody":"\n### Can cloud misconfigurations affect your company?\n\nYes, they can! In this case, Romania's largest real estate portal has suffered a data breach due to a misconfiguration. Website Planet detected that the portal's AWS S3 buckets were publicly available without any protection, back in December 2020. As a result, more than 200,000 records were exposed.\n\nAnyone with the URL could access the buckets and Personal Identifying Information (PII) stored there. Users' data such as full names, emails, phone numbers, Social Security Numbers (CNP), or even scanned copies of national ID cards including identifying codes were leaked.\n\nThe AWS (Amazon Web Services) S3 Access Points feature provides settings for access points, buckets, and accounts to help companies manage the public access to their resources. More information can be found on Amazon's Documentation Portal:\nhttps://aws.amazon.com/\npremiumsupport/\nknowledge-center/\nread-access-objects-s3-bucket\n\nBy default, new buckets do not allow public access. However, users can modify bucket policies and allow public access. Since these individual settings are customizations enabled to better suit a specific organization's needs, the responsibility is no longer with the cloud provider.\n\nEven if the unintentional breach was fixed after Website Planet reported it, the precise number of people affected remains unknown and the culpability for this data leak lies entirely with the real estate portal.\n\nThis could have easily been prevented with the implementation of a [Cloud Security Posture Management (CSPM) tool](https://cyscale.com/products/cloud-security-posture-management/). These solutions are developed to [detect any misconfigurations](https://cyscale.com/use-cases/cloud-misconfigurations/) and to prevent this type of event.\n\nAs a [CSPM](https://cyscale.com/blog/cloud-security-posture-management-cspm-guide/), Cyscale Cloud Platform is the perfect tool that helps companies reduce risk. It enables complete visibility and control over cloud accounts in under 5 minutes since deployment.\n\nCyscale's platform is equipped with an alert mechanism, that detects and informs security and cloud ops about exposed assets and helps them address these issues in time.\n\nMistakes such as having your company's buckets exposed, without password protection or encryption can be detected and fixed in time, you just need someone to guide you. We are ready to assist you with your Cloud Security.\n"}},{"node":{"frontmatter":{"authors":"Ovidiu Cical","categories":["News"],"title":"Hello Darkness, my old friend!","seoTitle":null,"description":"At Cyscale, we see Darkness as a force for good. It can obscure the less relevant and make the vital signals glow even brighter. We're introducing a dark mode for all users","seoDescription":null,"date":"2020-10-20T14:05:00.000Z","featuredpost":false,"permalink":"dark-theme","featuredimage":{"publicURL":"/static/6980073d35863daf32d05b1dd9bec6f3/darkprev.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/6980073d35863daf32d05b1dd9bec6f3/00400/darkprev.webp","srcSet":"/static/6980073d35863daf32d05b1dd9bec6f3/16688/darkprev.webp 205w,\n/static/6980073d35863daf32d05b1dd9bec6f3/e8095/darkprev.webp 410w,\n/static/6980073d35863daf32d05b1dd9bec6f3/00400/darkprev.webp 820w,\n/static/6980073d35863daf32d05b1dd9bec6f3/d12fb/darkprev.webp 1640w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":596}}}},"rawMarkdownBody":"\nAt Cyscale, we see Darkness as a force for good. It can obscure the less relevant and make the vital signals glow even brighter. We're introducing a **dark mode for all users**, regardless of their plan.\n\nThe new dark mode adapts automatically to your system's theme settings. It revamps every color, icon, and font in the app. It's easier on the eyes and even easier on the batteries of certain devices.\n\n<br/>\n\nA lot of people simply prefer it and we hope you will like it too. Any feedback is [welcome](https://cyscale.com/contact-us/).\n\n<br/>\n"}}]}},"pageContext":{"limit":9,"skip":81,"numPages":11,"currentPage":10,"category":"All","seoTitle":"Blog Page 10 - Cyscale","seoDescription":"Cloud and Data Security Blog","categoriesList":["Compliance","Engineering","Cloud Native Security","News","Cloud Security","IAM","CNAPP","Product","CSPM","Misconfigurations","Encryption"],"heading":"All you need to know about protecting SaaS apps and data in the cloud"}},"staticQueryHashes":["1117504136","2024892666","220583031","273821743","3722074465","4068795820","4109069157","81406208","981947644"],"slicesMap":{}}