{"componentChunkName":"component---src-template-blog-template-js","path":"/blog/soc-2-vs-ISO-27001-SaaS/","result":{"pageContext":{"alldata":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["Compliance"],"title":"SOC 2 vs ISO 27001: What every SaaS needs to know","seoTitle":"SOC 2 vs ISO 27001: What every SaaS needs to know","description":"When looking into consolidating your data protection services, you may decide to implement SOC 2 or ISO 27001. Acquiring one of these accreditations is a thorough process and choosing the right one for your company is the first step. In case you are a SaaS provider and are not certain which one to choose, this article maps out the key differences between them.\n","seoDescription":"A comparison between the standards SOC 2 and ISO 27001 and how to acquire them, including price, duration and others.","date":"2022-03-29T06:31:44.659Z","featuredpost":true,"permalink":"soc-2-vs-ISO-27001-SaaS","featuredimage":{"publicURL":"/static/48809b2bb298642ad9c8e20940f43f8f/microsoftteams-image.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/48809b2bb298642ad9c8e20940f43f8f/888e2/microsoftteams-image.webp","srcSet":"/static/48809b2bb298642ad9c8e20940f43f8f/913d0/microsoftteams-image.webp 205w,\n/static/48809b2bb298642ad9c8e20940f43f8f/91660/microsoftteams-image.webp 410w,\n/static/48809b2bb298642ad9c8e20940f43f8f/888e2/microsoftteams-image.webp 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[]},"width":820,"height":460}}},"tableOfContents":null},"rawMarkdownBody":"When looking into consolidating your data protection services, you may decide to implement one of the following two standards:\n\n* SOC 2\n* ISO 27001\n\nAcquiring one of these accreditations is a thorough process and choosing the right one for your company is the first step.\n\n**In case you are a SaaS provider** and are not certain which one to choose, keep reading to understand the key differences between them.\n\n**What are these accreditations** and what is their scope?\n\nThe SOC 2 and [ISO 27001](https://cyscale.com/use-cases/iso-27001-compliance/) standards are normally acquired by B2B (Business-to-business) companies.\nThey:\n\n* represent international standards for Information Security Management Systems (ISMSs)\n* describe best practices for service providers who manage customer data\n\nAs a SaaS, in order to obtain one of the two accreditations, you must implement all the policies of that standard that apply to your organization.\n\n**What do these standards say about your company?**\n\nSOC 2 and ISO 27001 are very similar.\nAcquiring one of them promotes the following principles about your organization:\n\n* You recognize the importance of cybersecurity\n* Your company is making efforts to mitigate information security risks\n* You are properly managing information security\n\nGiven the statements above, you can safely assume that a customer will prefer an organization with one of the described accreditations in their possession, to the detriment of one without any.\n\n### A comparison\n\n#### Geographical recognition\n\n* SOC 2 is governed by The American Institute of Certified Public Accountants (AICPA)\n* ISO 27001 was developed by ANSI-ASQ National Accreditation Board (ANAB)\n\n#### Duration\n\n* SOC 2: an audit takes **between 3 to 12 months**, depending on the type of audit\n* ISO 27001: takes **between 12 to 18 months** to complete\n\n#### Validity duration\n\n* For SOC 2: one year\n* For ISO 27001: three years (with surveillance audits once every year)\n\n##### Requirements\n\n**For SOC 2**, you need to fulfill **64 criteria** integrated through five trust service criteria (TSC), as seen below (along with a few criteria examples):\n\n1. Security\n\n   * Contains Security Incidents\n   * Communicates Remediation Activities\n2. Availability\n\n   * Identify environmental threats\n   * Measure Current Usage\n3. Processing Integrity\n\n   * Create and maintain records of system inputs\n   * Defines processing activities\n4. Confidentiality\n\n   * Identify confidential information\n   * Destroy confidential information\n5. Privacy\n\n   * Use clear and conspicuous language\n   * Collect information from reliable sources\n\n**For ISO 27001**, you need to:\n\n1. Implement an ISMS (Information Security Management Systems)\n2. Fulfill **7 requirements with 114 suggested controls** divided into 14 sections.\n\nThe requirements are described in the following clauses:\n\n* Clause 4: Context of the organization\n* Clause 5: Leadership\n* Clause 6: Planning\n* Clause 7: Support\n* Clause 8: Operation\n* Clause 9: Performance evaluation\n* Clause 10: Improvement\n\nIn the Annex of ISO 27001, you can find a list of controls and objectives to help you meet the requirements.\n\nYou can find more information [here](https://cyscale.com/blog/ISO-27001-certification-standard-policies-procedures/).\n\n**Price (of audit)**\n\n* For SOC 2, the cost depends on the type of audit and can range **between $5,000 and $60,000** with an average of about $20,000.\n* For ISO 27001, the price of an audit depends on the number of employees in the organization. It can go **as low as $5,400 up to $27,000**.\n\nIt is important to note that the price of implementing the standards may significantly increase the total cost of obtaining the accreditation.\n\nOne thing to note is that, although SOC 2 and ISO 27001 seem very different, their specifications overlap.\n\nThe level of similarity between the requirements of the two depends on:\n\n* The type of business you run\n* The scope of the audit\n\nThe similarity can be between 53% and 90%, according to AICPA’s mapping to ISO 27001.\n\nTaking into account all of the differences and similarities of the SOC 2 accreditation and the ISO 27001 certification, you can now choose the best standard for your company.\n\nFinally, implementing all the policies required by the described standards can be a difficult and time-consuming task.\n\nYou can make this process easier for you.\n\nWith [Cyscale](https://cyscale.com/), you can ensure easy and continuous compliance for ISO 27001.\n\nCyscale helps you meet the much-needed requirements described by this standard.\n"},"suggestions":[{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News"],"title":"Inside the Mind of an Attacker: How Contextual Security Can Save Your Cloud","seoTitle":"Inside the Mind of an Attacker: How Contextual Security Can Save Your Cloud","description":"The future of cloud security is contextual security. To fully understand how secure an asset is, you need to understand what users have permissions to interact with it and what resources it communicates with. It might seem that a VM is completely secure because you put it behind a firewall, but if a compromised user can access it, it’s game over. \n\nThe perfect recipe for contextual security is a Cloud Security Knowledge Graph. Based on it, we can represent in a visual and interactive way how cloud resources interact, what kind of relations they have, what users have permissions to read/write on them, and so on.  \n\nTo illustrate my point, I will show you some scenarios where the difference between a secure cloud and a breach is made by fixing misconfigurations and limiting users' access. These measures are easier to identify using a graph, because it helps you understand the risks your environment is exposed to.  ","seoDescription":"The future of cloud security is contextual security. To fully understand how secure an asset is, you need to understand what users have permissions to interact with it and what resources it communicates with. It might seem that a VM is completely secure because you put it behind a firewall, but if a compromised user can access it, it’s game over.   The perfect recipe for contextual security is a Cloud Security Knowledge Graph. Based on it, we can represent in a visual and interactive way how cloud resources interact, what kind of relations they have, what users have permissions to read/write on them, and so on.    To illustrate my point, I will show you some scenarios where the difference between a secure cloud and a breach is made by fixing misconfigurations and limiting users' access. These measures are easier to identify using a graph, because it helps you understand the risks your environment is exposed to.  ","date":"2023-09-19T09:01:02.199Z","featuredpost":true,"permalink":"contextual-security-google-cloud","featuredimage":{"publicURL":"/static/7fbef8aa4e6e383ec434207181f0d892/blog_54-cover.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/7fbef8aa4e6e383ec434207181f0d892/2c0f5/blog_54-cover.jpg","srcSet":"/static/7fbef8aa4e6e383ec434207181f0d892/41be8/blog_54-cover.jpg 205w,\n/static/7fbef8aa4e6e383ec434207181f0d892/c78f7/blog_54-cover.jpg 410w,\n/static/7fbef8aa4e6e383ec434207181f0d892/2c0f5/blog_54-cover.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/7fbef8aa4e6e383ec434207181f0d892/913d0/blog_54-cover.webp 205w,\n/static/7fbef8aa4e6e383ec434207181f0d892/91660/blog_54-cover.webp 410w,\n/static/7fbef8aa4e6e383ec434207181f0d892/888e2/blog_54-cover.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"When public cloud providers such as Google Cloud and AWS first appeared, their benefits were hard to ignore. And although companies were reluctant to put their infrastructure and applications in the hands of a different company, cloud solutions have grown in popularity.  \n\nWith more and more complex setups, it is hard for an organization to understand and keep track of the implication of every resource they have in the cloud, the risk it poses to the entire infrastructure or how many other assets it impacts. \n\nI believe the future of cloud security is contextual security. To fully understand how secure an asset is, you need to understand what users have permissions to interact with it and what resources it communicates with. It might seem that a VM is completely secure because you put it behind a firewall, but if a compromised user can access it, it’s game over. \n\nThe perfect recipe for contextual security is a [Cloud Security Knowledge Graph](https://cyscale.com/blog/security-knowledge-graph-integrations/). Based on it, we can represent in a visual and interactive way how cloud resources interact, what kind of relations they have, what users have permissions to read/write on them, and so on.  \n\nTo illustrate my point, I will show you some scenarios where the difference between a secure cloud and a breach is made by fixing misconfigurations and limiting users' access. These measures are easier to identify using a graph, because it helps you understand the risks your environment is exposed to.  \n\n## Case Study \n\nLet’s assume we use BigQuery in Google Cloud for a health analytics application. We have a table that contains some datasets of patients from a hospital, including PII data. These datasets are very valuable and cannot fall in the hands of outsiders. \n\nNow, we want to make sure that the data is securely stored. We look at the BigQuery table’s graph to see if the table poses any risk and, low and behold, it does! \n\n<img src=\"/img/blog_54-graf-0.png\" alt=\"Contextual security through the graph\" title=\"Contextual security through the graph\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nWe can observe, in the image above, that no less than 7 Cloud Functions and 4 VMs can access it across 9 Service Accounts that have permissions on the BigQueryTable, as well as 7 IAM Users. Does this alarm you? It should. \n\nBut just because a VM, or a function, can have access to the table does not mean anything, right? Wrong! I’m going to show you exactly how bad things can get in this situation. I’m going to put my hacker shoes on and show you potential scenarios that might lead to data being stolen. \n\n### Scenario 1: compromised VM \n\nOut of the 4 VMs that we see in the image, one is an Internet-facing one. The compute instance “dev-1” hosts an application that has the Log4J vulnerability, a classic. A hacker leverages the vulnerability and gains access to the instance, being able to execute commands on it, and the disaster begins. **Because a Service Account is associated to the VM, the attacker has that account’s permissions.** In our scenario, the application running on the Instance needs to process data in the dataset, so the associated Service Account was given the roles/bigquery.dataEditor permission. \n\nMoreover, in a VM, credentials used to manually authenticate are stored on the Compute Instance after the first time a user authenticates as a Service Account, in */.config/gcloud/credentials.db*, as you can see in the image below. \n\n<img src=\"/img/blog_54-ss1.png\" alt=\"Credentials stored in Google Cloud VM\" title=\"Credentials stored in Google Cloud VM\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nThis is a standard location and it stores the last private key that was used to authenticate as a Service Account.  You can also find access tokens in the same folder, in access_tokens.db. Moreover, you can see any other private keys used previously (which may still be valid, if they were not deleted in the Google Cloud Console) in */.config/gcloud/legacy_credentials/<serviceAccountEmail>/adc.json*. \n\nLooking at the file credentials.db, we notice that the information is not stored in the standard format for a private key for a Service Account. With a few adjustments, we obtain a valid private key that we then use to authenticate. To authenticate as a Service Account with a private key, simply use the following command:  \n\n```\ngcloud auth activate-service-account <serviceAccountEmail> --key-file=<keyFile>\n```\n\n<img src=\"/img/blog_54-ss2.png\" alt=\"Authenticating using the secret key\" title=\"Authenticating using the secret key\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nHowever, what happens when no one has authenticated as a Service Account on the VM? There is no *credentials.db* file (actually, there is no *.config* folder).  \n\nDevelopers tend to find ways to do things faster, and they get comfortable. It is not uncommon to find secrets in environment variables or plain-text files. If a developer were to store a secret key file on the Compute Instance, we could abuse it. Simply log in using the private RSA key file: \n\n<img src=\"/img/blog_54-ss3.png\" alt=\"Private key on the VM\" title=\"Private key on the VM\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n<img src=\"/img/blog_54-ss4.png\" alt=\"Authenticating as Service Account\" title=\"Authenticating as Service Account\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nChecking the current permissions, and… bingo! roles/bigquery.dataEditor is one of the available roles. \n\n<img src=\"/img/blog_54-ss5.png\" alt=\"Service Account with roles/bigquery.dataEditor\" title=\"Service Account with roles/bigquery.dataEditor\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nIf we expand the graph’s nodes that we used in this chain of attacks, you can clearly see the attack path: \n\n<img src=\"/img/blog_54-primul-graf.png\" alt=\"Attack path through the VM\" title=\"Attack path through the VM\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nWith the bigquery.dataEditor role, the attacker can now: \n\n* view data and metadata, \n* modify data and metadata, \n* delete tables. \n\n This breach could be avoided by: \n\n* ensuring the VM does not have vulnerabilities and patching the Log4J one, \n* isolating the Compute Instance from the Internet by closing the exposed port, if possible, \n* restricting the Service Account’s permissions as much as possible \n* making sure secrets are cleared from the VM files.   \n\n<img src=\"/img/blog_54-ss6.png\" alt=\"Access to the BigQueryTable datasets\" title=\"Access to the BigQueryTable datasets\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\n### Scenario 2: compromised user \n\nExpanding the Users node, we see that there are three users that have access to the BigQueryTable.  \n\n<img src=\"/img/blog_54-ultimul-graf.png\" alt=\"Attack path through user compromise\" title=\"Attack path through user compromise\" class=\" blog-image-shadow \" style=\"width:auto;height:auto;\"/>\n\nIf a hacker were to take over any of those accounts, for example, by stealing credentials, our customer’s data would be at risk. If one of the three users that have access to the table does not have MFA enforced, then the attacker can compromise the account.  \n\nEnabling MFA would prevent this. \n\nBesides this, a common mistake is focusing on protecting your environment from the outside, and forgetting about your own users. If one of the employees in the organization has too many permissions, they may produce damage without intention. By exploring the account and looking at resources, a user can accidentally modify or delete an asset. \n\nThis is why the Least Privilege Principle is so important – always limit the users’ access as much as possible and only assign the necessary permissions. \n\nWe believe that context is the future of cloud security. We’ve seen how the most simple relations between assets can be leveraged by attackers to take over cloud assets; and if your customers’ data is stored in those assets, the greater the prize is for hackers – and they will do anything to get it."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["News"],"title":"Cyber Safety Review Board Rings Alarm Bells for Shared Responsibility in the Cloud","seoTitle":"Cyber Safety Review Board Rings Alarm Bells for Shared Responsibility in the Cloud","description":"The Cyber Safety Review Board (CSRB) of the Department of Homeland Security is now embarking on its third cyber vulnerability review since the body was created in February 2022. During August, when lots of people were on summer vacation, a critical vulnerability in the authentication process for Azure Active Directory was exposed.\nAs with the two vulnerabilities the CSRB reviewed previously - Log4J in July of 2022 and Lapsus$ also in August of 2023 – the Azure Active Directory vulnerability highlights significant challenges in terms of remediation, due to the sprawling nature of cloud resources and their direct and indirect dependencies on assets that might, or might not, be affected.  ","seoDescription":"The Cyber Safety Review Board (CSRB) of the Department of Homeland Security is now embarking on its third cyber vulnerability review since the body was created in February 2022. During August, when lots of people were on summer vacation, a critical vulnerability in the authentication process for Azure Active Directory was exposed. As with the two vulnerabilities the CSRB reviewed previously - Log4J in July of 2022 and Lapsus$ also in August of 2023 – the Azure Active Directory vulnerability highlights significant challenges in terms of remediation, due to the sprawling nature of cloud resources and their direct and indirect dependencies on assets that might, or might not, be affected.","date":"2023-09-07T09:02:20.333Z","featuredpost":true,"permalink":"cyber-safety-review-board-on-cloud-security","featuredimage":{"publicURL":"/static/87ae3652b6af1c7dbe17d3182650a181/53_blog-csrb.jpeg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/87ae3652b6af1c7dbe17d3182650a181/2c0f5/53_blog-csrb.jpg","srcSet":"/static/87ae3652b6af1c7dbe17d3182650a181/41be8/53_blog-csrb.jpg 205w,\n/static/87ae3652b6af1c7dbe17d3182650a181/c78f7/53_blog-csrb.jpg 410w,\n/static/87ae3652b6af1c7dbe17d3182650a181/2c0f5/53_blog-csrb.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/87ae3652b6af1c7dbe17d3182650a181/913d0/53_blog-csrb.webp 205w,\n/static/87ae3652b6af1c7dbe17d3182650a181/91660/53_blog-csrb.webp 410w,\n/static/87ae3652b6af1c7dbe17d3182650a181/888e2/53_blog-csrb.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"The Cyber Safety Review Board (CSRB) of the Department of Homeland Security is now embarking on its third cyber vulnerability review since the body was created in February 2022. During August, when lots of people were on summer vacation, a critical vulnerability in the authentication process for Azure Active Directory was exposed.  \n\nAs with the two vulnerabilities the CSRB reviewed previously - Log4J in July of 2022 and Lapsus$ also in August of 2023 – the Azure Active Directory vulnerability highlights significant challenges in terms of remediation, due to the sprawling nature of cloud resources and their direct and indirect dependencies on assets that might, or might not, be affected.  \n\nEven for large organizations with sizeable security teams, navigating a complex dependency graph to understand which resources have dependencies on affected assets is a challenge. For SaaS startups with perhaps a handful of people building out their technology stack, such investigations are impossible.  \n\nAs a result, the findings of the CSRB’s reports and its recommendations for best practice build a strong case for contextually aware cloud security practices.  \n\n## How does this affect you (and everyone else)? \n\nIn its most recent announcement, the CSRB made it clear that identity access management (IAM) and authentication are in focus due to being one of the most vulnerable areas in a cloud environment. Identity management vulnerabilities are a key entry point for hackers, and SaaS companies and large enterprises are falling victim repeatedly. From IAM misconfigurations that CTOs and developers miss when setting up and managing their environment, to cloud service provider bugs, this area needs critical attention to ensure safe and secure cloud environments. \n\n## Did I just say cloud service provider bugs?  \n\nYes, I did. The incident in question that kicked off this latest review less than two months ago, was the discovery of a critical vulnerability in the authentication process for Azure Active Directory (soon to be renamed Microsoft Entra ID) that was allowing hackers to fabricate authentication tokens. Around 25 organizations including US government entities were impacted by this bug before it was discovered, with attackers stealing mailbox data and obtaining access to sensitive emails.  \n\nFor cloud native organizations building their entire business on public cloud platforms, this shared responsibility model is one of the most misunderstood (or ignored) aspects.  \n\nWhen the terms & conditions say that the cloud is a ‘shared responsibility’, it really is. It’s the cloud service provider’s job to secure the platform or infrastructure, and your job to secure the apps and data, and if one party fails (in this case, the cloud service provider – Microsoft Azure), your company, and potentially your customers and partners, are left exposed. \n\nThe CSRB’s previous two reports on [Log4j](https://www.cisa.gov/resources-tools/resources/csrb-log4j-key-findings-and-recommendations-summary) and [Lapsus$](https://www.cisa.gov/resources-tools/resources/review-attacks-associated-lapsus-and-related-threat-groups-executive-summary) have been very thorough and made some great recommendations that we hope will advance cybersecurity practices, which is why we’re eagerly waiting for CSRB’s report on cloud security. It not only promises a thorough set of recommendations for CISOs, CTOs, and developers, but it will also sound the alarm for cloud service providers.  \n\nAlthough the Cyber Safety Review Board has no regulatory power, its findings are transmitted to US President Biden and used to develop Executive Orders, so we can expect to see its influence in regulations such as [HIPAA](https://cyscale.com/blog/hipaa-compliance-in-cloud/), and perhaps best practices adopted into SOC 2, ISO 27001, and others. \n\n## The importance of contextual security \n\nWhat’s become evident is that simply informing businesses and cloud providers of the discovery of far-reaching misconfigurations and vulnerabilities is not enough. In fact, the potential workload created by responding to these challenges can be just as dangerous in that it can consume all an organization’s security resources.  \n\nContext is important and [contextual security](https://cyscale.com/blog/security-knowledge-graph-integrations/) is the most significant development in cloud infrastructure security in recent years. Identifying that a VM has the Log4J vulnerability is not the same as saying that an Internet-facing VM has the same vulnerability. Of course, they are both just as vulnerable, but if the first VM is running in a private network, the severity is not as high as for the one accessible from the Internet. The risk is not the same, but the alert will be, and we all know alert fatigue is a very real problem.  \n\nWrong prioritization, or no prioritization at all, can make all the difference between a secure cloud environment and a breach."}},{"node":{"frontmatter":{"authors":"Andrei Ștefănie","categories":["News"],"title":"IPv4 Billing Changes in AWS: Impact on Cloud Costs & Security","seoTitle":"IPv4 Billing Changes in AWS: Impact on Cloud Costs & Security","description":"Explore how AWS's new IPv4 billing changes, effective from February 2024, will influence both your financial and security strategies. Understand the implications for small startups to large enterprises, from cost optimization to IPv6 transition, NAT64, and security enhancements.","seoDescription":"Explore how AWS's new IPv4 billing changes, effective from February 2024, will influence both your financial and security strategies. Understand the implications for small startups to large enterprises, from cost optimization to IPv6 transition, NAT64, and security enhancements.","date":"2023-08-31T09:03:04.258Z","featuredpost":true,"permalink":"aws-ipv4-impact-on-cloud-costs-and-security","featuredimage":{"publicURL":"/static/e4eb30151713435e89ec3c37c4832ca7/aws-ipv4-article.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/e4eb30151713435e89ec3c37c4832ca7/2c0f5/aws-ipv4-article.jpg","srcSet":"/static/e4eb30151713435e89ec3c37c4832ca7/41be8/aws-ipv4-article.jpg 205w,\n/static/e4eb30151713435e89ec3c37c4832ca7/c78f7/aws-ipv4-article.jpg 410w,\n/static/e4eb30151713435e89ec3c37c4832ca7/2c0f5/aws-ipv4-article.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/e4eb30151713435e89ec3c37c4832ca7/913d0/aws-ipv4-article.webp 205w,\n/static/e4eb30151713435e89ec3c37c4832ca7/91660/aws-ipv4-article.webp 410w,\n/static/e4eb30151713435e89ec3c37c4832ca7/888e2/aws-ipv4-article.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"Beginning February 1, 2024, Amazon Web Services (AWS) will usher in a significant change by charging for public IPv4 addresses. Whether you are a seasoned cloud engineer or a business decision-maker this shift by one of the world's leading cloud providers will likely have broad implications.\n\nAWS's decision aligns with other major cloud providers that have adopted similar practices, reflecting an industry-wide trend. AWS's involvement is particularly significant given its substantial market presence, and it will likely influence various organizations across different scales and industries.\n\nIn terms of your business and the tech landscape, this change goes beyond additional costs, with the new model affecting network planning, igniting considerations about transitioning to IPv6, and opening opportunities to reassess cloud security strategies.\n\n## The Financial Implications of AWS's New Charging Model for IPv4 Addresses\n\n### Detailed Explanation of Pricing\n\nStarting February 1, 2024, AWS will charge for all public IPv4 addresses at a rate of 0.5 cents per hour. While this figure may initially seem inconsequential, it is vital to understand how swiftly it can accumulate. \n\nFor small businesses or individual projects, the impact might be marginal. Our example considers a small organization with 10 public IP addresses:\n\n*10 IPs x 0.5 cents per hour x 730 hours in a month = $36.5 per month, or $438 per year.*\n\nContrast this with an enterprise operating with 11,000 public IPs: \n\n*11,000 IPs x 0.5 cents per hour x 730 hours in a month = $40,150 per month, or nearly **$500,000 per year**.*\n\n1﻿1,000 IP addresses might sound like an overestimation, but we are seeing organizations with tens of thousands of EC2 instances. Assuming 20-30% of these need public IPs is not out of reach.\n\nThis striking difference highlights the importance of understanding and planning for the financial consequences, particularly for organizations heavily reliant on public IPv4 addresses.\n\n### Budget Considerations for Organizations\n\nAWS's decision to charge for public IPv4 addresses extends beyond a simple financial concern; it prompts businesses to reevaluate their entire approach to IP address utilization. Key considerations include:\n\n* **Reviewing existing usage:** Analyzing current usage patterns is essential for predicting additional costs and identifying opportunities for optimization.\n* **Considering IPv6 migration:** Some may find transitioning to IPv6 a cost-effective alternative, though it must be balanced against compatibility and technical constraints.\n* **Utilizing tools and insights:** Automated security platforms like Cyscale can offer comprehensive insights into your inventory of public IP addresses, helping you understand the big picture and delivering insight that can aid in cost control.\n\nThis policy change serves as a catalyst for reimagining how organizations approach cloud infrastructure financially. The ripple effects will be felt differently across the spectrum, but the core message is clear: understanding, planning, and adapting will be pivotal in navigating this change without unforeseen financial setbacks.\n\nWhether you are a decision-maker concerned about the bottom line or a cloud professional tasked with optimization, these changes necessitate close scrutiny and proactive planning.\n\n## Technical Aspects and Considerations\n\n### Impact on EC2 Instances, RDS, EKS, etc.\n\nThe new charging model impacts a broad array of resources, including EC2 instances, RDS, EKS, load balancers, and more. Managing complex architectures now entails a new layer of complexity, possibly requiring a reassessment of networking strategies and configurations.\n\n### The Complexity of Managing Multiple IP Addresses per Resource\n\nSome resources may have more than one public IPv4 address. Managing these involves not just technical configuration but also financial planning. Understanding how these multiple IPs interact within your infrastructure and contribute to overall costs is essential. \n\n### Discussion on the Feasibility and Challenges of Switching to IPv6\n\nThe move to IPv6 seems logical, but it's not devoid of challenges. Compatibility with services and APIs managed by others might become a hurdle. AWS has made progress, such as enabling communication from EC2 to Lambda functions over IPv6 (note that you cannot reach an EC2 instance from Lambda over IPv6), yet some cases may still hinder a complete switch.\n\n### IPv4 to IPv6 Transition Mechanisms\n\nDuring the transition, Network Address Translation (NAT), specifically NAT64, becomes vital. This mechanism translates IPv6 to IPv4 addresses, bridging communication between newer IPv6 systems and legacy IPv4 systems. Understanding and utilizing NAT64 is crucial for modernizing without losing functionality. Equally important is DNS64 which performs the translation at the DNS level. More specifically, in the case a domain is mapped only to an IPv4 address (i.e., it only has A records), DNS64 translates an A record (specific to IPv4) to an AAAA record (specific to IPv6), thus allowing an IPv6 client to reach an IPv4 server.\n\n### Proficiency with Security Groups and Other Network Considerations\n\nWith all IPv6 addresses being public, mastering security groups and leveraging egress-only internet gateways become even more critical. Properly configuring security rules and comprehending their interaction with different IP versions plays a significant role in upholding security and functionality within your network.\n\nThe new AWS charging model for public IPv4 addresses is more than a financial consideration. It intertwines with a multifaceted web of technical aspects that must be thoughtfully navigated. Embracing the right strategies and tools can pave the way for a seamless transition, preserving both efficiency and budget.\n\n## Security Implications\n\n### Reevaluation of Network Exposure\n\nThe new charges for public IPv4 addresses might encourage organizations to scrutinize network exposure more closely. Reducing the number of public IPs could be both a cost-saving measure and a strategy to enhance security by limiting the **attack surface.**\n\n### Importance of Secure Configuration in IPv6 Transition\n\nTransitioning to IPv6, while potentially cost-effective, demands careful consideration of security configurations. Understanding IPv6 security nuances is vital in safeguarding systems during and after the shift. While NAT64 facilitates communication between IPv6 and IPv4 systems, it also introduces unique security considerations. Proper implementation and continuous vigilance are required to ward off vulnerabilities that might arise during the translation process. In practice, most organizations will leverage the AWS NAT Gateway which already supports NAT64 and DNS64 (through Route 53) so our responsibility includes proper route configuration and keeping DNS resolvers up to date. However, other organizations might choose to deploy their own NAT instance to optimize cost.\n\n### Tools and Platforms for Security Management\n\nAutomated cloud security platforms like Cyscale can play a pivotal role in this secure transition. By providing insights into all public IP addresses, their attachments, and alternative communication paths, they can facilitate a more secure and cost-effective migration. Utilizing specialized security platforms and tools is fundamental to maintaining control over complex cloud environments.\n\nThis new AWS charging model for public IPv4 addresses is more than a technical and financial hurdle; it's an opportunity to rethink and potentially enhance security strategies. By understanding the interplay between IPv4 and IPv6, the role of the transition mechanisms, and the necessity of proper security configurations, organizations can navigate this transition without compromising security.\n\n## The Role of Cloud Security Platforms\n\nAutomated cloud security platforms like Cyscale are more than just a reactive measure to changes like AWS's new charging model for public IPv4 addresses; they represent a proactive approach to modern cloud infrastructure management. By providing tools that cut across cost optimization, security enhancement, migration planning, and collaboration, these holistic solutions enable organizations to thrive in an evolving cloud landscape."}},{"node":{"frontmatter":{"authors":"Sabrina Lupșan","categories":["CSPM"],"title":"Securing VMs in Google Cloud: Shielded VM and Other Features You Never Knew Existed ","seoTitle":"Securing VMs in Google Cloud: Shielded VM","description":"Best practices for securing VMs in Google Cloud, including the Shielded VM feature description and practical steps to enable it.","seoDescription":"Best practices for securing VMs in Google Cloud, including the Shielded VM feature description and practical steps to enable it.","date":"2023-08-23T15:16:04.584Z","featuredpost":true,"permalink":"securing-google-cloud-compute-shielded-vm","featuredimage":{"publicURL":"/static/f8641a2b38562362996601473551a92f/51-cyscale-blog-min.jpg","childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/f8641a2b38562362996601473551a92f/2c0f5/51-cyscale-blog-min.jpg","srcSet":"/static/f8641a2b38562362996601473551a92f/41be8/51-cyscale-blog-min.jpg 205w,\n/static/f8641a2b38562362996601473551a92f/c78f7/51-cyscale-blog-min.jpg 410w,\n/static/f8641a2b38562362996601473551a92f/2c0f5/51-cyscale-blog-min.jpg 820w","sizes":"(min-width: 820px) 820px, 100vw"},"sources":[{"srcSet":"/static/f8641a2b38562362996601473551a92f/913d0/51-cyscale-blog-min.webp 205w,\n/static/f8641a2b38562362996601473551a92f/91660/51-cyscale-blog-min.webp 410w,\n/static/f8641a2b38562362996601473551a92f/888e2/51-cyscale-blog-min.webp 820w","type":"image/webp","sizes":"(min-width: 820px) 820px, 100vw"}]},"width":820,"height":460}}},"tableOfContents":false},"rawMarkdownBody":"While assessing the controls suggested by the CIS Benchmark 2.0.0 for Google Cloud, I stumbled upon an interesting recommendation: to launch compute instances with Shielded VM enabled. When you think of VM security, you think of open management ports, outdated OS versions, unencrypted VM disks and so on. So what is Shielded VM and why do you need to enable it ASAP? \n\n\n\n## Shielded VM \n\nShielded VM, in a cloud computing context, is a security solution that hardens VMs deployed in Google Cloud. This measure protects them against rootkits and bootkits, which are essentially malware that infect and obtain persistence in VMs, allowing attackers to infiltrate in the cloud environment through the Compute Instances. It’s like a magical portal into your entire cloud infrastructure, which, if created, opens on command for the hackers.    \n\nThe advantage of this setting is that, with just a few clicks, you significantly increase the protection of your [Google Cloud](https://cyscale.com/use-cases/gcp-cloud-security/) VM by providing it with: \n\n* Secure Boot, \n* vTPM, \n* Integrity monitoring. \n\n**Secure Boot** is a feature that verifies the digital signature of all boot components of a virtual machine. In this way, if any signature verification fails, that boot process is halted, thus ensuring that only authentic software is run on the system. This means that you cannot use any custom drivers on the machine, because if you do, it will cause the VM to not boot anymore. If a failure occurs, the user receives two errors:\n\n* **UEFI: Failed to load image**, and \n* **Status: Security Violation.** \n\n**vTPM, or Virtual Trusted Platform Module,** is a computer chip specialized in protecting secrets. To understand what vTPM is, let’s break it down. TPM, or Trusted Platform Module, is a hardware component that stores cryptographic keys, passwords, and other sensitive data securely. By virtualizing it, the same result is achieved, but on a software level, meaning that VMs in the cloud can also be protected using a TPM, even though at hardware-level they may share components with other VMs. \n\nvTPM also introduces **Measure Boot**, a mechanism that checks the integrity of the VM’s components. When the VM first boots, Measure Boot establishes an **integrity policy** baseline by calculating hashes of the components, concatenating them and rehashing them into a final hash to guarantee a sound integrity monitoring. Then, every time the VM boots up, the hash is recalculated and checked against the initial one, thus being able to tell if there are any changes in the boot process. \n\nThe integrity policy baseline needs to be updated if changes appear, such as a system update. \n\nThrough the process described, **integrity monitoring** is achieved using Shielded VM and the Measure Boot mechanism. \n\n\n\n### How to enable Shielded VM \n\nTo enable Shielded VM, you can do it through the Google Cloud console, or using the Cloud shell.  \n\n**Using the Google Cloud console** \n\n1. Log in to your Google Cloud console and navigate to Compute Instances (or click [here](https://console.cloud.google.com/compute/instances)). \n2. For each VM on which you want to enable the feature, follow these steps: \n\n   1. Click on the VM name to go to its details page.\n   2. On the upper right area of the page, select EDIT. \n   3. Scroll down to “Security and access” and check boxes accordingly to your desired settings. Please note that you cannot select “Integrity Monitoring” without checking “Turn on vTPM”, as Integrity monitoring is a feature provided by vTPM. \n\n**Using the Cloud shell** \n\n1. Stop the instance: \n\n`gcloud compute instances stop <instanceName>`\n\n2. Turn on vTPM and Integrity Monitoring: \n\n`gcloud compute instances update <instanceName> --shielded-vtpm --shieldedvm-integrity-monitoring`\n\n3. To also turn on Secure Boot (if you have no custom or unsigned drivers on the instance), add the *\\--shielded-vm-secure-boot* parameter to the previous command or execute the following command separately: \n\n`gcloud compute instances update <instanceName> --shielded-vm-secure-boot` \n\n4. After applying the changes, restart the instance: \n\n`gcloud compute instances start <instanceName>`\n\nNote that Shielded VM is not enabled by default on a VM. However, you can set an organizational policy that will cause all the future VMs to have Shielded VM enabled. To do that, click [here](https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm).  \n\n\n\n#### Other configurations that you should consider for your Google Cloud VMs \n\nThere are some settings you should always check when assessing the security of a virtual machine. Here are just a few examples: \n\n* Use **confidential computing** to [encrypt in-use data](https://cyscale.com/blog/types-of-encryption/). In this way, your data that is processed, trained on, used, queried on your VMs remains encrypted and is not at risk. \n* **Close management ports** if not needed: RDP (3389), SSH (21), WINRM (5985), these are all open gateways for hackers to intrude in your VMs and further down your cloud environment. \n* **Apply patches, OS updates** and any other available updates on your VMs to keep them up to date with the current versions of software and ensure that you’re not leaving them vulnerable to found exploits. \n* **Do not use public IP addresses** for your Compute instances, if possible. Public IP addresses introduce the same vulnerability in your environment as management ports: you increase your attack surface and expose the VM to the Internet. Instead, use load balancers to “hide” your VMs. \n\nAlthough there are many aspects you should consider when setting up your cloud [infrastructure](https://cyscale.com/blog/cloud-infrastructure-security/) securely, use this article as a checklist to tick off some of the most important security configurations."}}],"blueBird":{"data":{"blueBird":{"childImageSharp":{"gatsbyImageData":{"layout":"fixed","images":{"fallback":{"src":"/static/a7e41d4813d3dfc105b466b26564c454/42463/cyscale-blue-bird.png","srcSet":"/static/a7e41d4813d3dfc105b466b26564c454/42463/cyscale-blue-bird.png 386w,\n/static/a7e41d4813d3dfc105b466b26564c454/74bb1/cyscale-blue-bird.png 772w","sizes":"386px"},"sources":[{"srcSet":"/static/a7e41d4813d3dfc105b466b26564c454/e03ca/cyscale-blue-bird.webp 386w,\n/static/a7e41d4813d3dfc105b466b26564c454/e7f31/cyscale-blue-bird.webp 772w","type":"image/webp","sizes":"386px"}]},"width":386,"height":351}}}}},"compliceToolbox":{"data":{"blueBird":{"childImageSharp":{"gatsbyImageData":{"layout":"fixed","images":{"fallback":{"src":"/static/a005e76c44581c38cf1d4d1e54e522c0/91b0f/compliance-toolbox-blog.png","srcSet":"/static/a005e76c44581c38cf1d4d1e54e522c0/91b0f/compliance-toolbox-blog.png 366w,\n/static/a005e76c44581c38cf1d4d1e54e522c0/d39b6/compliance-toolbox-blog.png 732w","sizes":"366px"},"sources":[{"srcSet":"/static/a005e76c44581c38cf1d4d1e54e522c0/7257f/compliance-toolbox-blog.webp 366w,\n/static/a005e76c44581c38cf1d4d1e54e522c0/a67bf/compliance-toolbox-blog.webp 732w","type":"image/webp","sizes":"366px"}]},"width":366,"height":333}}}}}}},"staticQueryHashes":["3058837307","3765828210","4109069157","632500807","981947644"],"slicesMap":{}}